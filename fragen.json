[
  {
    "frage": "Was ist Qualität?<br><br>Wählen Sie genau EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Aktivitäten, die darauf fokussieren, Vertrauen in die Erfüllung der Qualitätsanforderungen zu erzeugen",
      "b": "Der Grad, zu dem eine Komponente oder ein System die expliziten und impliziten Bedürfnisse seiner verschiedenen Stakeholder erfüllt",
      "c": "Der Grad, zu dem eine Komponente oder ein System Informationen und Daten schützt, so dass Personen oder andere Komponenten oder Systeme nur einen solchen Grad an Zugriff erhalten, der ihrer Berechtigungsart und -stufe entspricht",
      "d": "Die gesamten Kosten, die durch Qualitätssicherungsaktivitäten und durch Fehlerwirkungen entstehen. Sie werden oft in Kosten der Fehlervorbeugung, der Kosten der Fehlerermittlung, der internen Fehlerwirkungen und den externen Fehlerwirkungen aufgeteilt"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Das ist die Glossardefinition von Qualitätssicherung.",
      "b": "KORREKT<br><br>Das ist die Glossardefinition von Qualität.",
      "c": "FALSCH<br><br>Das ist die Glossardefinition von IT-Sicherheit.",
      "d": "FALSCH<br><br>Das ist die Glossardefinition von Qualitätskosten."
    }
  },
  {
    "frage": "Welcher der folgenden Punkte ist ein typisches Testziel?<br><br>Wählen Sie genau EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Verhindern von Fehlerzuständen",
      "b": "Fehlerzustände reparieren",
      "c": "Vergleich der tatsächlichen Ergebnisse mit den erwarteten Ergebnissen",
      "d": "Analysieren der Fehlerursache"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Dies ist ein (im Lehrplan) aufgeführtes Ziel.",
      "b": "FALSCH<br><br>Dies ist Debugging.",
      "c": "FALSCH<br><br>Dies ist eine Aktivität innerhalb der Testausführung innerhalb des Testprozesses.",
      "d": "FALSCH<br><br>Dies ist Teil der Fehlersuche."
    }
  },
  {
    "frage": "Ein Telefonklingeln lenkt einen Programmierer kurzzeitig ab, was dazu führt, dass der Programmierer die Logik, die die obere Grenze einer Eingangsvariablen prüft, nicht korrekt programmiert. Später, während des Systemtests, stellt ein Tester fest, dass dieses Eingabefeld ungültige Eingabewerte annimmt. Die unsachgemäß kodierte Logik für die Prüfung der oberen Grenze bezeichnet man als:<br><br>Wählen Sie genau EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Grundursache",
      "b": "Fehlerwirkung",
      "c": "Fehlhandlung",
      "d": "Fehlerzustand"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Die Grundursache ist die Ablenkung, die der Programmierer beim Programmieren erfahren hat.",
      "b": "FALSCH<br><br>Das Akzeptieren von ungültigen Eingängen ist die Fehlerwirkung.",
      "c": "FALSCH<br><br>Die Fehlhandlung ist der Denkfehler, der dazu geführt hat, dass der Fehler in den Code eingebaut wurde.",
      "d": "KORREKT<br><br>Das Problem im Code ist ein Fehlerzustand."
    }
  },
  {
    "frage": "Ein Product Owner sagt, dass Ihre Rolle als Tester in einem agilen Team darin besteht, alle Fehlerzustände vor dem Ende jeder Iteration aufzudecken.<br><br>Welches der folgenden Aussagen ist ein Testprinzip, das als Antwort auf diese (falsche) Aussage verwendet werden könnte?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Häufung von Fehlerzuständen",
      "b": "Testen zeigt die Anwesenheit von Fehlerzuständen",
      "c": "Trugschluss: “Keine Fehler” bedeutet ein brauchbares System",
      "d": "Analyse der Grundursache"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Die Fehlerhäufung hat damit zu tun, wo Fehlerzustände (Defekte) am wahrscheinlichsten zu finden sind, nicht, ob alle gefunden werden können.",
      "b": "KORREKT<br><br>Testen kann das Vorhandensein von Fehlern zeigen, aber nicht deren Abwesenheit beweisen, was es unmöglich macht, zu wissen, ob Sie alle Bugs erwischt haben. Außerdem macht es die Unmöglichkeit des vollständigen Testens für Sie unmöglich, alle Fehlerzustände zu erwischen.",
      "c": "FALSCH<br><br>Dieses Prinzip besagt, dass Sie viele Fehler finden und beseitigen können, aber trotzdem ein erfolgloses Software-Produkt veröffentlichen können, was nicht das ist, was der Product Owner von Ihnen verlangt.",
      "d": "FALSCH<br><br>Die Grundursachenanalyse ist kein Testprinzip."
    }
  },
  {
    "frage": "Programmierer schreiben oft Komponententests und führen diese gegen den von ihnen geschriebenen Code aus.<br><br>Welche der folgenden Denkweisen eines Testers sollten Programmierer während dieser Selbsttest-Aktivität einnehmen, um diese Komponententests effektiv durchzuführen?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Gute Kommunikationsfähigkeiten",
      "b": "Codeüberdeckung",
      "c": "Bewertung von Fehlern im Code",
      "d": "Detailgenauigkeit"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Der Programmierer scheint Komponententests an seinem eigenen Code durchzuführen.",
      "b": "FALSCH<br><br>Codeüberdeckung ist nützlich für Komponententests, aber es ist keine Tester-Denkweise.",
      "c": "FALSCH<br><br>Die Denkweise des Programmierers beinhaltet die Überlegung, was mit dem Code falsch sein könnte, aber das ist nicht die Denkweise eines Testers.",
      "d": "KORREKT<br><br>Diese Denkweise des Testers, die Detailgenauigkeit, hilft den Programmierern, Fehler während der Komponententests zu finden."
    }
  },
  {
    "frage": "Beachten Sie die folgenden Testaktivitäten:<br><ol><li>Auswählen von Regressionstests</li><li>Bewertung der Vollständigkeit der Testdurchführung</li><li>Identifizieren, welche User Stories offene Fehlerberichte haben</li><li>Bewertung, ob die Anzahl der Tests für jede Anforderung mit dem Grad des Produktrisikos vereinbar ist</li></ol><br>Betrachten Sie die folgenden Möglichkeiten, wie die Verfolgbarkeit beim Testen helfen kann:<br><ol style=\"list-style-type: upper-alpha;\"><li>Verbessern der Verständlichkeit von Teststatusberichten, um den Status der Elemente der Testbasis einzubeziehen</li><li>Testaktivitäten nachvollziehbarer/prüfbarer machen</li><li>Bereitstellung von Informationen zur Beurteilung der Prozessqualität</li><li>Analysieren der Auswirkungen von Änderungen</li></ol><br>Welche der folgenden Aussagen passt am besten zur aufgeführten Testaktivität und wie kann \"die Verfolgbarkeit\" diese Aktivität jeweils unterstützen?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "1D, 2B, 3C, 4A",
      "b": "1B, 2D, 3A, 4C",
      "c": "1D, 2C, 3A, 4B",
      "d": "1D, 2B, 3A, 4C"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH",
      "b": "FALSCH",
      "c": "FALSCH",
      "d": "KORREKT<br><br> Begründung:<br>Verfolgbarkeit (syn. Rückverfolgbarkeit, eng. traceability) hilft bei:<ol style=\"list-style-type: circle;\"><li>Auswahl von Regressionstests im Hinblick auf die Analyse der Auswirkungen von Änderungen (1D)</li><li>Bewertung der Vollständigkeit der Testausführung, die das Testen nachvollziehbarer macht (2B)</li><li>Identifizieren, welche User-Stories offene Fehlerberichte haben, was die Verständlichkeit von Teststatusberichten verbessert, um den Status von Testbasis Elementen (3A) einzubeziehen</li><li>Bewertung, ob die Anzahl der Tests für jede Anforderung mit dem Grad des Produktrisikos übereinstimmt, was Informationen zur Bewertung der Testprozessqualität liefert, d. h. Ausrichtung des Testaufwands am Risiko (4C)<br>Daher ist die Option d) KORREKT."
    }
  },
  {
    "frage": "Ein Tester nahm an einer Diskussion über die vorgeschlagene Datenbankstruktur teil. Der Tester identifizierte ein potenzielles Performanzproblem im Zusammenhang mit bestimmten häufigen Anfragen des Benutzers. Dieses mögliche Problem wurde dem Entwicklungsteam erläutert.<br><br>Welcher der folgenden Punkte ist ein Beitrag des Testens zum Erfolg, der am BESTEN zu dieser Situation passt?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Ermöglicht die frühzeitige Erkennung von erforderlichen Tests",
      "b": "Sicherstellen, dass Prozesse ordnungsgemäß durchgeführt werden",
      "c": "Verringerung des Risikos grundlegender Entwurfsfehler",
      "d": "Verringerung des Risikos nicht testbarer Funktionalität"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br> Das frühzeitige Erkennen von erforderlichen Tests ist zwar wichtig, jedoch nicht der beste Beitrag des Testens zu dieser Situation.",
      "b": "FALSCH<br><br> Die Sicherstellung ordnungsgemäßer Prozessdurchführung gehört eher zur Qualitätssicherung als zum Beitrag des Testens in dieser Situation.",
      "c": "KORREKT<br><br> Die Verringerung des Risikos grundlegender Entwurfsfehler ist der beste Beitrag des Testens zu dieser Situation, da die Datenbankstruktur eng mit dem Design verbunden ist und Performanzprobleme ein erhebliches Produktrisiko darstellen können.",
      "d": "FALSCH<br><br> Die Verringerung des Risikos nicht testbarer Funktionalität ist zwar wichtig, jedoch nicht der beste Beitrag des Testens zu dieser Situation, da der Tester hier ein potenzielles Performanzproblem identifiziert hat, das nichts mit nicht testbarer Funktionalität zu tun hat."
    }
  },
  {
    "frage": "Welcher der folgenden Punkte ist ein Beispiel für eine Aufgabe, die im Rahmen des Testprozesses durchgeführt werden kann?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Analysieren eines Fehlerzustands",
      "b": "Entwerfen von Testdaten",
      "c": "Einem Testobjekt eine Version zuordnen",
      "d": "Schreiben einer User Story"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br> Das Analysieren eines Fehlerzustands ist eher Teil des Debuggings als des Testens.",
      "b": "KORREKT<br><br> Das Entwerfen von Testdaten ist eine typische Aufgabe im Rahmen des Testprozesses, da es für die Testimplementierung wichtig ist, geeignete Testdaten zu erstellen.",
      "c": "FALSCH<br><br> Die Zuordnung von Testobjektversionen ist in der Regel Teil des Konfigurationsmanagements und nicht speziell eine Aufgabe im Testprozess.",
      "d": "FALSCH<br><br> Das Schreiben einer User Story ist keine direkte Testaktivität und fällt normalerweise in den Verantwortungsbereich des Product Owners."
    }
  },
  {
    "frage": "Sie führen einen Performanztest mit dem Ziel durch, mögliche Netzwerkengpässe in Schnittstellen zwischen Komponenten eines Systems zu finden. Welche der folgenden Aussagen beschreibt diesen Test?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Ein funktionaler Test während der Integrationsteststufe",
      "b": "Ein nicht-funktionaler Test während der Integrationsteststufe",
      "c": "Ein funktionaler Test während der Komponententeststufe",
      "d": "Ein nicht-funktionaler Test während der Komponententeststufe"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br> Dieser Test entspricht zwar der Beschreibung eines Integrationstests, ist aber ein nicht-funktionaler Test.",
      "b": "KORREKT<br><br> Dieser Test entspricht der Beschreibung eines Integrationstests und es handelt sich um einen nicht-funktionalen Test.",
      "c": "FALSCH<br><br> Dieser Test entspricht nicht der Beschreibung eines Komponententests und es handelt sich nicht um einen funktionalen Test.",
      "d": "FALSCH<br><br> Obwohl dieser Test ein nicht-funktionaler Test ist, entspricht er nicht der Beschreibung eines Komponententests."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen ist zutreffend?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Die Auswirkungsanalyse ist nützlich für Fehlernachtests während der Wartungstests",
      "b": "Fehlernachtests sind nützlich für Regressionstests während des Systementwurfs",
      "c": "Die Auswirkungsanalyse ist nützlich für Regressionstests während der Wartungstests",
      "d": "Die Fehlernachtests sind nützlich für die Auswirkungsanalyse während der Wartungstests"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br> Während die Auswirkungsanalyse während der Wartungstests nützlich ist, ist sie für Fehlernachtests nicht notwendig, da sich Fehlernachtests auf die beabsichtigten Auswirkungen einer Fehlerbehebung oder einer anderen Änderung beziehen.",
      "b": "FALSCH<br><br> Fehlernachtests und Regressionstests sind zwei separate Aktivitäten, und Fehlernachtests sind nicht Teil des Systementwurfs.",
      "c": "KORREKT<br><br> Die Auswirkungsanalyse kann verwendet werden, um Regressionstests für Wartungstests auszuwählen.",
      "d": "FALSCH<br><br> Fehlernachtests sind nicht Teil der Auswirkungsanalyse, obwohl Fehlernachtests typischerweise während der Wartungstests durchgeführt werden."
    }
  },
  {
    "frage": "Betrachten Sie die folgenden Arten von Fehlern, auf die sich eine Teststufe konzentrieren könnte:<ol><li>Fehlerzustände in separat testbaren Modulen oder Objekten</li><li>Nicht auf die Identifizierung von Fehlerzuständen ausgerichtet</li><li>Fehlerzustände an Schnittstellen und Wechselwirkungen</li><li>Fehlerzustände im gesamten Testobjekt</li></ol>Welche der folgenden Listen stimmt mit den Teststufen aus dem Foundation Lehrplan und den oben angegebenen Fehlerschwerpunkten überein?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "1 = Performanztest; 2 = Komponententest; 3 = Systemtest; 4 = Abnahmetest",
      "b": "1 = Komponententest; 2 = Abnahmetest; 3 = Systemtest; 4 = Integrationstest",
      "c": "1 = Komponententest; 2 = Abnahmetest; 3 = Integrationstest; 4 = Systemtest",
      "d": "1 = Integrationstest; 2 = Systemtest; 3 = Komponententest; 4 = Abnahmetest"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH",
      "b": "FALSCH",
      "c": "KORREKT<br><br> Begründung:<br><br>Performanztests sind eine Testart, keine Teststufe. Komponententests konzentrieren sich auf Fehlerzustände in separat testbaren Modulen oder Objekten, Integrationstests auf Fehlerzustände in Schnittstellen und Interaktionen, Systemtests auf Fehlerzustände im gesamten Testobjekt, und Abnahmetests sind typischerweise nicht auf die Identifizierung von Fehlerzuständen ausgerichtet.<br><br>Daher ist c) die KORREKTE Antwort.",
      "d": "FALSCH"
    }
  },
  {
    "frage": "Ein Betriebssystem-Softwareprodukt für den Massenmarkt ist so konzipiert, dass es auf jeder PC-Hardware mit einem Prozessor der x86-Familie läuft. Sie führen eine Reihe von Tests durch, um nach Fehlerzuständen im Zusammenhang mit der Unterstützung der verschiedenen PCs zu suchen, die einen solchen Prozessor verwenden, und um Vertrauen zu schaffen, dass wichtige PC-Marken funktionieren. Welche Art von Test führen Sie durch?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Performanztest",
      "b": "Prozessortest",
      "c": "Funktionaler Test",
      "d": "Übertragbarkeitstest"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br> Der beschriebene Test ist ein nicht-funktionaler Test, speziell ein Übertragbarkeitstest, und kein Performanztest.",
      "b": "FALSCH<br><br> Prozessortest ist keine definierte Testart und beschreibt nicht die Art von Test, der durchgeführt wird.",
      "c": "FALSCH<br><br> Der beschriebene Test ist ein nicht-funktionaler Test, speziell ein Übertragbarkeitstest, und kein funktionaler Test.",
      "d": "KORREKT<br><br> Das Testen unterstützter Geräte, um sicherzustellen, dass das Betriebssystem auf verschiedenen PCs mit x86-Prozessoren läuft, ist ein nicht-funktionaler Test, nämlich ein Übertragbarkeitstest."
    }
  },
  {
    "frage": "Während einer agilen Entwicklungsarbeit entdeckt ein Product Owner eine bisher unbekannte regulatorische Anforderung, die für die meisten User Stories innerhalb eines bestimmten Epics gilt. Die User Stories werden aktualisiert, um die notwendigen Änderungen im Softwareverhalten vorzusehen. Die Programmierer im Team modifizieren den Code entsprechend. Welche Arten von Tests werden Sie als Tester im Team durchführen?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Fehlernachtests",
      "b": "Regressionstests",
      "c": "Funktionale Tests",
      "d": "Änderungsbezogene Tests"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH",
      "b": "FALSCH",
      "c": "FALSCH",
      "d": "KORREKT<br><br> Begründung:<br><br>Die Änderung im Verhalten kann entweder funktional oder nicht-funktional sein. Sie müssen änderungsbezogene Tests durchführen, von denen einige Fehlernachtests und andere Regressionstests sind.<br><br>Daher ist d) die KORREKTE Antwort."
    }
  },
  {
    "frage": "Wie lautet die Bezeichnung der Rolle eines Teilnehmers, der eine Inspektionssitzung bei einer formellen Überprüfung leitet?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Moderator",
      "b": "Programmierer",
      "c": "Autor",
      "d": "Projektleiter"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br> Der Moderator leitet die Überprüfungssitzungen und ist verantwortlich für den Ablauf und die Einhaltung des Prozesses.",
      "b": "FALSCH<br><br> Die Rolle des Programmierers ist nicht die eines Leiters einer Inspektionssitzung bei einer formalen Überprüfung.",
      "c": "FALSCH<br><br> Der Autor ist normalerweise die Person, die den zu überprüfenden Artikel geschrieben hat und nicht zwangsläufig der Leiter der Inspektionssitzung.",
      "d": "FALSCH<br><br> Der Projektleiter ist nicht speziell dafür zuständig, eine Inspektionssitzung zu leiten."
    }
  },
  {
    "frage": "Sie lesen eine User Story im Product Backlog, um sich auf ein Meeting mit dem Product Owner und einem Entwickler vorzubereiten und notieren dabei mögliche Fehler. Welche der folgenden Aussagen zu dieser Aktivität ist zutreffend?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Es handelt sich nicht um einen statischen Test, denn beim statischen Test wird das Testobjekt ausgeführt",
      "b": "Es handelt sich nicht um einen statischen Test, denn statische Tests werden immer mit einem Werkzeug durchgeführt",
      "c": "Es handelt sich um einen statischen Test, denn alle Fehler, die Sie finden, könnten beim dynamischen Test günstiger gefunden werden",
      "d": "Es handelt sich um einen statischen Test, da bei statischen Tests das Testobjekt nicht ausgeführt wird"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br> Beim statischen Testen wird das Testobjekt nicht ausgeführt, es wird lediglich geprüft, ohne dass der Code ausgeführt wird.",
      "b": "FALSCH<br><br> Statische Tests können auch manuell durchgeführt werden, ohne dass unbedingt ein Werkzeug erforderlich ist.",
      "c": "FALSCH<br><br> Die Kosteneffizienz von Fehlerbehebungen hängt nicht unbedingt davon ab, ob sie in statischen oder dynamischen Tests gefunden werden, sondern von der Phase, in der sie gefunden und behoben werden.",
      "d": "KORREKT<br><br> Beim statischen Testen wird das Testobjekt nicht ausgeführt, sondern es werden Artefakte wie Code, Dokumente oder User Stories überprüft."
    }
  },
  {
    "frage": "Während einer Phase intensiver Projektüberstunden wird ein Systemarchitekturdokument an verschiedene Projektteilnehmer gesendet, in dem ein zuvor nicht geplantes technisches Review in einer Woche angekündigt wird. Es werden keine Anpassungen an der Liste der zugewiesenen Aufgaben der Teilnehmer vorgenommen.<br><br>Welcher der folgenden Erfolgsfaktoren für Reviews fehlt allein aufgrund dieser Information?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Geeignete Review-Art",
      "b": "Ausreichend Zeit zur Vorbereitung",
      "c": "Ausreichende Metriken zur Bewertung des Autors",
      "d": "Gut geleitete Review-Sitzung"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br> Technische Reviews sind für technische Dokumente wie Systemarchitektur geeignet, daher ist die Auswahl der Review-Art angemessen.",
      "b": "KORREKT<br><br> In diesem Szenario fehlt es an ausreichender Zeit für die Vorbereitung, da das technische Review innerhalb einer Woche angekündigt wird und keine Anpassungen an der Arbeitsliste der Teilnehmer vorgenommen wurden. Dies kann die Qualität des Reviews beeinträchtigen.",
      "c": "FALSCH<br><br> Das Fehlen ausreichender Metriken zur Bewertung des Autors ist nicht der Hauptgrund für den Mangel an Erfolgsfaktoren in diesem Szenario.",
      "d": "FALSCH<br><br> Eine gut geleitete Review-Sitzung ist wichtig, aber es gibt keinen spezifischen Hinweis darauf, dass die Sitzung nicht gut geleitet wird."
    }
  },
  {
    "frage": "Sie arbeiten als Tester in einem agilen Team und haben zu Beginn jeder Iteration an über zwei Dutzend User-Story-Verfeinerungssessions mit dem Product Owner und den Entwicklern im Team teilgenommen. Da die Reviews bei der Erkennung von Fehlerzuständen in User Stories immer effektiver und der Product Owner bei der Korrektur dieser Fehlerzustände immer geschickter geworden sind, stellen Sie und das Team fest, dass die Geschwindigkeit des Teams, wie in Ihren Burndown-Charts dargestellt, zu steigen beginnt.<br><br>Welcher der folgenden Vorteile des statischen Testens bezieht sich am DIREKTESTEN auf die erhöhte Geschwindigkeit des Teams?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Steigende Gesamtkosten der Qualität",
      "b": "Reduzierung der Testkosten",
      "c": "Steigerung der Entwicklungsproduktivität",
      "d": "Reduzierung der Gesamtkosten für Qualität"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br> Reviews reduzieren die Gesamtkosten der Qualität, anstatt sie zu steigern.",
      "b": "FALSCH<br><br> Die gesteigerte Geschwindigkeit ist ein Indikator für die gesteigerte Entwicklungsproduktivität, die nicht direkt mit Testkostenreduktion in Verbindung steht.",
      "c": "KORREKT<br><br> Die gesteigerte Entwicklungsproduktivität, die durch effektivere Reviews und Korrekturen von Fehlerzuständen erreicht wird, führt dazu, dass das Team schneller arbeitet und mehr Arbeit in jeder Iteration erledigt, was sich in einer höheren Geschwindigkeit des Teams niederschlägt.",
      "d": "FALSCH<br><br> Dieser Vorteil ist nicht direkt mit der gesteigerten Geschwindigkeit des Teams verbunden."
    }
  },
  {
    "frage": "Sie arbeiten an einem Entwicklungsprojekt für ein Videospiel, das mit agilen Methoden entwickelt wird. Es basiert auf der griechischen Mythologie und Geschichte, und die Spieler können Schlüsselrollen in Szenarien wie den Schlachten zwischen Griechen und Trojanern übernehmen.<br><br>Betrachten Sie die folgende User-Story und die zugehörigen Akzeptanzkriterien:<br><br>Als Spieler möchte ich in der Lage sein, den Stab des Midas (ein neues magisches Objekt) zu erwerben, damit ich Objekte und andere Spieler in Gold verwandeln kann.<br><br><ul class='ac-liste'><li>Der Stab muss auf jedes Objekt oder jeden Spieler – egal welcher Größe – wirken, das von dem Spieler, der den Stab hält, irgendwo berührt werden kann</li><li>Das Halten des Stabes verwandelt den Spieler, der ihn hält, nicht in Gold</li><li>Jeder Gegenstand oder Spieler, der vom Stab berührt wird, verwandelt sich innerhalb einer Millisekunde vollständig in Gold</li><li>Der Stab erscheint wie in Prototyp O.W.RoM gezeigt</li><li>Die Transformation beginnt an der Kontaktstelle mit dem Stab und bewegt sich mit einer Geschwindigkeit von einem Meter pro Millisekunde</li></ul>Sie nehmen an einer checklistenbasierten Reviewsitzung zu dieser User Story teil.<br><br>Diese User-Story und die zugehörigen Akzeptanzkriterien enthalten welche der folgenden typischen Fehler, die durch statische Tests bei dieser Art von Arbeitsprodukt identifiziert werden können?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Abweichung von Normen",
      "b": "Widersprüche",
      "c": "Sicherheitslücke",
      "d": "Überdeckungslücken"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Während die Abweichung von Standards typisch ist, wird uns kein Standard vorgegeben, dem die User Stories entsprechen sollen.",
      "b": "KORREKT<br><br>Widerspruch (Inkonsistenz) ist ein typischer Anforderungsfehler. AC3 und AC5 widersprechen sich, wenn der Stab ein Objekt berührt, das sich mehr als 1 Meter in jede Richtung vom Berührungspunkt aus erstreckt, da AC1 die Größe der zu berührenden Objekte nicht begrenzt.",
      "c": "FALSCH<br><br>Während Sicherheitslücken typische Fehler sind, gibt es hier nichts, was mit Sicherheit zu tun hat.",
      "d": "FALSCH<br><br>Obwohl (Test-)Überdeckungslücken typische Fehler sind, einschließlich fehlender Tests für Abnahmekriterien, erhalten wir keine Informationen darüber, welche Tests vorhanden sind und welche nicht."
    }
  },
  {
    "frage": "Was ist Entscheidungsüberdeckung?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Die Überdeckung der Bedingungsergebnisse",
      "b": "Entscheidungsüberdeckung ist ein Synonym für Anweisungsüberdeckung",
      "c": "Die Überdeckung von ausführbaren Anweisungen",
      "d": "Die Überdeckung von Entscheidungsergebnissen"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Dies ist die Glossardefinition von Bedingungsüberdeckung.",
      "b": "FALSCH<br><br>Die Entscheidungsüberdeckung ist eine höhere Ebene der Überdeckung und die beiden Begriffe sind im Glossar nicht als Synonyme definiert.",
      "c": "FALSCH<br><br>Das ist die Glossar-Definition von Anweisungsüberdeckung.",
      "d": "KORREKT<br><br>Die Überdeckung von Entscheidungsergebnissen ist die Glossar-Definition des Begriffs Entscheidungsüberdeckung, der auf Entscheidungen angewendet wird."
    }
  },
  {
    "frage": "Im Vorfeld einer Iterationsplanungssitzung untersuchen Sie eine User Story und deren Akzeptanzkriterien und leiten daraus Testbedingungen und zugehörige Testfälle ab, um das Prinzip der frühen Qualitätssicherung und des Tests anzuwenden.<br><br>Welches Testverfahren wenden Sie an?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "White-Box",
      "b": "Black-Box",
      "c": "Erfahrungsbasiert",
      "d": "Intuitiv"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Strukturbasierte oder White-Box-Verfahren basieren auf einer Analyse der Architektur, des detaillierten Designs, der internen Struktur oder des Codes des Testobjekts.",
      "b": "KORREKT<br><br>Black-Box-Testverfahren basieren auf einer Analyse der entsprechenden Testbasis (z. B. formale Anforderungsdokumente, Spezifikationen, Anwendungsfälle, User Stories oder Geschäftsprozesse), die funktionales und nicht-funktionales Verhalten beschreiben.",
      "c": "FALSCH<br><br>Erfahrungsbasierte Techniken nutzen die Erfahrung von Entwicklern, Testern und Benutzern, um zu bestimmen, was getestet werden soll.",
      "d": "FALSCH<br><br>Intuitive Testfallermittlung ist eine Art von erfahrungsbasiertem Testen, dass kein Blackbox-Test ist."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen über exploratives Testen ist zutreffend?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Erfahrene Tester, die ähnliche Anwendungen und Technologien getestet haben, schneiden bei explorativen Tests wahrscheinlich besser ab als weniger erfahrene Tester",
      "b": "Beim explorativen Testen werden keine zusätzlichen Tests identifiziert, die über diejenigen hinausgehen, die sich aus formalen Testverfahren ergeben würden",
      "c": "Die Zeit, die für eine explorative Testsitzung benötigt wird, lässt sich nicht im Voraus vorhersagen",
      "d": "Exploratives Testen kann den Einsatz von Black-Box-Techniken beinhalten, aber nicht von White-Box-Techniken"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Exploratives Testen ist eine Form des erfahrungsbasierten Testens, das von den Fähigkeiten und der Erfahrung des Testers profitiert.",
      "b": "FALSCH<br><br>Exploratives Testen ist nützlich, um formale Testverfahren zu ergänzen.",
      "c": "FALSCH<br><br>Beim sitzungsbasierten Testmanagement werden explorative Tests innerhalb eines definierten Zeitrahmens durchgeführt, und der Tester verwendet eine Test-Charta, die Testziele enthält, um das Testen anzuleiten.",
      "d": "FALSCH<br><br>Exploratives Testen kann die Verwendung anderer Black-Box-, White-Box und erfahrungsbasierter Techniken beinhalten, die in diesem Lehrplan genannt werden."
    }
  },
  {
    "frage": "Sie testen eine mobile App, mit der Kunden auf ihre Bankkonten zugreifen und diese verwalten können. Sie führen eine Testsuite aus, die die Bewertung jedes Bildschirms und jedes Feldes auf jedem Bildschirm anhand einer allgemeinen Liste von Best Practices für Benutzeroberflächen umfasst. Sie wurde aus einem populären Buch zu diesem Thema abgeleitet und soll die Attraktivität, Benutzerfreundlichkeit und Zugänglichkeit für solche Apps maximieren.<br><br>Welche der folgenden Optionen kategorisiert das von Ihnen verwendete Testverfahren am BESTEN?<br><br>Wählen Sie EINE Option.",
    "inhalte": [],
    "antworten": {
      "a": "Spezifikationsbasiert",
      "b": "Explorativ",
      "c": "Checklistenbasiert",
      "d": "Intuitiv"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Das Buch bietet einen allgemeinen Leitfaden und ist kein formales Anforderungsdokument, keine Spezifikation oder eine Sammlung von Anwendungsfällen, User Stories oder Geschäftsprozessen",
      "b": "FALSCH<br><br>Während Sie die Liste als eine Reihe von Test-Chartas betrachten könnten, ähnelt sie eher der Liste von Testbedingungen",
      "c": "KORREKT<br><br>Die Liste der Best Practices für die Benutzeroberfläche ist die Liste der Testbedingungen",
      "d": "FALSCH<br><br>Die Tests konzentrieren sich nicht auf Fehler, die auftreten könnten, sondern auf die Erkenntnis, was für den Benutzer wichtig ist, im Sinne der Leichtigkeit der Nutzung (Benutzerfreundlichkeit)."
    }
  },
  {
    "frage": "Betrachten Sie eine mobile App, mit der Kunden auf ihre Bankkonten zugreifen und diese verwalten können. Es wurde gerade eine User Story zu den Funktionen hinzugefügt, die die Social-Media-Konten und Bankdaten der Kunden überprüft, um personalisierte Grüße zu Geburtstagen und anderen persönlichen Jahrestagen zu übermitteln.<br><br>Welche der folgenden Testverfahren könnte ein PROGRAMMIERER während eines Komponententests des Codes verwenden, um sicherzustellen, dass Situationen abgedeckt werden, in denen die Grüße auftreten SOLLEN und in denen die Grüße NICHT auftreten SOLLEN?<br><br>Wählen Sie EINE Option.",
    "inhalte": [],
    "antworten": {
      "a": "Anweisungstest",
      "b": "Exploratives Testen",
      "c": "Zustandsübergangstest",
      "d": "Entscheidungstest"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Anweisungstests führen die Anweisungen im Code aus, was dazu führen kann, dass bestimmte Ansagen bezogen auf Jahrestage nicht getestet werden.",
      "b": "FALSCH<br><br>Wenn in der Test-Charta nicht ausdrücklich erwähnt wird, dass sowohl das Vorhandensein als auch das Nichtvorhandensein jeder Art von Begrüßung getestet wird, kann die Abdeckung für einen explorativen Test schwer zu beurteilen sein.",
      "c": "FALSCH<br><br>Das Testen von Zustandsübergängen ist nützlich für Situationen, in denen das Testobjekt abhängig von aktuellen Bedingungen oder der Vorgeschichte unterschiedlich auf eine Eingabe reagiert. In diesem Fall muss das Testobjekt jedoch entscheiden, ob das aktuelle Datum mit einem bestimmten Meilenstein übereinstimmt und somit die entsprechende Ansage angezeigt werden soll.",
      "d": "KORREKT<br><br>Entscheidungstests beinhalten Testfälle, die den Kontrollflüssen folgen, die von einem Entscheidungspunkt ausgehen, was in diesem Fall die Entscheidung wäre, ob eine Ansage bezogen auf einen Jahrestag gemacht werden soll oder nicht."
    }
  },
  {
    "frage": "Eine Batch-Anwendung ist seit über zwei Jahren unverändert in Produktion. Sie läuft einmal im Monat über Nacht, um Auszüge zu erstellen, die per E-Mail an die Kunden gesendet werden. Für jeden Kunden geht die Anwendung durch jedes Konto und listet jede Transaktion auf diesem Konto im letzten Monat auf. Sie verwendet eine verschachtelte Schleifenstruktur, um Kunden (äußere Schleife), die Konten jedes Kunden (mittlere Schleife) und die Transaktionen jedes Kontos (innere Schleife) zu verarbeiten.<br><br>In einer Nacht bricht die Batch-Anwendung vorzeitig ab und versäumt es, Auszüge per E-Mail an einige Kunden zu senden, wenn sie auf einen Kunden mit einem Konto trifft, für das im letzten Monat keine Transaktionen stattgefunden haben. Dies ist eine sehr ungewöhnliche Situation und ist in den Jahren, seitdem diese Anwendung in Produktion gegangen ist, nicht mehr aufgetreten.<br><br>Während der Behebung des Fehlers bittet Sie ein Programmierer, Testverfahren zu empfehlen, die gegen diese Art von Fehler wirksam sind.<br><br>Welche der folgenden Testverfahren hätte den zugrundeliegenden Fehlerzustand am ehesten aufdecken können?<br><br>Wählen Sie EINE OPTION aus.",
    "inhalte": [],
    "antworten": {
      "a": "Entscheidungstest",
      "b": "Anweisungstest",
      "c": "Checklistenbasiertes Testen",
      "d": "Intuitive Testfallermittlung"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Für ein Schleifenkonstrukt erfordert die Anweisungsüberdeckung nur, dass alle Anweisungen innerhalb der Schleife ausgeführt werden, aber die Entscheidungsüberdeckung erfordert das Testen sowohl der Bedingungen, unter denen die Schleife ausgeführt wird, als auch der Bedingungen, unter denen sie umgangen wird.",
      "b": "FALSCH<br><br>Für ein Schleifenkonstrukt erfordert die Anweisungsüberdeckung nur, dass alle Anweisungen innerhalb der Schleife ausgeführt werden, aber die Entscheidungsüberdeckung erfordert das Testen sowohl der Bedingungen, unter denen die Schleife ausgeführt wird, als auch, wenn sie umgangen wird.",
      "c": "FALSCH<br><br>Checklisten basieren auf Erfahrung, Fehlerdaten, Wissen darüber, was für den Benutzer wichtig ist, und einem Verständnis darüber, warum und wie Software versagt, wobei nichts davon zur Aufnahme einer solchen Testbedingung geführt haben dürfte.",
      "d": "FALSCH<br><br>Es ist zwar möglich, dass ein Entwickler die irrtümliche Annahme macht, dass es immer mindestens eine Transaktion in einem Monat für jedes Konto gibt, aber nur Entscheidungstests garantieren das Testen dieser Bedingung."
    }
  },
  {
    "frage": "Sie testen für eine unbeaufsichtigte amerikanische Zapfsäule, an der nur Kreditkarten akzeptiert werden. Nachdem die Kreditkarte validiert, die Zapfpistole in den Tank eingeführt und die gewünschte Sorte ausgewählt wurde, gibt der Kunde die gewünschte Kraftstoffmenge in Gallonen über das Tastenfeld ein. Das Tastenfeld erlaubt nur die Eingabe von Ziffern. Kraftstoff wird in Zehntel (0,1) Gallonen verkauft, bis zu 50,0 Gallonen.<br><br>Welche der folgenden Eingabewerte ist eine minimale Menge von gewünschten Beträgen, die die Äquivalenzklassen für diese Eingabe abdeckt?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "0,0; 20,0, 60,0",
      "b": "0,0; 0,1; 50,0",
      "c": "0,0; 0,1; 50,0; 70,0",
      "d": "-0,1; 0,0; 0,1; 49,9; 50,0; 50,1"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Dieser Satz von Eingabewerten hat genau einen Test pro Äquivalenzklasse. Begründung: Es gibt drei Äquivalenzklassen: - Kein Verkauf abgeschlossen (0,0 Gallonen); - Ein gültiger Verkauf findet statt (0,1 bis 50,0 Gallonen); - Eine ungültige Menge wurde ausgewählt (50,1 oder mehr Gallonen).",
      "b": "FALSCH<br><br>Dieser Satz von Eingangswerten deckt die ungültige Überschreitung der höchstens erlaubten 50,0 Gallonen nicht ab. Begründung: Es gibt drei Äquivalenzklassen: - Kein Verkauf abgeschlossen (0,0 Gallonen); - Ein gültiger Verkauf findet statt (0,1 bis 50,0 Gallonen); - Eine ungültige Menge wurde ausgewählt (50,1 oder mehr Gallonen).",
      "c": "FALSCH<br><br>Dieser Satz von Eingangswerten hat zwei Tests für die gültige Verkaufs Äquivalenzklasse, was nicht das Minimum von einem Test ist. Begründung: Es gibt drei Äquivalenzklassen: - Kein Verkauf abgeschlossen (0,0 Gallonen); - Ein gültiger Verkauf findet statt (0,1 bis 50,0 Gallonen); - Eine ungültige Menge wurde ausgewählt (50,1 oder mehr Gallonen).",
      "d": "FALSCH<br><br>Dieser Satz von Eingabewerten deckt jeweils drei Grenzwerte für die beiden Grenzen 0,0 und 50,0 ab, nicht die Mindestanzahl, die erforderlich ist, um die Äquivalenzklassen abzudecken. Begründung: Es gibt drei Äquivalenzklassen: - Kein Verkauf abgeschlossen (0,0 Gallonen); - Ein gültiger Verkauf findet statt (0,1 bis 50,0 Gallonen); - Eine ungültige Menge wurde ausgewählt (50,1 oder mehr Gallonen)."
    }
  },
  {
    "frage": "Sie testen ein E-Commerce-System, das Lebensmittel wie Gewürze, Mehl und andere Artikel in großen Mengen verkauft. Die Einheiten, in denen die Artikel verkauft werden, sind entweder Gramm (für Gewürze und andere teure Artikel) oder Kilogramm (für Mehl und andere preiswerte Artikel). Unabhängig von den Einheiten ist die kleinste gültige Bestellmenge 0,5 Einheiten (z. B. ein halbes Gramm Kardamomkapseln) und die größte gültige Bestellmenge 25,0 Einheiten (z. B. 25 Kilogramm Zucker). Die Genauigkeit des Einheitenfeldes beträgt 0,1 Einheiten.<br><br>Welche der folgenden Eingabewerte decken die Grenzwerte mit Zweipunkt Grenzwerten für dieses Feld ab?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "0,3; 10,0; 28,0",
      "b": "0,4; 0,5; 0,6; 24,9;25,0; 25,1",
      "c": "0,4; 0,5; 25,0; 25,1",
      "d": "0,5; 0,6; 24,9; 25,0"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Keiner dieser vier Grenzwerte ist in diesem Satz von Tests enthalten. Diese Tests decken die Äquivalenzklassen ab",
      "b": "FALSCH<br><br>Alle diese vier Grenzwerte sind in diesem Satz von Tests enthalten, aber zwei zusätzliche Werte sind enthalten, einer für jede Grenze. Dies sind die Werte, die mit der Dreipunkt-Grenzwertanalyse verbunden sind",
      "c": "KORREKT<br><br>Jeder dieser vier Zweipunkt-Grenzwerte ist in diesem Satz von Tests enthalten",
      "d": "FALSCH<br><br>Diese vier Werte sind alle in der gültigen Äquivalenzklasse enthalten"
    }
  },
  {
    "frage": "Betrachten Sie die folgende Entscheidungstabelle für den Teil eines Online-Flugreservierungssystems, der Vielfliegern das Einlösen von Punkten für Prämienreisen ermöglicht:<br>",
    "inhalte": [
      {
        "typ": "tabelle",
        "inhalt": {
          "kopf": [
            "Zustand",
            "1",
            "2",
            "3"
          ],
          "koerper": [
            [
              "Konto/Passwort okay",
              "N",
              "J",
              "J"
            ],
            [
              "Ausreichend Punkte",
              "-",
              "N",
              "J"
            ],
            {
              "zeile": [
                "Aktion",
                " ",
                " ",
                " "
              ],
              "istKopfZeile": true
            },
            [
              "Flugverlauf anzeigen",
              "N",
              "J",
              "J"
            ],
            [
              "Belohnungsfahrten zulassen",
              "N",
              "N",
              "J"
            ]
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Angenommen, es gibt zwei Äquivalenzklassen für die Bedingung, bei der \"Konto/Passwort okay\" nicht wahr ist, eine, bei der das Konto ungültig ist, und eine andere, bei der das Konto gültig ist, aber das Passwort ungültig ist. Angenommen, es gibt nur eine Äquivalenzklasse für die Bedingung, in der „Konto/Passwort okay“ wahr ist, in der sowohl das Konto als auch das Passwort gültig sind.<br><br>Wenn Sie Tests entwerfen möchten, um die Äquivalenzklassen für \"Konto/Passwort okay\" und auch für diesen Teil der Entscheidungstabelle abzudecken, wie viele Tests sind mindestens erforderlich?<br><br>Wählen Sie EINE Option aus."
      }
    ],
    "antworten": {
      "a": "2",
      "b": "3",
      "c": "4",
      "d": "9"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Die Anzahl der Tests sollte basierend auf den Äquivalenzklassen und der Entscheidungstabelle bestimmt werden.",
      "b": "FALSCH<br><br>Die Anzahl der Tests sollte basierend auf den Äquivalenzklassen und der Entscheidungstabelle bestimmt werden.",
      "c": "KORREKT<br><br>Für jede Spalte in der Entscheidungstabelle gibt es mindestens einen Test. Für Spalte eins sind jedoch zwei Tests erforderlich, einer, bei dem das Konto ungültig ist, und ein weiterer, bei dem das Konto gültig ist, aber das Kennwort ungültig ist, sodass die Mindestanzahl an Tests vier beträgt.<br><br>Daher ist Option c) KORREKT.",
      "d": "FALSCH<br><br>Die Anzahl der Tests sollte basierend auf den Äquivalenzklassen und der Entscheidungstabelle bestimmt werden."
    }
  },
  {
    "frage": "Betrachten Sie das folgende Zustandsübergangsdiagramm für eine Zapfsäule, die nur mit einer Kreditkarte bedient wird:",
    "inhalte": [
      {
        "typ": "bild",
        "inhalt": "pics/istqb-ctfl-2018-sc-q28.png"
      },
      {
        "typ": "text",
        "inhalt": "Nehmen Sie an, dass Sie eine minimale Anzahl von Tests entwickeln möchten, um jeden Übergang im Zustandsübergangsdiagramm abzudecken. Nehmen Sie weiter an, dass jeder Test im Anfangszustand beginnen muss, also beim Warten auf den Kunden, und jeder Test endet, wenn ein Übergang im Anfangszustand ankommt.<br><br>Wie viele Tests benötigen Sie?<br><br>Wählen Sie EINE Option aus."
      }
    ],
    "antworten": {
      "a": "4",
      "b": "7",
      "c": "1",
      "d": "unendlich viele Tests"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Begründung:<br><br>Jeder Übergang muss mindestens einmal durchlaufen werden. Dabei kann der erste Test einen erfolgreichen Kauf, der nächste Test Abbruch oder Zeitüberschreitung vom Warten auf das Tanken, der nächste Test Abbruch oder Zeitüberschreitung vom Warten auf den Kraftstofftyp und der letzte Test das Einführen einer ungültigen Kreditkarte abdecken. Die Reihenfolge ist zwar unerheblich, aber bei weniger als vier Tests wird einer der Übergänge vom Eingang zum Warten auf den Kunden nicht abgedeckt oder die Regeln darüber, wo ein Test beginnt oder endet, werden verletzt. Mehr als vier Tests beinhalten Tests, die bereits abgedeckte Übergänge erneut durchlaufen.<br><br>Daher ist Option a) KORREKT.",
      "b": "FALSCH",
      "c": "FALSCH",
      "d": "FALSCH"
    }
  },
  {
    "frage": "Sie testen ein E-Commerce-System, das Lebensmittel wie Gewürze, Mehl und andere Artikel in großen Mengen verkauft. Die Einheiten, in denen die Artikel verkauft werden, sind entweder Gramm (für Gewürze und andere teure Artikel) oder Kilogramm (für Mehl und andere preiswerte Artikel). Unabhängig von den Einheiten ist die kleinste gültige Bestellmenge 0,5 Einheiten (z. B. ein halbes Gramm Kardamomkapseln) und die größte gültige Bestellmenge 25,0 Einheiten (z. B. 25 Kilogramm Zucker). Die Genauigkeit des Feldes 'Einheiten' beträgt 0,1 Einheiten.<br><br>Welche der folgenden ist eine MINIMALE Menge von Eingabewerten, die die Äquivalenzklassen für dieses Feld abdecken?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "10,0; 28,0",
      "b": "0,4; 0,5; 25,0; 25,1",
      "c": "0,2; 0,9; 29,5",
      "d": "12,3"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Nur zwei der Äquivalenzklassen werden in diesem Satz von Tests abgedeckt.<br><br>Begründung:<br><br>Es gibt drei Äquivalenzklassen, mit den Grenzen wie gezeigt:<br><br>- Ungültig zu niedrig (0,4 und darunter)<br><br>- Gültig (0,5 bis 25,0)<br><br>- Ungültig zu hoch (25,1 und höher)",
      "b": "FALSCH<br><br>Jeder dieser vier Grenzwerte ist in diesem Satz von Tests enthalten, aber die Frage fragte nach der Abdeckung der Äquivalenzklasse mit minimalen Tests, also sollte entweder 0,5 oder 25,0 weggelassen werden.",
      "c": "KORREKT<br><br>Jede dieser drei Äquivalenzklassen wird in diesem Testsatz abgedeckt.<br><br>Begründung:<br><br>Es gibt drei Äquivalenzklassen, mit den Grenzen wie gezeigt:<br><br>- Ungültig zu niedrig (0,4 und darunter)<br><br>- Gültig (0,5 bis 25,0)<br><br>- Ungültig zu hoch (25,1 und höher)",
      "d": "FALSCH<br><br>Nur eine dieser Äquivalenzklassen wird von diesem Test abgedeckt.<br><br>Begründung:<br><br>Es gibt drei Äquivalenzklassen, mit den Grenzen wie gezeigt:<br><br>- Ungültig zu niedrig (0,4 und darunter)<br><br>- Gültig (0,5 bis 25,0)<br><br>- Ungültig zu hoch (25,1 und höher)"
    }
  },
  {
    "frage": "Sie arbeiten als Tester an einem Online-Banking-System. Die Verfügbarkeit wird als eines der Top-Produkt(qualitäts)risiken für das System angesehen. Sie finden einen reproduzierbaren Fehler, der dazu führt, dass Kunden bei Überweisungen zwischen gängigen Kontotypen die Verbindung zur Bank-Website verlieren und diese dann drei bis fünf Minuten lang nicht wiederhergestellt werden kann.<br><br>Welche der folgenden Aussagen wäre eine gute Zusammenfassung für einen Fehlerbericht für diesen Fehler, die sowohl das Wesentliche des Fehlers als auch seine Auswirkungen auf die Beteiligten erfasst?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Webserver-Protokolle zeigen beim Ausführen von Test 07.005 den Fehler 0x44AB27 an, was keine erwartete Fehlermeldung im /tmp-Dateisystem ist",
      "b": "Die Entwickler haben einen schwerwiegenden Verfügbarkeitsfehler eingeführt, der unsere Kunden ernsthaft verärgern wird",
      "c": "Die Leistung ist langsam und die Zuverlässigkeit unter Last schwankend",
      "d": "Typische Überweisungstransaktion führt zur Unterbrechung der Kundensitzung, mit einer Verzögerung der Verfügbarkeit beim Versuch, die Verbindung wiederherzustellen"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Während diese Informationen für Entwickler nützlich sind, geben sie Managern kein Gefühl für die Auswirkungen auf die Produktqualität.",
      "b": "FALSCH<br><br>Diese Zusammenfassung liefert Entwicklern oder Managern nicht die notwendigen Informationen und greift die Entwickler an.",
      "c": "FALSCH<br><br>Diese Zusammenfassung liefert Entwicklern oder Managern nicht die notwendigen Informationen.",
      "d": "KORREKT<br><br>Diese Zusammenfassung vermittelt ein gutes Gefühl für den Ausfall und seine Auswirkungen."
    }
  },
  {
    "frage": "Sie testen eine mobile App, mit der Benutzer basierend auf der Art des gewünschten Essens ein Restaurant in der Nähe finden können.<br><br>Betrachten Sie die folgende Liste von Testfällen, Prioritäten (kleinere Zahl bedeutet hohe Priorität) und Abhängigkeiten im folgenden Format:<br>",
    "inhalte": [
      {
        "typ": "tabelle",
        "inhalt": {
          "kopf": [
            "Testfall-Nummer",
            "Abgedeckte Testbedingung",
            "Priorität",
            "Logische Abhängigkeit"
          ],
          "koerper": [
            [
              "01.001",
              "Art des Lebensmittels wählen",
              "3",
              "keine"
            ],
            [
              "01.002",
              "Restaurant auswählen",
              "2",
              "01.001"
            ],
            [
              "01.003",
              "Wegbeschreibung erhalten",
              "1",
              "01.002"
            ],
            [
              "01.004",
              "Restaurant anrufen",
              "1",
              "01.002"
            ],
            [
              "01.005",
              "Reservierung vornehmen",
              "3",
              "01.002"
            ]
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Welcher der folgenden ist ein möglicher Testausführungsplan, der sowohl Prioritäten als auch Abhängigkeiten berücksichtigt?<br><br>Wählen Sie EINE Option aus."
      }
    ],
    "antworten": {
      "a": "01.001, 01.002, 01.003, 01.005, 01.004",
      "b": "01.001, 01.002, 01.004, 01.003, 01.005",
      "c": "01.003, 01.004, 01.002, 01.001, 01.002",
      "d": "01.001, 01.002, 01.004, 01.005, 01.003"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Begründung:<br><br>Der Test 01.001 muss zuerst ausgeführt werden, gefolgt von 01.002, um Abhängigkeiten zu erfüllen. Danach sollten 01.004 und 01.003 in beliebiger Reihenfolge ausgeführt werden, gefolgt von 01.005, um die Priorität zu erfüllen.",
      "b": "FALSCH<br><br>Begründung:<br><br>Der Test 01.001 muss zuerst ausgeführt werden, gefolgt von 01.002, um Abhängigkeiten zu erfüllen. Danach sollten 01.004 und 01.003 in beliebiger Reihenfolge ausgeführt werden, gefolgt von 01.005, um die Priorität zu erfüllen.<br><br>Daher ist Option b) KORREKT.",
      "c": "KORREKT<br><br>Begründung:<br><br>Der Test 01.001 muss zuerst ausgeführt werden, gefolgt von 01.002, um Abhängigkeiten zu erfüllen. Danach sollten 01.004 und 01.003 in beliebiger Reihenfolge ausgeführt werden, gefolgt von 01.005, um die Priorität zu erfüllen.",
      "d": "FALSCH<br><br>Begründung:<br><br>Der Test 01.001 muss zuerst ausgeführt werden, gefolgt von 01.002, um Abhängigkeiten zu erfüllen. Danach sollten 01.004 und 01.003 in beliebiger Reihenfolge ausgeführt werden, gefolgt von 01.005, um die Priorität zu erfüllen."
    }
  },
  {
    "frage": "Welcher der folgenden Punkte ist eine gängige Testmetrik, die häufig verwendet wird, um SOWOHL die Testvorbereitung ALS AUCH die Testausführung zu überwachen?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Status des Testfalls",
      "b": "Fehlerfindungsraten / Fehlerbehebungsraten",
      "c": "Vorbereitung der Testumgebung",
      "d": "Geschätzte Kosten, um den nächsten Fehlerzustand zu finden"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Der Prozentsatz der vorbereiteten Testfälle ist eine übliche Metrik während der Testvorbereitung, während der Prozentsatz der bestandenen, fehlgeschlagenen, nicht ausgeführten Testfälle usw. während der Testausführung üblich ist.",
      "b": "FALSCH<br><br> Fehlerberichte werden typischerweise während der Testausführung erfasst, basierend auf den gefundenen Fehlern.",
      "c": "FALSCH<br><br> Die Vorbereitung der Testumgebung ist Teil der Implementierung und würde im Allgemeinen vor der Testausführung abgeschlossen sein.",
      "d": "FALSCH<br><br> Fehlerzustände werden typischerweise während der Testausführung gemeldet, basierend auf den gefundenen Fehlerwirkungen, so dass die Kosten für das Finden des nächsten Fehlerzustands nur während der Testausführung verfügbar sind."
    }
  },
  {
    "frage": "Welche folgenden Faktoren können zur Bestimmung der Risikostufe herangezogen werden?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Testen und Entwicklung",
      "b": "Dynamisch und reaktiv",
      "c": "Stellungnahme und Entscheidung",
      "d": "Eintrittswahrscheinlichkeit und Auswirkungen"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br> Die Höhe des Risikos wird durch die Wahrscheinlichkeit des Eintretens eines unerwünschten Ereignisses und die Auswirkungen (den Schaden) dieses Ereignisses bestimmt.<br><br>Daher ist die Option d) KORREKT.",
      "b": "FALSCH<br><br> Die Höhe des Risikos wird durch die Wahrscheinlichkeit des Eintretens eines unerwünschten Ereignisses und die Auswirkungen (den Schaden) dieses Ereignisses bestimmt.<br><br>Daher ist die Option d) KORREKT.",
      "c": "FALSCH<br><br> Die Höhe des Risikos wird durch die Wahrscheinlichkeit des Eintretens eines unerwünschten Ereignisses und die Auswirkungen (den Schaden) dieses Ereignisses bestimmt.<br><br>Daher ist die Option d) KORREKT.",
      "d": "KORREKT<br><br> Die Höhe des Risikos wird durch die Wahrscheinlichkeit des Eintretens eines unerwünschten Ereignisses und die Auswirkungen (den Schaden) dieses Ereignisses bestimmt.<br><br>Daher ist die Option d) KORREKT."
    }
  },
  {
    "frage": "Sie arbeiten als Projektleiter an einem bankinternen Softwareprojekt. Um Nacharbeit und übermäßige „Fehlerfindungszyklen / Fehlerbehebungszyklen / Fehlernachtestzyklen“ (Find/Fix/Retest) zu vermeiden, wurde der folgende Prozess zur Behebung eines Fehlers eingeführt, sobald dieser im Testlabor gefunden wurde:<br><ol style=\"list-style-type: lower-alpha;\"><li>Der zugewiesene Entwickler findet und behebt den Fehler und erstellt dann einen experimentellen Build.</li><li>Ein Peer-Entwickler überprüft, testet und bestätigt die Fehlerbehebung auf seinem Desktop</li><li>Ein Tester - in der Regel derjenige, der den Fehler gefunden hat - bestätigt die Fehlerbehebung durch einen Test in der Entwicklungsumgebung</li><li>Einmal am Tag wird ein neues Release mit allen bestätigten Fehlerkorrekturen in der Testumgebung installiert</li><li>Derselbe Tester aus Schritt c testet die Fehlerbehebung in der Testumgebung</li></ol>Trotzdem fällt eine große Anzahl von Fehlerzuständen, die die Tester in der Entwicklungsumgebung (in Schritt c) als behoben bestätigt haben, irgendwie bei den Fehlernachtests in der Testumgebung durch, mit den daraus resultierenden Nacharbeiten und Auswirkungen auf die Zykluszeiten. Sie haben höchstes Vertrauen in Ihre Tester und haben Fehler oder Auslassungen in Schritt c ausgeschlossen.<br><br>Welcher der folgenden Punkte ist der wahrscheinlichste Teil des Prozesses, der als nächstes überprüft werden sollte?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Die Aktivität von Entwicklern, die in Schritt b möglicherweise nicht ausreichend getestet wurde",
      "b": "Die Aktivität von Testern, die möglicherweise unklar darüber sind, was in Schritt e zu testen ist",
      "c": "Konfigurationsmanagement, das möglicherweise die Integrität des Produkts in Schritt d nicht aufrecht erhält",
      "d": "Die Aktivität von Entwicklern, die die Fehler in Schritt a möglicherweise nicht korrekt beheben"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Wenn unzureichende Entwicklertests das Problem wären, würde der Fehlernachtests in Schritt 3 nicht bestehen.",
      "b": "FALSCH<br><br>Derselbe Tester, der den Fehlernachtests in Schritt 3 erfolgreich durchgeführt hat, wiederholt ihn in Schritt 5.",
      "c": "KORREKT<br><br>Das Konfigurationsmanagement bewahrt die Integrität der Software. Wenn ein Test, der in Schritt 3 bestanden wurde, in Schritt 5 fehlschlägt, dann ist etwas zwischen diesen beiden Schritten anders. Ein möglicher Unterschied ist das Testobjekt, die hier aufgeführte Option. Ein weiterer möglicher Unterschied ist der zwischen der Entwicklungsumgebung und der Testumgebung, aber das ist keine hier aufgeführte Option.",
      "d": "FALSCH<br><br>Wenn die Entwickler den Fehler nicht beheben würden, würde der Fehlernachtest in Schritt 3 nicht erfolgreich sein."
    }
  },
  {
    "frage": "Sie sind mit der Planung des Testaufwands für eine neue mobile Banking Anwendung beschäftigt. Im Rahmen der Schätzung treffen Sie sich zunächst mit den vorgeschlagenen Testern und anderen Mitarbeitern des Projekts. Das Team ist gut eingespielt und hat bereits an ähnlichen Projekten gearbeitet. Um die resultierende Schätzung zu verifizieren, beziehen Sie sich dann auf einige Branchendurchschnittswerte für Testaufwand und -kosten bei ähnlichen Projekten, die von einem renommierten Berater veröffentlicht wurden.<br><br>Welche Aussage beschreibt Ihren Schätzungsansatz genau?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Ein gleichzeitiger expertenbasierter und metrikbasierter Ansatz",
      "b": "In erster Linie ein expertenbasierter Ansatz, ergänzt durch einen metrikbasierten Ansatz",
      "c": "In erster Linie ein metrikbasierter Ansatz, ergänzt durch einen expertenbasierten Ansatz",
      "d": "Primär Planungspoker, geprüft durch Geschwindigkeit aus Burndown-Charts"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Die beiden Methoden werden nacheinander verwendet, nicht gleichzeitig.",
      "b": "KORREKT<br><br>Die primären Informationsquellen stammen von den erfahrenen Testern, die die Experten sind. Die Branchendurchschnittswerte des Beraters ergänzen die ursprüngliche Schätzung aus veröffentlichten Metriken.",
      "c": "FALSCH<br><br>Der expertenbasierte Ansatz ist der primäre Ansatz, der durch einen metrikbasierten Ansatz ergänzt wird.",
      "d": "FALSCH<br><br>Wir wissen nicht, ob dieses Projekt agilen Methoden folgt, und Burndown Charts stammen nicht von externen Beratern."
    }
  },
  {
    "frage": "Während eines Projekts mit agilen Methoden stellen Sie einen Widerspruch zwischen der Interpretation eines Abnahmekriteriums durch den Entwickler und der Interpretation des Product Owners fest, die Sie während einer User-Story-Verfeinerungssession zur Sprache bringen.<br><br>Welcher der folgenden Punkte ist ein Vorteil der Testunabhängigkeit, der in dieser Situation deutlich wird?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Erkennen von verschiedenen Arten von Fehlern",
      "b": "Übernahme der Hauptverantwortung für die Qualität",
      "c": "Einen Fehlerzustand frühzeitig beheben",
      "d": "Annahmen der Stakeholder in Frage stellen"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Während das Erkennen verschiedener Arten von Fehlern ein Vorteil der Unabhängigkeit des Testens ist, gibt es in dem Szenario hier noch keinen Code, der fehlschlagen kann, und das Problem ist, dass der Entwickler und der Product Owner beide unterschiedliche Dinge über die Abnahmekriterien annehmen.",
      "b": "FALSCH<br><br>Der Verlust des Verantwortungsbewusstseins der Entwickler für die Qualität ist ein Nachteil, kein Vorteil",
      "c": "FALSCH<br><br>Während der Effekt der Entdeckung dieser Unstimmigkeit die frühere Beseitigung des Fehlerzustands ist, können Fehlerzustände vor der Codierung von verschiedenen Personen frühzeitig entdeckt werden, nicht nur von unabhängigen Testern.",
      "d": "KORREKT<br><br>Die Annahmen der Stakeholder in Frage zu stellen, ist ein Vorteil der Unabhängigkeit des Testers, und hier gehen sowohl der Entwickler als auch der Product Owner von unterschiedlichen Annahmen bezüglich der Abnahmekriterien aus."
    }
  },
  {
    "frage": "Sie definieren den Prozess für die Durchführung der Produktrisikoanalyse als Teil jeder Iteration in einem agilen Projekt.<br><br>Welche der folgenden Stellen ist die KORREKTE, um diesen Prozess in einem Testkonzept zu dokumentieren?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Umfang des Testens",
      "b": "Testvorgehensweise",
      "c": "Testmetriken",
      "d": "Konfigurationsmanagement des Testobjekts"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Während der Umfang ein Thema ist, das in einem Testkonzept angesprochen wird, ist die Implementierung einer risikobasierten Teststrategie in diesem Projekt die allgemeine Testvorgehensweise, daher sollte dieses Thema in diesem Abschnitt angesprochen werden.",
      "b": "KORREKT<br><br>Die Testvorgehensweise ist ein Thema, das in einem Testkonzept angesprochen wird, und die Implementierung einer risikobasierten Teststrategie in diesem Projekt ist die allgemeine Testvorgehensweise.",
      "c": "FALSCH<br><br>Während Metriken für die Testüberwachung und -steuerung ein Thema sind, das in einem Testkonzept behandelt wird, ist die Implementierung einer risikobasierten Teststrategie in diesem Projekt die allgemeine Testvorgehensweise, daher sollte dieses Thema in diesem Abschnitt behandelt werden.",
      "d": "FALSCH<br><br>Konfigurationsmanagement ist kein Thema, das in einem Testkonzept angesprochen wird."
    }
  },
  {
    "frage": "Betrachten Sie die folgende Liste von unerwünschten Ergebnissen, die bei der Entwicklung einer mobilen App auftreten können:<br><ol style=\"list-style-type: upper-alpha;\"><li>Falsche Summe wird auf dem Display angezeigt</li><li>Änderung der Abnahmekriterien während des Abnahmetests</li><li>Benutzer empfinden die Soft-Tastatur als zu schwer zu bedienen für die Verwendung mit Ihrer App</li><li>System reagiert zu langsam auf Benutzereingaben bei der Suchstring-Eingabe</li><li>Tester dürfen in täglichen Standup-Meetings nicht über Testergebnisse berichten</li></ol>Welche der folgenden Aussagen klassifiziert diese Ergebnisse KORREKT als Projekt- und Produktrisiken?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Produktrisiken: B, E; Projekt-Risiken: A, C, D",
      "b": "Produktrisiken: A, C, D; Projektrisiken: B, E",
      "c": "Produktrisiken: A, C, D, E; Projektrisiken: B",
      "d": "Produktrisiken: A, C; Projektrisiken: B, D, E"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br> Diese Liste ist völlig verkehrt<br><br>Begründung:<br><br>Produktrisiken bestehen, wenn ein Arbeitsprodukt möglicherweise nicht den legitimen Anforderungen entspricht, während Projektrisiken Situationen sind, die sich negativ auf die Fähigkeit des Projekts auswirken könnten, seine Ziele zu erreichen. Also:<br><ol style=\"list-style-type: upper-alpha;\"><li>Falsche Summen auf Berichten = Produktrisiko</li><li>Änderung der Abnahmekriterien während der Abnahmeprüfung = Projektrisiko</li><li>Benutzer empfinden die Soft-Tastatur als zu schwer für die Verwendung mit Ihrer App = Produktrisiko</li><li>System reagiert zu langsam auf Benutzereingaben bei der Suchstring-Eingabe = Produktrisiko</li><li>Tester dürfen Testergebnisse nicht in täglichen Standup-Meetings melden = Projektrisiko<br><br>Deshalb ist b) korrekt.",
      "b": "KORREKT<br><br> Begründung:<br><br>Produktrisiken bestehen, wenn ein Arbeitsprodukt möglicherweise nicht den legitimen Anforderungen entspricht, während Projektrisiken Situationen sind, die sich negativ auf die Fähigkeit des Projekts auswirken könnten, seine Ziele zu erreichen. Also:<br><ol style=\"list-style-type: upper-alpha;\"><li>Falsche Summen auf Berichten = Produktrisiko</li><li>Änderung der Abnahmekriterien während der Abnahmeprüfung = Projektrisiko</li><li>Benutzer empfinden die Soft-Tastatur als zu schwer für die Verwendung mit Ihrer App = Produktrisiko</li><li>System reagiert zu langsam auf Benutzereingaben bei der Suchstring-Eingabe = Produktrisiko</li><li>Tester dürfen Testergebnisse nicht in täglichen Standup-Meetings melden = Projektrisiko</li></ol>",
      "c": "FALSCH<br><br> Während es bei e um Produktqualität und Produktrisiken geht, ist das Versäumnis, Testergebnisse zu kommunizieren, laut Lehrplan ein Projektrisiko.<br><br>Begründung:<br><br>Produktrisiken bestehen, wenn ein Arbeitsprodukt möglicherweise nicht den legitimen Anforderungen entspricht, während Projektrisiken Situationen sind, die sich negativ auf die Fähigkeit des Projekts auswirken könnten, seine Ziele zu erreichen. Also:<br><ol style=\"list-style-type: upper-alpha;\"><li>Falsche Summen auf Berichten = Produktrisiko</li><li>Änderung der Abnahmekriterien während der Abnahmeprüfung = Projektrisiko</li><li>Benutzer empfinden die Soft-Tastatur als zu schwer für die Verwendung mit Ihrer App = Produktrisiko</li><li>System reagiert zu langsam auf Benutzereingaben bei der Suchstring-Eingabe = Produktrisiko</li><li>Tester dürfen Testergebnisse nicht in täglichen Standup-Meetings melden = Projektrisiko<br><br>Deshalb ist b) korrekt.",
      "d": "FALSCH<br><br> Produktrisiken können funktional und nicht-funktional sein, daher ist diese Option auch ein Produktrisiko.<br><br>Begründung:<br><br>Produktrisiken bestehen, wenn ein Arbeitsprodukt möglicherweise nicht den legitimen Anforderungen entspricht, während Projektrisiken Situationen sind, die sich negativ auf die Fähigkeit des Projekts auswirken könnten, seine Ziele zu erreichen. Also:<br><ol style=\"list-style-type: upper-alpha;\"><li>Falsche Summen auf Berichten = Produktrisiko</li><li>Änderung der Abnahmekriterien während der Abnahmeprüfung = Projektrisiko</li><li>Benutzer empfinden die Soft-Tastatur als zu schwer für die Verwendung mit Ihrer App = Produktrisiko</li><li>System reagiert zu langsam auf Benutzereingaben bei der Suchstring-Eingabe = Produktrisiko</li><li>Tester dürfen Testergebnisse nicht in täglichen Standup-Meetings melden = Projektrisiko<br><br>Deshalb ist b) korrekt."
    }
  },
  {
    "frage": "Sie haben gerade ein Pilotprojekt für ein Regressionstest-Werkzeug abgeschlossen. Sie verstehen das Werkzeug viel besser und haben Ihren Testprozess darauf abgestimmt. Sie haben einen standardisierten Ansatz für die Verwendung des Werkzeugs und der zugehörigen Arbeitsprodukte entwickelt.<br><br>Welcher der folgenden Aussagen ist ein typisches Ziel eines Testautomatisierungsprojekts bzw. Pilotprojekts, das noch verwirklicht werden muss?<br><br>Wählen Sie EINE Option aus.",
    "inhalte": [],
    "antworten": {
      "a": "Erfahren Sie mehr Details über das Werkzeug",
      "b": "Prüfen Sie, wie das Werkzeug in bestehende Prozesse und Praktiken passen würde",
      "c": "Entscheiden Sie sich für Standardverfahren zur Verwendung, Verwaltung, Speicherung und Pflege des Werkzeugs und der Test-Assets",
      "d": "Beurteilen Sie, ob der Nutzen zu vertretbaren Kosten erreicht werden kann"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br> Dies ist ein Ziel für einen Piloten, aber Sie haben es erreicht, weil Sie das Werkzeug durch den Piloten viel besser verstehen.",
      "b": "FALSCH<br><br> Dies ist ein Ziel für einen Piloten, aber Sie haben es erreicht, weil Sie Ihre Testprozesse maßgeschneidert haben.",
      "c": "FALSCH<br><br> Dies ist ein Ziel für einen Piloten, aber Sie haben es erreicht, weil Sie einen Ansatz zur Verwendung des Werkzeugs und der damit verbundenen Arbeitsprodukte standardisiert haben.",
      "d": "KORREKT<br><br> Die Bewertung der Vorteile sowie die Konfiguration der Erfassung von Metriken sind die beiden Ziele, die in dieser Liste fehlen."
    }
  },
  {
    "frage": "Welches der folgenden Werkzeuge ist am nützlichsten für das Reporting von Testmetriken?",
    "inhalte": [],
    "antworten": {
      "a": "Testmanagementwerkzeug",
      "b": "Werkzeug zur statischen Analyse",
      "c": "Überdeckungswerkzeug",
      "d": "Testwerkzeuge für das modellbasierte Testen"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br> Testmanagementwerkzeuge unterstützen die mit dem Testmanager verbundenen Aktivitäten einschließlich Metriken.",
      "b": "FALSCH<br><br> Metriken der statischen Code-Analyse würden sich nur auf den Code beziehen, nicht auf das Testen als Ganzes",
      "c": "FALSCH<br><br> Diese Werkzeuge berichten nur über die Testbasis-Überdeckung und die Codeüberdeckung, nicht über das Testen als Ganzes.",
      "d": "FALSCH<br><br> Testwerkzeuge für das modellbasierte Testen konzentrieren sich auf einen bestimmten Bereich, nicht auf das Testen als Ganzes."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen ist die korrekte Definition des Begriffes „Testfall“?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Teilmenge des Wertebereichs innerhalb einer Komponente oder eines Systems, für die aufgrund der Spezifikation erwartet wird, dass alle Werte gleichartig behandelt werden.",
      "b": "Menge von Vorbedingungen, Eingaben, Aktionen, erwarteten Ergebnissen und Nachbedingungen, welche auf Basis von Testbedingungen entwickelt wurden.",
      "c": "Arbeitsergebnis, welches während des Testprozesses erstellt wird und dazu gebraucht wird, um die Tests zu planen, zu entwerfen, auszuführen,auszuwerten und darüber zu berichten.",
      "d": "Informationsquelle zur Ermittlung des erwarteten Ergebnisses, um es mit dem tatsächlichen Ergebnis eines Systems unter Test zu vergleichen."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Begründung: Basierend auf der Definition Äquivalenzklasse aus dem Glossar 3.3.<br><br>(CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Eine Teilmenge des Wertebereichs einer Variablen innerhalb einer Komponente oder eines Systems, für die aufgrund der Spezifikation erwartet wird, dass alle Werte gleichartig behandelt werden.<br><br>Aus diesem Grund ist Antwort b) korrekt.",
      "b": "KORREKT<br><br>Begründung: Basierend auf einer Definition Testfall aus dem Glossar 3.3.<br><br>(CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Eine Menge von Vorbedingungen, Eingaben, Aktionen (falls anwendbar), erwarteten Ergebnissen und Nachbedingungen, welche auf Basis von Testbedingungen entwickelt wurden.",
      "c": "FALSCH<br><br>Begründung: Basierend auf der Glossardefinition Testmittel (Glossar 3.3).<br><br>(CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die Arbeitsergebnisse, die während des Testprozesses erstellt werden und dazu gebraucht werden, um die Tests zu planen, zu entwerfen, auszuführen, auszuwerten und darüber zu berichten.<br><br>Aus diesem Grund ist Antwort b) korrekt.",
      "d": "FALSCH<br><br>Begründung: Basierend auf der Definition des Begriffs Testorakel (Glossar 3.3)<br><br>(CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Eine Informationsquelle zur Ermittlung des erwarteten Ergebnisses, um es mit dem tatsächlichen Ergebnis eines Systems unter Test zu vergleichen.<br><br>Aus diesem Grund ist Antwort b) korrekt."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen ist ein typisches Ziel des Testens von Software?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Fehlerwirkungen und Fehlerzustände aufdecken",
      "b": "Validierung von Projektplänen",
      "c": "Sicherstellen von vollständigen Tests",
      "d": "Vergleich der Istergebnisse mit den erwarteten Ergebnissen"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Eines der typischen Hauptziele des Testens aus dem Lehrplan (1.1.1).<br><br>(CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Für jedes mögliche Projekt können die Ziele des Testens Folgendes beinhalten:<br><br><ol style=\"list-style-type: circle;\"><li>Arbeitsergebnisse wie Anforderungen, User-Stories, Architekturdesign und Code bewerten, um Fehler zu identifizieren und in Folgearbeitsergebnissen zu vermeiden</li><li>Verifizieren, ob alle spezifischen Anforderungen erfüllt sind</li><li>Prüfen, ob das Testobjekt vollständig ist und validieren, ob das Testobjekt so funktioniert, wie es die Benutzer und andere Stakeholder erwarten</li><li>Vertrauen in das Qualitätsniveau des Testobjekts schaffen</li><li>Fehlerwirkungen und Fehlerzustände aufdecken, wodurch man Risiken aufgrund einer unzureichenden Softwarequalität reduziert</li><li>Stakeholdern ausreichende Informationen zur Verfügung stellen, damit diese fundierte Entscheidungen treffen können, insbesondere bezüglich des Qualitätsniveaus des Testobjekts</li><li>Konform mit vertraglichen, rechtlichen oder regulatorischen Anforderungen oder Standards zu sein und/oder um die Konformität (compliance) des Testobjekts mit diesen Anforderungen oder Standards zu verifizieren</li></ol>Die Ziele des Testens können abhängig vom Kontext der zu testenden Komponente oder des Systems, das getestet wird, von der Teststufe und dem Softwareentwicklungslebenszyklus-Modell variieren. Diese Unterschiede können zum Beispiel Folgendes beinhalten:<ol style=\"list-style-type: circle;\"><li>Während des Komponententests kann es ein Ziel sein, so viele Fehlerwirkungen wie möglich zu finden, damit die zugrunde liegenden Fehlerzustände frühzeitig identifiziert und behoben werden. Ein weiteres Ziel kann es sein, die Codeüberdeckung durch Komponententests zu erhöhen.</li><li>Während des Abnahmetests kann es ein Ziel sein, zu bestätigen, dass das System so funktioniert wie erwartet und die Anforderungen erfüllt wurden. Ein weiteres Ziel dieses Tests kann darin bestehen, Stakeholdern Informationen über das Risiko einer Systemfreigabe zu einem festgelegten Zeitpunkt zu geben.",
      "b": "FALSCH<br><br>Die Validierung des Projektplans ist eine Projektmanagementaktivität.",
      "c": "FALSCH<br><br>Widerspruch zum Grundsatz 2; Vollständiges Testen ist nicht möglich.<br><br>(CTFL CORE Syllabus 2018, V.3.1; Abschnitt 1.3)<br><br>2. Vollständiges Testen ist nicht möglich<br><br>Ein vollständiger Test, bei dem alle möglichen Eingabewerte und deren Kombinationen unter Berücksichtigung aller unterschiedlichen Vorbedingungen ausgeführt werden, ist nicht durchführbar, mit Ausnahme von sehr trivialen Testobjekten. Anstatt zu versuchen, vollständig zu testen, sollten Risikoanalyse, Testverfahren und Prioritäten genutzt werden, um den Testaufwand zu konzentrieren.",
      "d": "FALSCH<br><br>„Vergleich der Istergebnisse mit den erwarteten Ergebnissen“ ist eine Aktivität der Testdurchführung, aber kein Testziel.<br><br>(CTFL CORE Syllabus 2018, V.3.1; Abschnitt 1.4.2, Testdurchführung).<br><br>Testdurchführung<br><br>Während der Testdurchführung laufen Testsuiten in Übereinstimmung mit dem Testausführungsplan ab.<br><br>Die Testdurchführung beinhaltet die folgenden Hauptaktivitäten:<ol style=\"list-style-type: circle;\"><li>Aufzeichnung der IDs und Versionen des Testelements/der Testelemente oder des Testobjekts, des Testwerkzeugs/der Testwerkzeuge und Testmittel</li><li>Durchführung der Tests entweder manuell oder durch Nutzung von Testausführungswerkzeugen</li><li>Vergleich der Istergebnisse mit den erwarteten Ergebnissen</li><li>Analyse der Anomalien zur Feststellung ihrer wahrscheinlichen Ursachen (z.B. können Fehlerwirkungen aufgrund von Fehlerzuständen im Code entstehen, aber falsch positive Ergebnisse können ebenfalls auftreten; siehe Abschnitt 1.2.3 Fehlhandlungen, Fehlerzustände und Fehlerwirkungen)</li><li>Bericht über Fehlerzustände auf Grundlage der beobachteten Fehlerwirkungen (siehe Abschnitt 5.6 Fehlermanagement)</li><li>Aufzeichnung der Ergebnisse der Testdurchführung (z.B. bestanden, fehlgeschlagen, blockiert)</li><li>Wiederholung von Testaktivitäten entweder als Ergebnis einer Aktion aufgrund einer Anomalie oder als Teil der geplanten Tests (z.B. Durchführung eines korrigierten Tests, Fehlernachtests und/oder Regressionstests)</li><li>Verifizierung und Aktualisierung der bidirektionalen Verfolgbarkeit zwischen der Testbasis, den Testbedingungen, den Testfällen, den Testabläufen und den Testergebnissen</li></ol>"
    }
  },
  {
    "frage": "Welches der folgenden Beispiele ist eine Fehlerwirkung in einem Tempomat eines Autos?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Der Entwickler des Systems hat vergessen, Variablen nach einem Ausschneiden und Einfügen umzubenennen.",
      "b": "Nicht benötigter Code, der beim Rückwärtsfahren einen Alarm auslöst, wurde in das System aufgenommen.",
      "c": "Das System hält die eingestellte Geschwindigkeit nicht mehr ein, wenn die Radiolautstärke erhöht oder verringert wird.",
      "d": "Die System-Entwurfsspezifikation gibt die Geschwindigkeit falsch an."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Dies ist ein Beispiel für einen vom Entwickler begangenen Fehler (Fehlhandlung).",
      "b": "FALSCH<br><br>Dies ist ein Beispiel für einen Fehlerzustand (etwas, das im Code falsch ist und einen Fehler verursachen kann).",
      "c": "KORREKT<br><br>Dies ist eine Abweichung von der erwarteten Funktionalität - ein Tempomat sollte nicht von der Lautstärkeeinstellung des Radios betroffen sein.",
      "d": "FALSCH<br><br>Dies ist ein Beispiel für einen Defekt (Fehlerzustand in einer Spezifikation, die eine Fehlerwirkung verursachen kann, wenn gegen die Spezifikation anschließend implementiert wird)."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen ist eher ein Fehlerzustand als eine Grundursache für einen Fehlerzustand in einem Fitness-Tracker?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Der Anforderungsmanager war mit der Domäne des Fitnesstrainings nicht vertraut und ging zu Unrecht davon aus, dass die Benutzer die Herzschlag Frequenz in Schlägen pro Stunde ablesen wollen.",
      "b": "Der Tester des Smartphone-Interfaces war nicht im zustandsbasierten Testen geschult und hat daher einen signifikanten Fehler übersehen.",
      "c": "Eine vom Entwickler für die GPS-Funktion fehlerhaft implementierte Konfigurationsvariable kann während der Sommerzeit zu Standortproblemen führen.",
      "d": "Die Designerin der Benutzeroberfläche hat noch nie an tragbaren Geräten gearbeitet und missverstand deshalb die Auswirkungen von reflektiertem Sonnenlicht."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Die mangelnde Vertrautheit des Anforderungsmanagers mit der Fitnessdomäne ist eine Grundursache für einen Fehlerzustand.",
      "b": "FALSCH<br><br>Die fehlende Schulung des Testers im zustandsbasierten Testen war eine Grundursache für den Fehler.",
      "c": "KORREKT<br><br>Die fehlerhaft implementierte Konfigurationsvariable stellt einen Fehlerzustand in der Software des Fitness-Trackers dar, der zu Standortproblemen führen kann. Die Grundursache ist „Eine vom Entwickler für die GPS-Funktion fehlerhaft implementierte Konfigurationsvariable. (V.3.0)",
      "d": "FALSCH<br><br>Die mangelnde Erfahrung bei der Gestaltung von Benutzeroberflächen für tragbare Geräte ist eine Grundursache für einen Fehlerzustand."
    }
  },
  {
    "frage": "Als Ergebnis der Risikoanalyse werden mehr Tests auf die Bereiche des Systems unter Test angewendet, in denen die ersten Tests mehr Fehler als in den anderen Bereichen aufgedeckt haben.<br><br>Welcher der folgenden Grundsätze des Testens wird angewendet?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Vorsicht vor dem Pestizid-Paradoxon.",
      "b": "Das Testen ist kontextabhängig.",
      "c": "Trugschluss: Keine Fehler bedeutet brauchbares System.",
      "d": "Häufung von Fehlerzuständen."
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>„Vorsicht vor dem Pestizid-Paradoxon“ befasst sich mit dem erneuten Ausführen der gleichen Tests und der Verringerung ihrer Wirksamkeit bei der Fehlersuche.",
      "b": "FALSCH<br><br>– Dieses Prinzip des Testens befasst sich mit der Durchführung von Tests, die je nach Kontext unterschiedlich sind (z. B. Spiele vs. sicherheitskritisch).",
      "c": "FALSCH<br><br>Dieses Prinzip des Testens betrifft den Unterschied zwischen einem getesteten und einem festen System und einem validierten System. Keine \"Fehler\" bedeutet nicht, dass das System einsatzbereit ist.",
      "d": "KORREKT<br><br>Wenn eine Häufung von Fehlerzuständen identifiziert werden (Bereiche des Systems, die mehr Fehler enthalten als der Durchschnitt), sollte der Testaufwand auf diese Bereiche ausgerichtet sein."
    }
  },
  {
    "frage": "Gegeben seien die folgenden Listen von Testaktivitäten (A.-D.) und Testaufgaben (1.-4.):<ol style=\"list-style-type: upper-alpha;\"><li>Testentwurf</li><li>Testrealisierung</li><li>Testdurchführung</li><li>Testabschluss</li></ol><ol><li>Erfassung von Änderungsanforderungen für offene Fehlerberichte</li><li>Identifizierung von Testdaten zur Unterstützung der Testfälle</li><li>Priorisierung von Testabläufen und Vorbereitung von Testdaten</li><li>Analyse von Abweichungen, um deren Ursache zu ermitteln</li></ol>Welches ist die korrekte Paarung von Testaktivitäten und Testaufgaben?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "A-2, B-3, C-4, D-1",
      "b": "A-2, B-1, C-3, D-4",
      "c": "A-3, B-2, C-4, D-1",
      "d": "A-3, B-2, C-1, D-4"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br> Die korrekte Zuordnung von Testaktivitäten und Testaufgaben laut Lehrplan (1.4.2) ist:<ol style=\"list-style-type: upper-alpha;\"><li>Testentwurf – (2) Identifizierung von notwendigen Testdaten zur Unterstützung der Testbedingungen und Testfälle.</li><li>Testrealisierung – (3) Priorisierung von Testabläufen und Vorbereitung der Testdaten.</li><li>Testdurchführung – (4) Analyse von Abweichungen, um deren Ursache zu ermitteln.</li><li>Testabschluss – (1) Erfassung von Änderungsanforderungen für offene Fehlerberichte.</li></ol>",
      "b": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br> Die korrekte Zuordnung von Testaktivitäten und Testaufgaben laut Lehrplan (1.4.2) ist:<ol style=\"list-style-type: upper-alpha;\"><li>Testentwurf – (2) Identifizierung von notwendigen Testdaten zur Unterstützung der Testbedingungen und Testfälle.</li><li>Testrealisierung – (3) Priorisierung von Testabläufen und Vorbereitung der Testdaten.</li><li>Testdurchführung – (4) Analyse von Abweichungen, um deren Ursache zu ermitteln.</li><li>Testabschluss – (1) Erfassung von Änderungsanforderungen für offene Fehlerberichte.</li></ol>Aus diesem Grund ist Antwort a) korrekt.",
      "c": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br> Die korrekte Zuordnung von Testaktivitäten und Testaufgaben laut Lehrplan (1.4.2) ist:<ol style=\"list-style-type: upper-alpha;\"><li>Testentwurf – (2) Identifizierung von notwendigen Testdaten zur Unterstützung der Testbedingungen und Testfälle.</li><li>Testrealisierung – (3) Priorisierung von Testabläufen und Vorbereitung der Testdaten.</li><li>Testdurchführung – (4) Analyse von Abweichungen, um deren Ursache zu ermitteln.</li><li>Testabschluss – (1) Erfassung von Änderungsanforderungen für offene Fehlerberichte.</li></ol>Aus diesem Grund ist Antwort a) korrekt.",
      "d": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br> Die korrekte Zuordnung von Testaktivitäten und Testaufgaben laut Lehrplan (1.4.2) ist:<ol style=\"list-style-type: upper-alpha;\"><li>Testentwurf – (2) Identifizierung von notwendigen Testdaten zur Unterstützung der Testbedingungen und Testfälle.</li><li>Testrealisierung – (3) Priorisierung von Testabläufen und Vorbereitung der Testdaten.</li><li>Testdurchführung – (4) Analyse von Abweichungen, um deren Ursache zu ermitteln.</li><li>Testabschluss – (1) Erfassung von Änderungsanforderungen für offene Fehlerberichte.</li></ol>Aus diesem Grund ist Antwort a) korrekt."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen beschreibt AM BESTEN, wie ein Mehrwert durch Aufrechterhaltung und Wartung der Verfolgbarkeit zwischen Testbasis und Testartefakten erzielt wird?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Wartungstests können basierend auf Änderungen der ursprünglichen Anforderungen vollständig automatisiert werden.",
      "b": "Es kann festgestellt werden, ob ein neuer Testfall eine höhere Abdeckung der Anforderungen erreicht.",
      "c": "Testmanager können feststellen, welche Tester die Fehler mit dem höchsten Schweregrad gefunden haben.",
      "d": "Bereiche, die möglicherweise durch Seiteneffekte einer Änderung beeinflusst werden, können durch Regressionstests gezielt überprüft werden."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br> Die Verfolgbarkeit ermöglicht die Verknüpfung vorhandener Testfälle mit aktualisierten und gelöschten Anforderungen (obwohl keine neuen Anforderungen unterstützt werden), sie hilft jedoch nicht bei der Automatisierung von Wartungstests.",
      "b": "KORREKT<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Wenn alle Testfälle mit Anforderungen verknüpft sind, kann bei jeder Hinzufügung eines neuen Testfalls (mit Verfolgbarkeit) festgestellt werden, ob zuvor nicht abgedeckte Anforderungen durch den neuen Testfall abgedeckt werden.",
      "c": "FALSCH<br><br> Die Verfolgbarkeit zwischen Testbasis und Testartefakten liefert keine Informationen darüber, welche Tester Fehler mit hohem Schweregrad festgestellt haben, und selbst wenn diese Informationen ermittelt werden könnten, wäre dies von begrenztem Wert.",
      "d": "FALSCH<br><br> – Bereiche die durch eine Änderung DIREKT betroffen sind, können durch die Verfolgbarkeit identifiziert werden. Seiteneffekte betreffen jedoch die Bereiche welche NICHT DIREKT betroffen und damit NICHT VERFOLGBAR sind."
    }
  },
  {
    "frage": "Welche der folgenden Eigenschaften findet man EHER in der Denkweise eines Testers als in der Denkweise eines Entwicklers?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die Leistung eines Testers wächst und reift mit steigender Erfahrung.",
      "b": "Die Fähigkeit zu erkennen, was an Lösungen falsch sein könnte.",
      "c": "Gute Kommunikation mit Teammitgliedern.",
      "d": "Aufmerksamkeit für Details."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br> Sowohl Entwickler als auch Tester profitieren von Erfahrung.",
      "b": "KORREKT<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Entwickler sind häufig stärker am Entwurf und an der Erstellung von Lösungen interessiert als daran, darüber nachzudenken, was an diesen Lösungen falsch sein könnte (Siehe CTFL CORE Lehrplan 2018, Abschnitt 1.5.2).<br><br>1.5.2 Denkweisen von Testern und Entwicklern<br><br>Entwickler und Tester denken oft unterschiedlich. Das Hauptziel der Entwicklung ist es, ein Produkt zu entwerfen und zu erstellen. Wie schon zuvor erwähnt, beinhalten die Ziele des Testens die Verifizierung und Validierung des Produkts, das Finden von Fehlerzuständen vor Inbetriebnahme usw. Dies sind unterschiedliche Sets an Zielen, die unterschiedliche Denkweisen erfordern. Diese Denkweisen zusammenzuführen hilft dabei, ein höheres Maß an Produktqualität zu erreichen.<br><br>Eine Denkweise spiegelt die Annahmen und bevorzugten Methoden eines Menschen für die Entscheidungsfindung und Problemlösung wider. Die Denkweise eines Testers sollte Neugier, professionellen Pessimismus, einen kritischen Blick, Detailgenauigkeit und die Motivation zu guter und positiver Kommunikation und Beziehungen beinhalten. Die Denkweise eines Testers wächst und reift mit steigender Erfahrung.<br><br>Die Denkweise eines Entwicklers kann einige der Elemente der Denkweise eines Testers enthalten, aber erfolgreiche Entwickler sind häufig stärker am Entwurf und an der Erstellung von Lösungen interessiert als daran, darüber nachzudenken, was an diesen Lösungen falsch sein könnte. Darüber hinaus erschwert ihnen das Phänomen Bestätigungsfehler, sich der von ihnen selbst begangenen Fehlhandlungen bewusst zu werden.<br><br>Mit der richtigen Denkweise können Entwickler ihren eigenen Code testen. Unterschiedliche Softwareentwicklungslebenszyklus-Modelle weisen oft verschiedene Möglichkeiten auf, wie die Tester und Testaktivitäten organisiert werden. Die Durchführung einiger der Testaktivitäten von unabhängigen Testern erhöht die Effektivität der Fehlerfindung, was insbesondere bei großen, komplexen oder sicherheitskritischen Systemen von hoher Bedeutung ist. Unabhängige Tester bringen eine Sichtweise ein, die sich von denen der Autoren der Arbeitsergebnisse (d.h. Business-Analysten, Product Owner, Designer und Entwickler) unterscheidet, da sie andere kognitive Voreingenommenheiten als die Autoren haben.",
      "c": "FALSCH<br><br> Sowohl Entwickler als auch Tester sollten gute Kommunikationsfähigkeiten haben.",
      "d": "FALSCH<br><br> Sowohl Entwickler als auch Tester müssen auf Details achten."
    }
  },
  {
    "frage": "Betrachten Sie die folgenden Aussagen über die Beziehungen zwischen Softwareentwicklungsaktivitäten und Testaktivitäten im Softwareentwicklungslebenszyklus:<br><ol><li>Für jede Entwicklungsaktivität sollte es eine zugehörige Testaktivität geben.</li><li>Reviewaktivitäten sollten starten, sobald die finale Version der Dokumente verfügbar ist.</li><li>Testentwurf und Implementierung der Tests sollten während der entsprechenden Entwicklungsaktivitäten starten.</li><li>Testaktivitäten sollten schon in frühen Phasen des Softwareentwicklungslebenszyklus beginnen.</li></ol><br>Welche der folgenden Optionen zeigt KORREKT, welche dieser Aussagen wahr und welche falsch sind?<br><br>Wählen Sie genau EINE Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Wahr – 1, 2; FALSCH<br><br>3, 4",
      "b": "Wahr – 2, 3; FALSCH<br><br>1, 4",
      "c": "Wahr – 1, 2, 4; FALSCH<br><br>3",
      "d": "Wahr – 1, 4; FALSCH<br><br>2, 3"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Begründung:<ol><li>WAHR: „Für jede Entwicklungsaktivität sollte es eine zugehörige Testaktivität geben.“(siehe CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).</li><li>FALSCH: „Reviewaktivitäten sollten starten, sobald die finale Version der Dokumente verfügbar ist.“ Sie sollten starten, sobald erste Entwürfe dafür vorliegen, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.).</li><li>FALSCH: „Testentwurf und Implementierung der Tests sollten während der entsprechenden Entwicklungsaktivitäten starten.“– Testanalyse und Testentwurf sollten während der entsprechenden Entwicklungsaktivitäten beginnen, nicht die Testimplementierung, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)</li><li>WAHR: „Testaktivitäten sollten schon in frühen Phasen des Softwareentwicklungslebenszyklus beginnen.“ (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)</li></ol>Folglich ist d) korrekt.<br><br>2.1.1 Softwareentwicklung und Softwaretesten<br><br>Damit Testaktivitäten angemessen erfolgen können, ist es in der Rolle eines Testers eine wichtige Kompetenz, sich mit den gängigen Softwareentwicklungslebenszyklus-Modellen auszukennen.<br><br>In jedem Softwareentwicklungslebenszyklus-Modell gibt es mehrere Merkmale für gutes Testen:<ol style=\"list-style-type: circle;\"><li>Für jede Entwicklungsaktivität gibt es eine zugehörige Testaktivität.</li><li>Jede Teststufe hat ihre stufenspezifischen Ziele für den Test.</li><li>Für eine vorgegebene Teststufe beginnen Testanalyse und Testentwurf bereits während der zugehörigen Entwicklungsaktivität.</li><li>Tester nehmen an Diskussionen zur Definition und Verfeinerung von Anforderungen und des Entwurfs teil. Darüber hinaus sind sie am Review von Arbeitsergebnissen (z.B. Anforderungen, Architekturdesign, User-Stories usw.) beteiligt, sobald erste Entwürfe dafür vorliegen.</li></ol>Unabhängig davon, welches Softwareentwicklungslebenszyklus-Modell gewählt wird, sollten Testaktivitäten in Übereinstimmung mit dem Grundsatz des frühen Testens schon in frühen Phasen des Lebenszyklus beginnen.<br><br>Dieser Lehrplan kategorisiert verbreitete Softwareentwicklungslebenszyklus-Modelle wie folgt:<ol style=\"list-style-type: circle;\"><li>Sequenzielle Entwicklungsmodelle</li><li>Iterative und inkrementelle Entwicklungsmodelle</li></ol>Ein sequenzielles Entwicklungsmodell beschreibt den Softwareentwicklungsprozess als linearen, sequenziellen Ablauf von Aktivitäten. Das bedeutet, dass jede Phase im Entwicklungsprozess erst beginnen sollte, wenn die vorherige Phase abgeschlossen ist. Theoretisch gibt es keine Überlappung der Phasen. In der Praxis ist es aber von Nutzen, aus der folgenden Phase eine frühe Rückmeldung zu erhalten.<br><br>Im Wasserfallmodell werden die Entwicklungsaktivitäten (z.B. Anforderungsanalyse, Entwurf, Implementierung, Test) nacheinander abgeschlossen. In diesem Modell findet das Testen erst statt, nachdem alle anderen Entwicklungsaktivitäten abgeschlossen sind.<br><br>Anders als das Wasserfallmodell integriert das (allgemeine) V-Modell den Testprozess in den Entwicklungsprozess und realisiert so den Grundsatz des frühen Testens. Außerdem beinhaltet das V-Modell Teststufen, die zu jeder zugehörigen Entwicklungsphase in Bezug stehen, was das frühe Testen noch weiter unterstützt (für eine Beschreibung der Teststufen siehe Abschnitt 2.2 Teststufen). In diesem Modell findet die Durchführung der Tests, die zu der jeweiligen Teststufe gehören, sequenziell statt. In manchen Fällen kann es aber zu einer Überlappung kommen.<br><br>Sequenzielle Entwicklungsmodelle liefern Software, die das komplette Feature-Set enthält und benötigen typischerweise Monate oder Jahre für die Auslieferung an Stakeholder und Benutzer.<br><br>In der inkrementellen Entwicklung erfolgt die Festlegung der Anforderungen, der Entwurf, die Implementierung und das Testen eines Systems in Teilen, d.h., dass die Software-Features inkrementell anwachsen. Die Größe der Inkremente kann variieren. Einige Methoden haben größere und andere kleinere Inkremente. Ein Inkrement kann dabei so klein sein wie eine einzige Veränderung in einer Maske der Benutzungsoberfläche oder wie eine neue Abfrageoption.<br><br>Iterative Entwicklung findet insbesondere dann statt, wenn Gruppen von Features zusammen in einer Reihe von Zyklen, oft mit einer festgelegten Dauer, spezifiziert, entworfen, implementiert und getestet werden können. Iterationen können sowohl Änderungen von Leistungsmerkmalen umfassen, die in früheren Iterationen entwickelt wurden, als auch Änderungen am eigentlichen Projektumfang. Jede Iteration liefert hierbei so lange eine lauffähige Software, die eine wachsende Teilmenge des gesamten Feature-Sets darstellt, bis die endgültige Software geliefert oder die Entwicklung beendet ist.<br><br>Beispiele hierfür sind u.a.:<ol style=\"list-style-type: circle;\"><li>Rational Unified Process: Jede Iteration ist tendenziell relativ lang (z.B. zwei bis drei Monate) und die Inkremente der Features sind entsprechend groß (z.B. zwei oder drei Gruppen zusammengehörender Features).</li><li>Scrum: Jede Iteration ist tendenziell eher kurz (z.B. Stunden, Tage oder einige Wochen) und die Inkremente der Features sind entsprechend klein (z.B. einige Verbesserungen und/oder zwei oder drei neue Features).</li><li>Kanban: Implementierung mit Iterationen mit oder ohne festgelegten Länge. Sie liefert entweder eine einzige Verbesserung oder ein einziges vollständiges Feature oder Gruppen von Features zusammengefasst in einem Release.</li><li>Spiralmodell: Beinhaltet das Schaffen von experimentellen Inkrementen, von denen einige in den folgenden Iterationen stark überarbeitet oder sogar aufgegeben werden müssen.</li></ol>Komponenten oder Systeme, die unter Nutzung dieser Methoden entwickelt werden, beinhalten in der gesamten Entwicklung häufig Überlappung und iterative Teststufen. Idealerweise wird jedes Feature auf dem Weg zur Auslieferung auf mehreren Teststufen getestet. In manchen Fällen nutzen Teams eine kontinuierliche Auslieferung (continuous delivery) oder eine kontinuierliche Bereitstellung (continuous deployment) der Software. Beide beinhalten die Automatisierung von Tests auf mehreren Teststufen als Teil ihrer Delivery-Pipelines. Viele Entwicklungsbemühungen, die diese Methoden nutzen, beinhalten auch das Konzept der selbstorganisierenden Teams. Dieses Konzept verändert auch die Art und Weise, wie Tests organisiert werden, und die Beziehung zwischen Testern und Entwicklern.<br><br>Diese Methoden formen ein wachsendes System, das für die Endanwender Feature für Feature, Iteration für Iteration oder traditionell als Hauptrelease freigegeben werden kann. Je mehr das System wächst, desto wichtiger sind Regressionstests; unabhängig davon, ob die Softwareinkremente für Anwender freigegeben werden.<br><br>Im Gegensatz zu sequenziellen Modellen können iterative und inkrementelle Modelle in Wochen oder Tagen nutzbare Software liefern. Die vollständige Menge an Anforderungen können diese aber erst nach einer Reihe von Monaten oder sogar Jahren liefern.<br><br>Für weitere Informationen zum Softwaretesten im Kontext der agilen Entwicklung siehe ISTQB-AT, Black 2017, Crispin 2008 und Gregory 2015.",
      "b": "FALSCH<br><br>Begründung:<ol><li>WAHR: „Für jede Entwicklungsaktivität sollte es eine zugehörige Testaktivität geben.“(siehe CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).</li><li>FALSCH: „Reviewaktivitäten sollten starten, sobald die finale Version der Dokumente verfügbar ist.“ Sie sollten starten, sobald erste Entwürfe dafür vorliegen, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.).</li><li>FALSCH: „Testentwurf und Implementierung der Tests sollten während der entsprechenden Entwicklungsaktivitäten starten.“– Testanalyse und Testentwurf sollten während der entsprechenden Entwicklungsaktivitäten beginnen, nicht die Testimplementierung, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)</li><li>WAHR: „Testaktivitäten sollten schon in frühen Phasen des Softwareentwicklungslebenszyklus beginnen.“ (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)</li></ol>Folglich ist d) korrekt.<br><br>2.1.1 Softwareentwicklung und Softwaretesten<br><br>Damit Testaktivitäten angemessen erfolgen können, ist es in der Rolle eines Testers eine wichtige Kompetenz, sich mit den gängigen Softwareentwicklungslebenszyklus-Modellen auszukennen.<br><br>In jedem Softwareentwicklungslebenszyklus-Modell gibt es mehrere Merkmale für gutes Testen:<ol style=\"list-style-type: circle;\"><li>Für jede Entwicklungsaktivität gibt es eine zugehörige Testaktivität.</li><li>Jede Teststufe hat ihre stufenspezifischen Ziele für den Test.</li><li>Für eine vorgegebene Teststufe beginnen Testanalyse und Testentwurf bereits während der zugehörigen Entwicklungsaktivität.</li><li>Tester nehmen an Diskussionen zur Definition und Verfeinerung von Anforderungen und des Entwurfs teil. Darüber hinaus sind sie am Review von Arbeitsergebnissen (z.B. Anforderungen, Architekturdesign, User-Stories usw.) beteiligt, sobald erste Entwürfe dafür vorliegen.</li></ol>Unabhängig davon, welches Softwareentwicklungslebenszyklus-Modell gewählt wird, sollten Testaktivitäten in Übereinstimmung mit dem Grundsatz des frühen Testens schon in frühen Phasen des Lebenszyklus beginnen.<br><br>Dieser Lehrplan kategorisiert verbreitete Softwareentwicklungslebenszyklus-Modelle wie folgt:<ol style=\"list-style-type: circle;\"><li>Sequenzielle Entwicklungsmodelle</li><li>Iterative und inkrementelle Entwicklungsmodelle</li></ol>Ein sequenzielles Entwicklungsmodell beschreibt den Softwareentwicklungsprozess als linearen, sequenziellen Ablauf von Aktivitäten. Das bedeutet, dass jede Phase im Entwicklungsprozess erst beginnen sollte, wenn die vorherige Phase abgeschlossen ist. Theoretisch gibt es keine Überlappung der Phasen. In der Praxis ist es aber von Nutzen, aus der folgenden Phase eine frühe Rückmeldung zu erhalten.<br><br>Im Wasserfallmodell werden die Entwicklungsaktivitäten (z.B. Anforderungsanalyse, Entwurf, Implementierung, Test) nacheinander abgeschlossen. In diesem Modell findet das Testen erst statt, nachdem alle anderen Entwicklungsaktivitäten abgeschlossen sind.<br><br>Anders als das Wasserfallmodell integriert das (allgemeine) V-Modell den Testprozess in den Entwicklungsprozess und realisiert so den Grundsatz des frühen Testens. Außerdem beinhaltet das V-Modell Teststufen, die zu jeder zugehörigen Entwicklungsphase in Bezug stehen, was das frühe Testen noch weiter unterstützt (für eine Beschreibung der Teststufen siehe Abschnitt 2.2 Teststufen). In diesem Modell findet die Durchführung der Tests, die zu der jeweiligen Teststufe gehören, sequenziell statt. In manchen Fällen kann es aber zu einer Überlappung kommen.<br><br>Sequenzielle Entwicklungsmodelle liefern Software, die das komplette Feature-Set enthält und benötigen typischerweise Monate oder Jahre für die Auslieferung an Stakeholder und Benutzer.<br><br>In der inkrementellen Entwicklung erfolgt die Festlegung der Anforderungen, der Entwurf, die Implementierung und das Testen eines Systems in Teilen, d.h., dass die Software-Features inkrementell anwachsen. Die Größe der Inkremente kann variieren. Einige Methoden haben größere und andere kleinere Inkremente. Ein Inkrement kann dabei so klein sein wie eine einzige Veränderung in einer Maske der Benutzungsoberfläche oder wie eine neue Abfrageoption.<br><br>Iterative Entwicklung findet insbesondere dann statt, wenn Gruppen von Features zusammen in einer Reihe von Zyklen, oft mit einer festgelegten Dauer, spezifiziert, entworfen, implementiert und getestet werden können. Iterationen können sowohl Änderungen von Leistungsmerkmalen umfassen, die in früheren Iterationen entwickelt wurden, als auch Änderungen am eigentlichen Projektumfang. Jede Iteration liefert hierbei so lange eine lauffähige Software, die eine wachsende Teilmenge des gesamten Feature-Sets darstellt, bis die endgültige Software geliefert oder die Entwicklung beendet ist.<br><br>Beispiele hierfür sind u.a.:<ol style=\"list-style-type: circle;\"><li>Rational Unified Process: Jede Iteration ist tendenziell relativ lang (z.B. zwei bis drei Monate) und die Inkremente der Features sind entsprechend groß (z.B. zwei oder drei Gruppen zusammengehörender Features).</li><li>Scrum: Jede Iteration ist tendenziell eher kurz (z.B. Stunden, Tage oder einige Wochen) und die Inkremente der Features sind entsprechend klein (z.B. einige Verbesserungen und/oder zwei oder drei neue Features).</li><li>Kanban: Implementierung mit Iterationen mit oder ohne festgelegten Länge. Sie liefert entweder eine einzige Verbesserung oder ein einziges vollständiges Feature oder Gruppen von Features zusammengefasst in einem Release.</li><li>Spiralmodell: Beinhaltet das Schaffen von experimentellen Inkrementen, von denen einige in den folgenden Iterationen stark überarbeitet oder sogar aufgegeben werden müssen.</li></ol>Komponenten oder Systeme, die unter Nutzung dieser Methoden entwickelt werden, beinhalten in der gesamten Entwicklung häufig Überlappung und iterative Teststufen. Idealerweise wird jedes Feature auf dem Weg zur Auslieferung auf mehreren Teststufen getestet. In manchen Fällen nutzen Teams eine kontinuierliche Auslieferung (continuous delivery) oder eine kontinuierliche Bereitstellung (continuous deployment) der Software. Beide beinhalten die Automatisierung von Tests auf mehreren Teststufen als Teil ihrer Delivery-Pipelines. Viele Entwicklungsbemühungen, die diese Methoden nutzen, beinhalten auch das Konzept der selbstorganisierenden Teams. Dieses Konzept verändert auch die Art und Weise, wie Tests organisiert werden, und die Beziehung zwischen Testern und Entwicklern.<br><br>Diese Methoden formen ein wachsendes System, das für die Endanwender Feature für Feature, Iteration für Iteration oder traditionell als Hauptrelease freigegeben werden kann. Je mehr das System wächst, desto wichtiger sind Regressionstests; unabhängig davon, ob die Softwareinkremente für Anwender freigegeben werden.<br><br>Im Gegensatz zu sequenziellen Modellen können iterative und inkrementelle Modelle in Wochen oder Tagen nutzbare Software liefern. Die vollständige Menge an Anforderungen können diese aber erst nach einer Reihe von Monaten oder sogar Jahren liefern.<br><br>Für weitere Informationen zum Softwaretesten im Kontext der agilen Entwicklung siehe ISTQB-AT, Black 2017, Crispin 2008 und Gregory 2015.",
      "c": "FALSCH<br><br>Begründung:<ol><li>WAHR: „Für jede Entwicklungsaktivität sollte es eine zugehörige Testaktivität geben.“(siehe CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).</li><li>FALSCH: „Reviewaktivitäten sollten starten, sobald die finale Version der Dokumente verfügbar ist.“ Sie sollten starten, sobald erste Entwürfe dafür vorliegen, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.).</li><li>FALSCH: „Testentwurf und Implementierung der Tests sollten während der entsprechenden Entwicklungsaktivitäten starten.“– Testanalyse und Testentwurf sollten während der entsprechenden Entwicklungsaktivitäten beginnen, nicht die Testimplementierung, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)</li><li>WAHR: „Testaktivitäten sollten schon in frühen Phasen des Softwareentwicklungslebenszyklus beginnen.“ (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)</li></ol>Folglich ist d) korrekt.<br><br>2.1.1 Softwareentwicklung und Softwaretesten<br><br>Damit Testaktivitäten angemessen erfolgen können, ist es in der Rolle eines Testers eine wichtige Kompetenz, sich mit den gängigen Softwareentwicklungslebenszyklus-Modellen auszukennen.<br><br>In jedem Softwareentwicklungslebenszyklus-Modell gibt es mehrere Merkmale für gutes Testen:<ol style=\"list-style-type: circle;\"><li>Für jede Entwicklungsaktivität gibt es eine zugehörige Testaktivität.</li><li>Jede Teststufe hat ihre stufenspezifischen Ziele für den Test.</li><li>Für eine vorgegebene Teststufe beginnen Testanalyse und Testentwurf bereits während der zugehörigen Entwicklungsaktivität.</li><li>Tester nehmen an Diskussionen zur Definition und Verfeinerung von Anforderungen und des Entwurfs teil. Darüber hinaus sind sie am Review von Arbeitsergebnissen (z.B. Anforderungen, Architekturdesign, User-Stories usw.) beteiligt, sobald erste Entwürfe dafür vorliegen.</li></ol>Unabhängig davon, welches Softwareentwicklungslebenszyklus-Modell gewählt wird, sollten Testaktivitäten in Übereinstimmung mit dem Grundsatz des frühen Testens schon in frühen Phasen des Lebenszyklus beginnen.<br><br>Dieser Lehrplan kategorisiert verbreitete Softwareentwicklungslebenszyklus-Modelle wie folgt:<ol style=\"list-style-type: circle;\"><li>Sequenzielle Entwicklungsmodelle</li><li>Iterative und inkrementelle Entwicklungsmodelle</li></ol>Ein sequenzielles Entwicklungsmodell beschreibt den Softwareentwicklungsprozess als linearen, sequenziellen Ablauf von Aktivitäten. Das bedeutet, dass jede Phase im Entwicklungsprozess erst beginnen sollte, wenn die vorherige Phase abgeschlossen ist. Theoretisch gibt es keine Überlappung der Phasen. In der Praxis ist es aber von Nutzen, aus der folgenden Phase eine frühe Rückmeldung zu erhalten.<br><br>Im Wasserfallmodell werden die Entwicklungsaktivitäten (z.B. Anforderungsanalyse, Entwurf, Implementierung, Test) nacheinander abgeschlossen. In diesem Modell findet das Testen erst statt, nachdem alle anderen Entwicklungsaktivitäten abgeschlossen sind.<br><br>Anders als das Wasserfallmodell integriert das (allgemeine) V-Modell den Testprozess in den Entwicklungsprozess und realisiert so den Grundsatz des frühen Testens. Außerdem beinhaltet das V-Modell Teststufen, die zu jeder zugehörigen Entwicklungsphase in Bezug stehen, was das frühe Testen noch weiter unterstützt (für eine Beschreibung der Teststufen siehe Abschnitt 2.2 Teststufen). In diesem Modell findet die Durchführung der Tests, die zu der jeweiligen Teststufe gehören, sequenziell statt. In manchen Fällen kann es aber zu einer Überlappung kommen.<br><br>Sequenzielle Entwicklungsmodelle liefern Software, die das komplette Feature-Set enthält und benötigen typischerweise Monate oder Jahre für die Auslieferung an Stakeholder und Benutzer.<br><br>In der inkrementellen Entwicklung erfolgt die Festlegung der Anforderungen, der Entwurf, die Implementierung und das Testen eines Systems in Teilen, d.h., dass die Software-Features inkrementell anwachsen. Die Größe der Inkremente kann variieren. Einige Methoden haben größere und andere kleinere Inkremente. Ein Inkrement kann dabei so klein sein wie eine einzige Veränderung in einer Maske der Benutzungsoberfläche oder wie eine neue Abfrageoption.<br><br>Iterative Entwicklung findet insbesondere dann statt, wenn Gruppen von Features zusammen in einer Reihe von Zyklen, oft mit einer festgelegten Dauer, spezifiziert, entworfen, implementiert und getestet werden können. Iterationen können sowohl Änderungen von Leistungsmerkmalen umfassen, die in früheren Iterationen entwickelt wurden, als auch Änderungen am eigentlichen Projektumfang. Jede Iteration liefert hierbei so lange eine lauffähige Software, die eine wachsende Teilmenge des gesamten Feature-Sets darstellt, bis die endgültige Software geliefert oder die Entwicklung beendet ist.<br><br>Beispiele hierfür sind u.a.:<ol style=\"list-style-type: circle;\"><li>Rational Unified Process: Jede Iteration ist tendenziell relativ lang (z.B. zwei bis drei Monate) und die Inkremente der Features sind entsprechend groß (z.B. zwei oder drei Gruppen zusammengehörender Features).</li><li>Scrum: Jede Iteration ist tendenziell eher kurz (z.B. Stunden, Tage oder einige Wochen) und die Inkremente der Features sind entsprechend klein (z.B. einige Verbesserungen und/oder zwei oder drei neue Features).</li><li>Kanban: Implementierung mit Iterationen mit oder ohne festgelegten Länge. Sie liefert entweder eine einzige Verbesserung oder ein einziges vollständiges Feature oder Gruppen von Features zusammengefasst in einem Release.</li><li>Spiralmodell: Beinhaltet das Schaffen von experimentellen Inkrementen, von denen einige in den folgenden Iterationen stark überarbeitet oder sogar aufgegeben werden müssen.</li></ol>Komponenten oder Systeme, die unter Nutzung dieser Methoden entwickelt werden, beinhalten in der gesamten Entwicklung häufig Überlappung und iterative Teststufen. Idealerweise wird jedes Feature auf dem Weg zur Auslieferung auf mehreren Teststufen getestet. In manchen Fällen nutzen Teams eine kontinuierliche Auslieferung (continuous delivery) oder eine kontinuierliche Bereitstellung (continuous deployment) der Software. Beide beinhalten die Automatisierung von Tests auf mehreren Teststufen als Teil ihrer Delivery-Pipelines. Viele Entwicklungsbemühungen, die diese Methoden nutzen, beinhalten auch das Konzept der selbstorganisierenden Teams. Dieses Konzept verändert auch die Art und Weise, wie Tests organisiert werden, und die Beziehung zwischen Testern und Entwicklern.<br><br>Diese Methoden formen ein wachsendes System, das für die Endanwender Feature für Feature, Iteration für Iteration oder traditionell als Hauptrelease freigegeben werden kann. Je mehr das System wächst, desto wichtiger sind Regressionstests; unabhängig davon, ob die Softwareinkremente für Anwender freigegeben werden.<br><br>Im Gegensatz zu sequenziellen Modellen können iterative und inkrementelle Modelle in Wochen oder Tagen nutzbare Software liefern. Die vollständige Menge an Anforderungen können diese aber erst nach einer Reihe von Monaten oder sogar Jahren liefern.<br><br>Für weitere Informationen zum Softwaretesten im Kontext der agilen Entwicklung siehe ISTQB-AT, Black 2017, Crispin 2008 und Gregory 2015.",
      "d": "KORREKT<br><br>Begründung:<ol><li>WAHR: „Für jede Entwicklungsaktivität sollte es eine zugehörige Testaktivität geben.“(siehe CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).</li><li>FALSCH: „Reviewaktivitäten sollten starten, sobald die finale Version der Dokumente verfügbar ist.“ Sie sollten starten, sobald erste Entwürfe dafür vorliegen, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.).</li><li>FALSCH: „Testentwurf und Implementierung der Tests sollten während der entsprechenden Entwicklungsaktivitäten starten.“– Testanalyse und Testentwurf sollten während der entsprechenden Entwicklungsaktivitäten beginnen, nicht die Testimplementierung, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)</li><li>WAHR: „Testaktivitäten sollten schon in frühen Phasen des Softwareentwicklungslebenszyklus beginnen.“ (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)</li></ol>Folglich ist d) korrekt<br><br>2.1.1 Softwareentwicklung und Softwaretesten<br><br>Damit Testaktivitäten angemessen erfolgen können, ist es in der Rolle eines Testers eine wichtige Kompetenz, sich mit den gängigen Softwareentwicklungslebenszyklus-Modellen auszukennen.<br><br>In jedem Softwareentwicklungslebenszyklus-Modell gibt es mehrere Merkmale für gutes Testen:<ol style=\"list-style-type: circle;\"><li>Für jede Entwicklungsaktivität gibt es eine zugehörige Testaktivität.</li><li>Jede Teststufe hat ihre stufenspezifischen Ziele für den Test.</li><li>Für eine vorgegebene Teststufe beginnen Testanalyse und Testentwurf bereits während der zugehörigen Entwicklungsaktivität.</li><li>Tester nehmen an Diskussionen zur Definition und Verfeinerung von Anforderungen und des Entwurfs teil. Darüber hinaus sind sie am Review von Arbeitsergebnissen (z.B. Anforderungen, Architekturdesign, User-Stories usw.) beteiligt, sobald erste Entwürfe dafür vorliegen.</li></ol>Unabhängig davon, welches Softwareentwicklungslebenszyklus-Modell gewählt wird, sollten Testaktivitäten in Übereinstimmung mit dem Grundsatz des frühen Testens schon in frühen Phasen des Lebenszyklus beginnen.<br><br>Dieser Lehrplan kategorisiert verbreitete Softwareentwicklungslebenszyklus-Modelle wie folgt:<ol style=\"list-style-type: circle;\"><li>Sequenzielle Entwicklungsmodelle</li><li>Iterative und inkrementelle Entwicklungsmodelle</li></ol>Ein sequenzielles Entwicklungsmodell beschreibt den Softwareentwicklungsprozess als linearen, sequenziellen Ablauf von Aktivitäten. Das bedeutet, dass jede Phase im Entwicklungsprozess erst beginnen sollte, wenn die vorherige Phase abgeschlossen ist. Theoretisch gibt es keine Überlappung der Phasen. In der Praxis ist es aber von Nutzen, aus der folgenden Phase eine frühe Rückmeldung zu erhalten.<br><br>Im Wasserfallmodell werden die Entwicklungsaktivitäten (z.B. Anforderungsanalyse, Entwurf, Implementierung, Test) nacheinander abgeschlossen. In diesem Modell findet das Testen erst statt, nachdem alle anderen Entwicklungsaktivitäten abgeschlossen sind.<br><br>Anders als das Wasserfallmodell integriert das (allgemeine) V-Modell den Testprozess in den Entwicklungsprozess und realisiert so den Grundsatz des frühen Testens. Außerdem beinhaltet das V-Modell Teststufen, die zu jeder zugehörigen Entwicklungsphase in Bezug stehen, was das frühe Testen noch weiter unterstützt (für eine Beschreibung der Teststufen siehe Abschnitt 2.2 Teststufen). In diesem Modell findet die Durchführung der Tests, die zu der jeweiligen Teststufe gehören, sequenziell statt. In manchen Fällen kann es aber zu einer Überlappung kommen.<br><br>Sequenzielle Entwicklungsmodelle liefern Software, die das komplette Feature-Set enthält und benötigen typischerweise Monate oder Jahre für die Auslieferung an Stakeholder und Benutzer.<br><br>In der inkrementellen Entwicklung erfolgt die Festlegung der Anforderungen, der Entwurf, die Implementierung und das Testen eines Systems in Teilen, d.h., dass die Software-Features inkrementell anwachsen. Die Größe der Inkremente kann variieren. Einige Methoden haben größere und andere kleinere Inkremente. Ein Inkrement kann dabei so klein sein wie eine einzige Veränderung in einer Maske der Benutzungsoberfläche oder wie eine neue Abfrageoption.<br><br>Iterative Entwicklung findet insbesondere dann statt, wenn Gruppen von Features zusammen in einer Reihe von Zyklen, oft mit einer festgelegten Dauer, spezifiziert, entworfen, implementiert und getestet werden können. Iterationen können sowohl Änderungen von Leistungsmerkmalen umfassen, die in früheren Iterationen entwickelt wurden, als auch Änderungen am eigentlichen Projektumfang. Jede Iteration liefert hierbei so lange eine lauffähige Software, die eine wachsende Teilmenge des gesamten Feature-Sets darstellt, bis die endgültige Software geliefert oder die Entwicklung beendet ist.<br><br>Beispiele hierfür sind u.a.:<ol style=\"list-style-type: circle;\"><li>Rational Unified Process: Jede Iteration ist tendenziell relativ lang (z.B. zwei bis drei Monate) und die Inkremente der Features sind entsprechend groß (z.B. zwei oder drei Gruppen zusammengehörender Features).</li><li>Scrum: Jede Iteration ist tendenziell eher kurz (z.B. Stunden, Tage oder einige Wochen) und die Inkremente der Features sind entsprechend klein (z.B. einige Verbesserungen und/oder zwei oder drei neue Features).</li><li>Kanban: Implementierung mit Iterationen mit oder ohne festgelegten Länge. Sie liefert entweder eine einzige Verbesserung oder ein einziges vollständiges Feature oder Gruppen von Features zusammengefasst in einem Release.</li><li>Spiralmodell: Beinhaltet das Schaffen von experimentellen Inkrementen, von denen einige in den folgenden Iterationen stark überarbeitet oder sogar aufgegeben werden müssen.</li></ol>Komponenten oder Systeme, die unter Nutzung dieser Methoden entwickelt werden, beinhalten in der gesamten Entwicklung häufig Überlappung und iterative Teststufen. Idealerweise wird jedes Feature auf dem Weg zur Auslieferung auf mehreren Teststufen getestet. In manchen Fällen nutzen Teams eine kontinuierliche Auslieferung (continuous delivery) oder eine kontinuierliche Bereitstellung (continuous deployment) der Software. Beide beinhalten die Automatisierung von Tests auf mehreren Teststufen als Teil ihrer Delivery-Pipelines. Viele Entwicklungsbemühungen, die diese Methoden nutzen, beinhalten auch das Konzept der selbstorganisierenden Teams. Dieses Konzept verändert auch die Art und Weise, wie Tests organisiert werden, und die Beziehung zwischen Testern und Entwicklern.<br><br>Diese Methoden formen ein wachsendes System, das für die Endanwender Feature für Feature, Iteration für Iteration oder traditionell als Hauptrelease freigegeben werden kann. Je mehr das System wächst, desto wichtiger sind Regressionstests; unabhängig davon, ob die Softwareinkremente für Anwender freigegeben werden.<br><br>Im Gegensatz zu sequenziellen Modellen können iterative und inkrementelle Modelle in Wochen oder Tagen nutzbare Software liefern. Die vollständige Menge an Anforderungen können diese aber erst nach einer Reihe von Monaten oder sogar Jahren liefern.<br><br>Für weitere Informationen zum Softwaretesten im Kontext der agilen Entwicklung siehe ISTQB-AT, Black 2017, Crispin 2008 und Gregory 2015."
    }
  },
  {
    "frage": "Ein durchgeführter Test hat folgende Eigenschaften:<br><ol style=\"list-style-type: circle;\"><li>Er basiert auf Schnittstellenspezifikationen.</li><li>Der Schwerpunkt liegt auf dem Finden von Fehlerwirkungen in der Kommunikation.</li><li>Die Testvorgehensweise wendet sowohl funktionale als auch strukturelle Testarten an.</li></ol>Auf welcher der folgenden Teststufen wird dieser Test AM WAHRSCHEINLICHSTEN durchgeführt?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Integrationstest",
      "b": "Abnahmetest",
      "c": "Systemtest",
      "d": "Komponententest"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Aufgrund der obigen Beschreibung und des CTFL Lehrplans 2018, Abschnitt 2.2 erkennt man:<br><ol style=\"list-style-type: circle;\"><li>„Er basiert auf Schnittstellenspezifikationen” – Die Testbasis für Integrationstests enthält die Spezifikationen von Schnittstellen (zusammen mit Kommunikationsprotokollen). Hingegen enthält keine der anderen angegebenen Teststufen diese Arbeitsergebnisse als Testbasis.</li><li>„Der Schwerpunkt liegt auf dem Finden von Fehlerwirkungen in der Kommunikation” –Fehlerwirkungen in der Kommunikation der getesteten Komponenten sind eine der typischen Fehlerarten, welche man beim Integrationstest findet, während diese Fehlerart bei keiner anderen der angegebenen Teststufen im Schwerpunkt liegt.</li><li>„Die Testvorgehensweise wendet sowohl funktionale als auch strukturelle Testarten an” –Funktionale und strukturelle Testarten sind beim Integrationstest beide als Vorgehensweise möglich, wie sie auch für jede andere Teststufe geeignet wären. Im Lehrplan werden sie allerdings nur noch beim Systemtest explizit erwähnt.</li></ol>Folglich ist Option a) richtig.<br><br>2.2 Teststufen<br><br> Teststufen sind Gruppen von Testaktivitäten, die gemeinsam organisiert und verwaltet werden. Jede Teststufe ist eine Instanz des Testprozesses, der aus Aktivitäten besteht, die in Abschnitt 1.4 Testprozess beschrieben wurden. Diese Testaktivitäten beziehen sich auf die Software einer festgelegten Entwicklungsstufe von einzelnen Einheiten oder Komponenten bis hin zu vollständigen Systemen oder, falls zutreffend, von Systemen von Systemen. Die Teststufen stehen mit anderen Aktivitäten innerhalb des Softwareentwicklungslebenszyklus in Verbindung. In diesem Lehrplan werden die folgenden Teststufen verwendet: <ol style=\"list-style-type: circle;\"><li>Komponententest</li> <li>Integrationstest</li> <li>Systemtest</li> <li>Abnahmetest</li> </ol>Teststufen sind durch die folgenden Eigenschaften gekennzeichnet: <ol style=\"list-style-type: circle;\"><li>Spezifische Ziele</li> <li>Testbasis, um mit Bezug darauf Testfälle abzuleiten</li><li>Testobjekt (d.h., was wird getestet)</li> <li>Typische Fehlerzustände und Fehlerwirkungen</li><li>Spezifische Ansätze und Verantwortlichkeiten</li></ol>Für jede Teststufe ist eine passende Testumgebung erforderlich. Für den Abnahmetest ist beispielsweise eine produktionsähnliche Umgebung ideal, während die Entwickler im Komponententest üblicherweise ihre eigene Entwicklungsumgebung nutzen.<br><br>2.2.1 Komponententest <br><br>Ziele des Komponententests <br><br>Der Komponententest (auch Unit- oder Modultest genannt) konzentriert sich auf Komponenten, die einzeln testbar sind. Die Ziele des Komponententests beinhalten:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen der Komponente dem Entwurf und der Spezifikation entsprechen</li><li>Schaffen von Vertrauen in die Qualität der Komponente</li><li>Finden von Fehlerzuständen in der Komponente</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen weitergegeben werden</li></ol>In manchen Fällen, insbesondere in inkrementellen und iterativen Entwicklungsmodellen (z.B. agilen Entwicklungsmodellen), in denen Codeänderungen stetig erfolgen, spielen automatisierte Komponentenregressionstests eine Schlüsselrolle. Diese sollen Vertrauen schaffen, dass Änderungen bestehende Komponenten nicht beschädigt haben.<br><br>Der Komponententest wird häufig isoliert vom Rest des Systems vorgenommen. In Abhängigkeit vom Softwareentwicklungslebenszyklus-Modell und vom System erfordert dies eventuell Mock-Objekte, Service-Virtualisierung, Rahmen, Platzhalter und Treiber. Der Komponententest kann die Funktionalität (z.B. die Korrektheit von Berechnungen), nicht-funktionale Eigenschaften (z.B. Suche nach Speicherengpässen) und strukturelle Merkmale (z.B. Entscheidungstests) abdecken.<br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Komponententests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>Feinentwurf</li><li>Code</li><li>Datenmodelle</li><li>Komponentenspezifikationen</li></ol>Testobjekte<br><br>Gängige Testobjekte für Komponententests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Komponenten, Units oder Module</li><li>Code und Datenstrukturen</li><li>Klassen</li><li>Datenbankmodule</li></ol>Gängige Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für gängige Fehlerzustände und Fehlerwirkungen für Komponententests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Nicht korrekte Funktionalität (z.B. nicht wie in den Entwurfsspezifikationen beschrieben)</li><li>Datenflussprobleme</li><li>Nicht korrekter Code und nicht korrekte Logik</li></ol>Fehlerzustände werden in der Regel behoben, sobald sie gefunden werden, oftmals ohne formales Fehlermanagement. Wenn Entwickler allerdings Fehlerzustände berichten, liefert dies wichtige Informationen für die Grundursachenanalyse und die Prozessverbesserung.<br><br>Spezifische Ansätze und Verantwortlichkeiten <br><br>Komponententests werden üblicherweise von dem Entwickler durchgeführt, der den Code geschrieben hat. Zumindest aber erfordert dies den Zugang zum Code, der getestet werden soll. Entwickler können zwischen der Entwicklung einer Komponente und dem Finden und Beheben von Fehlerzuständen wechseln. Entwickler schreiben oft Tests und führen diese aus, nachdem sie den Code für eine Komponente entwickelt haben. Insbesondere in der agilen Entwicklung kann es jedoch auch sein, dass das Schreiben von automatisierten Komponententestfällen dem Schreiben von Anwendungscode vorangeht.<br><br>Nehmen wir zum Beispiel die testgetriebene Entwicklung (test driven development, TDD). Die testgetriebene Entwicklung ist hoch iterativ und basiert auf Zyklen zur Entwicklung automatisierter Testfälle, dann erfolgt die Entwicklung und Integration kleiner Teile von Code, gefolgt von der Durchführung von Komponententests, der Korrektur möglicher Probleme und der Restrukturierung (Refactoring) von Code. Dieser Prozess setzt sich fort, bis die Komponente vollständig erstellt und alle Komponententests erfolgreich abgeschlossen sind. Die testgetriebene Entwicklung ist ein Beispiel für den Ansatz „test first“. Obwohl die testgetriebene Entwicklung ihren Ursprung im eXtreme Programming (XP) hat, hat sie sich auch in andere Formen der agilen und in sequenzielle Lebenszyklen verbreitet (siehe ISTQB-AT).<br><br>2.2.2 Integrationstest <br><br>Ziele von Integrationstests <br><br>Integrationstests konzentrieren sich auf die Interaktion zwischen Komponenten oder Systemen. Ziele der Integrationstests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen der Schnittstellen dem Entwurf und der Spezifikation entsprechen</li><li>Vertrauen schaffen in die Qualität der Schnittstellen</li><li>Fehlerzustände finden (die in den Schnittstellen selbst oder innerhalb der Komponenten oder des Systems liegen können)</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen weitergegeben werden</li></ol>Wie beim Komponententest liefern automatisierte Integrationsregressionstests in manchen Fällen das Vertrauen, dass Änderungen bestehende Schnittstellen, Komponenten oder Systeme nicht beschädigt haben.<br><br>In diesem Lehrplan wird der Test von zwei Integrationsstufen beschrieben, der auf Testobjekte unterschiedlicher Größe ausgeübt werden kann:<ol style=\"list-style-type: circle;\"><li>Komponentenintegrationstests konzentrieren sich auf die Interaktionen und die Schnittstellen zwischen integrierten Komponenten. Komponentenintegrationstests werden nach Komponententests durchgeführt und sind generell automatisiert. In der iterativen und inkrementellen Entwicklung sind Integrationstests in der Regel Teil des kontinuierlichen Integrationsprozesses (continuous integration).</li><li>Systemintegrationstests konzentrieren sich auf die Interaktionen und Schnittstellen zwischen Systemen, Paketen und Microservices. Systemintegrationstests können auch Interaktionen und Schnittstellen abdecken, die von externen Organisationen bereitgestellt werden (z.B. Webservices). In diesem Fall hat die entwickelnde Organisation keinen Einfluss auf die externen Schnittstellen. Dies kann zu verschiedenen Herausforderungen im Testen führen (z.B. Sicherstellen, dass testblockierende Fehlerzustände im Code der externen Organisation behoben sind, Bereitstellen von Testumgebungen usw.). Der Systemintegrationstest kann nach den Systemtests oder parallel zu andauernden Systemtestaktivitäten stattfinden (sowohl in der sequenziellen Entwicklung als auch in der iterativen und inkrementellen Entwicklung).</li></ol>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Integrationstests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>Software- und Systementwurf</li><li>Sequenzdiagramme</li><li>Spezifikationen von Schnittstellen und Kommunikationsprotokollen</li><li>Anwendungsfälle</li><li>Architektur auf Komponenten- oder Systemebene</li><li>Workflows</li><li>Externe Schnittstellendefinitionen</li></ol>Testobjekte <br><br>Gängige Testobjekte für Integrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Subsysteme</li><li>Datenbanken</li><li>Infrastruktur</li><li>Schnittstellen</li><li>APIs</li><li>Microservices</li></ol>Typische Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für typische Fehlerzustände und Fehlerwirkungen für Komponentenintegrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Falsche Daten, fehlende Daten oder falsche Datenverschlüsselung</li><li>Falsche Reihenfolge oder fehlerhafte zeitliche Abfolge von Schnittstellenaufrufen</li><li>Falsch angepasste Schnittstellen</li><li>Fehlerwirkungen in der Kommunikation zwischen Komponenten</li><li>Nicht behandelte oder nicht ordnungsgemäß behandelte Fehlerwirkungen in der Kommunikation</li><li>zwischen den Komponenten</li><li>Nicht korrekte Annahmen über die Bedeutung, Einheiten oder Grenzen der Daten, die zwischen den Komponenten hin- und hergereicht werden</li></ol>Beispiele typischer Fehlerzustände und Fehlerwirkungen für Systemintegrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Inkonsistente Nachrichtenstrukturen zwischen den Systemen</li><li>Falsche Daten, fehlende Daten oder falsche Datenverschlüsselung</li><li>Falsch angepasste Schnittstellen</li><li>Fehlerwirkungen in der Kommunikation zwischen den Systemen</li><li>Nicht behandelte oder nicht ordnungsgemäß behandelte Fehlerwirkungen in der Kommunikation zwischen den Systemen</li><li>Falsche Annahmen über die Bedeutung, Einheiten oder Grenzen der Daten, die zwischen den Systemen hin- und hergereicht werden</li><li>Fehlende Konformität mit erforderlichen Richtlinien zur IT-Sicherheit</li></ol>Spezifische Ansätze und Verantwortlichkeiten <br><br>Komponentenintegrationstests und Systemintegrationstests sollten sich auf die Integration selbst konzentrieren. Zum Beispiel, wenn das Modul A mit dem Modul B integriert wird, sollten sich die Tests auf die Kommunikation zwischen diesen Modulen konzentrieren und nicht auf die Funktionalität der einzelnen Module, da diese in den Komponententests abgedeckt sein sollte. Wenn System X mit System Y integriert wird, sollten sich die Tests auf die Kommunikation zwischen den Systemen konzentrieren, nicht auf die Funktionalität der einzelnen Systeme, da diese in den Systemtests abgedeckt sein sollte. Funktionale, nicht-funktionale und strukturelle Testarten sind geeignet. <br><br>Komponentenintegrationstests liegen häufig in der Verantwortung der Entwickler. Systemintegrationstests liegen im Allgemeinen in der Verantwortung der Tester. Idealerweise sollten Tester, die Systemintegrationstests durchführen, die Systemarchitektur verstehen und die Integrationsplanung beeinflusst haben. <br><br>Wenn Integrationstests und die Integrationsstrategie geplant werden, bevor Komponenten oder Systeme entwickelt werden, können diese Komponenten oder Systeme in der Reihenfolge entwickelt werden, die für das effizienteste Testen erforderlich ist. Systematische Integrationsstrategien können auf der Systemarchitektur (z.B. Top-down und Bottom-up), auf funktionellen Aufgaben, auf der Reihenfolge der Transaktionsverarbeitung oder auf anderen Aspekten des Systems oder der Komponenten basieren. Um die Isolation von Fehlerzuständen zu vereinfachen und Fehlerzustände früh zu erkennen, sollte die Integration normalerweise inkrementell erfolgen (d.h. nur eine kleine Anzahl von zusätzlichen Komponenten oder Systemen zur gleichen Zeit) statt in einer Art „Big Bang“ (d.h. Integration aller Komponenten oder Systeme in einem einzigen Schritt). Eine Risikoanalyse der komplexesten Schnittstellen kann dabei helfen, die Integrationstests zielgerichtet einzusetzen. <br><br>Je größer der Umfang der Integration, desto schwieriger wird es, die Fehlerzustände in einer spezifischen Komponente oder einem spezifischen System zu isolieren. Dies führt zu einem höheren Risiko und einem größeren Zeitaufwand für die Fehlerbehebung. Das ist ein Grund dafür, dass kontinuierliche Integration, bei der Software auf Komponentenbasis integriert wird (d.h. funktionale Integration), zur gängigen Vorgehensweise geworden ist. Eine derartige kontinuierliche Integration (continuous integration) beinhaltet häufig automatisierte Regressionstests, idealerweise auf mehreren Teststufen<br><br>2.2.3 Systemtest <br><br>Systemtests konzentrieren sich auf das Verhalten und die Fähigkeiten des Systems oder Produkts. Dies geschieht oft unter Berücksichtigung der End-to-End-Aufgaben, die das System leisten kann, und der nicht-funktionalen Verhaltensweisen, die bei der Verarbeitung dieser Aufgaben zu Tage treten. Ziele des Systemtests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen des Systems dem Entwurf und den Spezifikationen entsprechen</li><li>Validierung, dass das System vollständig ist und wie erwartet funktionieren wird</li><li>Vertrauen in die Qualität des Systems als Ganzes schaffen</li><li>Finden von Fehlerzuständen</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen oder in die Produktion weitergegeben werden</li></ol>Für einige Systeme kann auch die Verifizierung der Datenqualität ein Ziel sein. Wie beim Komponententest und beim Integrationstest bieten in einigen Fällen automatisierte Systemregressionstests die Gewissheit, dass Änderungen nicht die bestehenden Features oder End-to-End-Fähigkeiten beeinträchtigt haben.<br>Systemtests liefern häufig Informationen, die von Stakeholdern für Freigabeentscheidungen genutzt werden. Systemtests können auch zur Erfüllung rechtlicher oder regulatorischer Anforderungen oder Standards notwendig sein.<br><br>Die Testumgebung sollte idealerweise der finalen Ziel- oder der Produktivumgebung entsprechen. <br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Systemtests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>System- und Softwareanforderungsspezifikationen (funktional und nicht-funktional)</li><li>Risikoanalyseberichte</li><li>Anwendungsfälle</li><li>Epics und User-Stories</li><li>Modelle des Systemverhaltens</li><li>Zustandsdiagramme</li><li>System- und Benutzeranleitungen</li></ol>Testobjekte<br><br>Gängige Testobjekte für Systemtests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Anwendungen</li><li>Hardware/Softwaresysteme</li> <li>Betriebssysteme</li><li>Systeme unter Test (SUT)</li><li>Systemkonfiguration und Konfigurationsdaten</li></ol>Typische Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für typische Fehlerzustände und Fehlerwirkungen für Systemtests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Falsche Berechnungen</li><li>Falsche oder unerwartete funktionale oder nicht-funktionale Systemverhaltensweisen</li><li>Falsche Kontrollflüsse und/oder Datenflüsse innerhalb des Systems</li><li>Versagen bei der korrekten oder vollständigen Ausführung von funktionalen End-to-End-Aufgaben</li><li>Versagen des Systems bei der ordnungsgemäßen Arbeit in der/den Systemumgebung/en</li><li>Das System funktioniert nicht wie in den System- oder Benutzeranleitungen beschrieben</li></ol>Spezifische Ansätze und Verantwortlichkeiten <br><br>Systemtests sollten sich auf das allgemeine End-to-End-Verhalten des Systems als Ganzes konzentrieren, sowohl in funktionaler als auch in nicht-funktionaler Hinsicht. Systemtests sollten die Verfahren nutzen, die am besten für die zu testenden Aspekte des Systems geeignet sind (siehe Kapitel 4). Beispielsweise kann eine Entscheidungstabelle erstellt werden, um zu verifizieren, ob ein funktionales Verhalten den Beschreibungen in den Geschäftsregeln entspricht.<br><br>Systemtests werden in der Regel von unabhängigen Testern durchgeführt, die sich stark auf Spezifikationen stützen. Fehlerzustände in Spezifikationen (z.B. fehlende User-Stories, falsch benannte Fachanforderungen usw.) können zu einem Verständnisproblem oder Unstimmigkeiten über das erwartete Systemverhalten führen. Derartige Situationen können zu „falsch positiven“ und „falsch negativen“ Ergebnissen führen. Dies verschwendet Zeit und reduziert entsprechend die Effektivität der Fehleridentifikation. Das frühe Einbeziehen von Testern in User-Story-Verfeinerungen (Refinements) oder statische Testaktivitäten, wie Reviews, helfen dabei, das Auftreten solcher Situationen zu reduzieren.<br><br>2.2.4 Abnahmetest <br><br>Ziele des Abnahmetests <br><br>Der Abnahmetest konzentriert sich wie der Systemtest typischerweise auf das Verhalten und die Fähigkeiten eines gesamten Systems oder Produkts. Ziele des Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Vertrauen in die Qualität des Systems als Ganzen aufbauen</li><li>Validieren, ob das System vollständig ist und wie erwartet funktionieren wird</li><li>Verifizieren, ob funktionale und nicht-funktionale Verhaltensweisen des Systems den Spezifikationen entsprechen</li></ol>Der Abnahmetest kann Informationen bereitstellen, mit denen sich die Bereitschaft des Systems für den Einsatz und die Nutzung durch den Kunden (Endanwender) beurteilen lässt. Im Abnahmetest können Fehlerzustände gefunden werden, aber das Finden von Fehlerzuständen ist häufig nicht das Ziel und das Finden einer großen Anzahl von Fehlerzuständen im Abnahmetest wird in manchen Fällen als großes Projektrisiko angesehen. Der Abnahmetest kann auch notwendig sein, um rechtliche oder regulatorische Anforderungen oder Standards zu erfüllen.<br><br>Häufige Ausprägungen von Abnahmetests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Benutzerabnahmetest</li><li>Betrieblicher Abnahmetest</li><li>Vertraglicher und regulatorischer Abnahmetest</li><li>Alpha- und Beta-Test</li></ol>Jeder dieser Ausprägungen wird in den folgenden vier Unterabschnitten genauer beschrieben. <br><br>Benutzerabnahmetest (User Acceptance Testing (UAT))<br><br>Der Abnahmetest des Systems ist üblicherweise darauf konzentriert, die Bereitschaft des Systems zur Nutzung durch Benutzer in einer realen oder simulierten Betriebsumgebung zu validieren. Das Hauptziel ist es, Vertrauen darin zu schaffen, dass die Benutzer das System so nutzen können, dass es ihre Bedürfnisse und Anforderungen erfüllt und ihre Geschäftsprozesse mit einem Minimum an Schwierigkeiten, Kosten und Risiken ausführt.<br><br>Betrieblicher Abnahmetest (Operational Acceptance Testing (OAT)) <br><br>Der Abnahmetests des Systems durch Mitarbeiter des Betriebs oder Systemadministratoren wird üblicherweise in einer (simulierten) Produktivumgebung durchgeführt. Der Fokus des Tests liegt dabei auf betrieblichen Aspekten, u.a.:<ol style=\"list-style-type: circle;\"><li>Testen von Backups und Wiederherstellungen</li><li>Installieren, Deinstallieren und Aktualisieren</li><li>Notfallwiederherstellung (Disaster-Recovery)</li><li>Benutzerverwaltung</li><li>Wartungsaufgaben</li><li>Datenladeaufgaben und Migrationsaufgaben</li><li>Prüfen von IT-Sicherheitsschwachstellen</li><li>Performanztest</li></ol>Das Hauptziel von betrieblichen Abnahmetests ist es, Vertrauen darin aufzubauen, dass die Betreiber oder Systemadministratoren das System in der betrieblichen Umgebung ordnungsgemäß für die Benutzer funktionsfähig halten können, selbst unter außergewöhnlichen oder schwierigen Bedingungen.<br><br>Vertraglicher oder regulatorischer Abnahmetest<br><br>Der vertragliche Abnahmetest wird aufgrund von vertraglichen Abnahmekriterien für die Herstellung von kundenspezifisch entwickelter Software durchgeführt. Abnahmekriterien sollten zu dem Zeitpunkt definiert werden, an dem sich die Vertragsparteien auf den Vertrag einigen. Vertragliche Abnahmetests werden häufig durch Benutzer oder unabhängige Tester durchgeführt. <br><br>Regulatorische Abnahmetests werden gegen Regularien durchgeführt, die eingehalten werden müssen, beispielsweise staatliche, gesetzliche oder Vorschriften zur funktionalen Sicherheit. Regulatorische Abnahmetests werden häufig von Benutzern oder unabhängigen Testern durchgeführt. Manchmal werden die Ergebnisse von Aufsichtsbehörden bestätigt oder auditiert. <br><br>Das Hauptziel von vertraglichen oder regulatorischen Abnahmetests ist es, Vertrauen darin aufzubauen, dass die vertragliche oder regulatorische Konformität gegeben ist. <br><br>Alpha- und Beta-Tests <br><br>Alpha- und Beta-Tests werden üblicherweise von Entwicklern von kommerzieller Standardsoftware genutzt, die Rückmeldungen von ihren potenziellen oder bestehenden Benutzern, Kunden und/oder Betreibern erhalten wollen, bevor die Software auf den Markt kommt. Alpha-Tests werden auf Seiten des entwickelnden Unternehmens vorgenommen, nicht vom Entwicklungsteam, sondern von potenziellen oder bestehenden Kunden und/oder Betreibern oder von einem unabhängigen Testteam. Beta-Tests werden von potenziellen oder bestehenden Kunden und/oder Betreibern an ihren eigenen Standorten durchgeführt.<br>Beta-Tests können nach Alpha-Tests erfolgen oder auch ohne, dass ein vorausgehender Alpha-Test stattfand. <br><br>Ein Ziel des Alpha- und Beta-Testens ist es, Vertrauen bei potenziellen oder bestehenden Kunden und/oder Betreibern darüber zu schaffen, dass sie das System unter normalen alltäglichen Umständen in der Produktivumgebung(en) nutzen können, um ihre Ziele bequem und mit geringsten Kosten und Risiken zu erreichen. Ein weiteres Ziel kann das Finden von Fehlerzuständen sein, die sich auf die Bedingungen und Umgebungen beziehen, in denen das System genutzt werden wird, insbesondere dann, wenn diese Bedingungen und Umgebungen durch das Entwicklungsteam nur schwer nachzubilden sind.<br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für jegliche Form von Abnahmetests verwendet werden können, sind u.a.:<ol style=\"list-style-type: circle;\"><li>Geschäftsprozesse</li><li>Benutzer- oder Fachanforderungen</li><li>Vorschriften, rechtliche Verträge und Standards</li><li>Anwendungsfälle und/oder User Stories</li><li>Systemanforderungen</li><li>System- oder Benutzerdokumentation</li><li>Installationsverfahren</li><li>Risikoanalyseberichte</li></ol>Zusätzlich können eines oder mehrere der folgenden Arbeitsergebnisse als Testbasis für die Ableitung von Testfällen für betriebliche Abnahmetests genutzt werden:<ol style=\"list-style-type: circle;\"><li>Sicherungsverfahren und Wiederherstellungsverfahren</li><li>Disaster-Recovery-Verfahren</li><li>Nicht-funktionale Anforderungen</li><li>Betriebsdokumentation</li><li>Bereitstellungsanweisungen und Installationsanweisungen</li><li>Performanzziele</li><li>Datenbankpakete</li><li>Standards oder Vorschriften bzgl. IT-Sicherheit</li></ol>Typische Testobjekte<br><br>Typische Testobjekte für jegliche Form von Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>System unter Test (SUT)</li><li>Systemkonfigurationen und Konfigurationsdaten</li><li>Geschäftsprozesse des vollintegrierten Systems</li><li>Wiederherstellungssysteme und Hot Sites (für Tests zur Business-Continuity (Betriebskontinuität) und Notfallwiederherstellung)</li><li>Betriebs- und Wartungsprozesse</li><li>Formulare</li><li>Berichte</li><li>Bestehende und konvertierte Produktionsdaten</li></ol>Typische Fehlerzustände und Fehlerwirkungen<br><br>Beispiele für typische Fehlerzustände für jegliche Form von Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Systemworkflows erfüllen nicht die Fach- oder Benutzeranforderungen</li><li>Geschäftsregeln wurden nicht korrekt umgesetzt</li><li>Das System erfüllt nicht die vertraglichen oder regulatorischen Anforderungen</li><li>Nicht-funktionale Fehlerwirkungen wie IT-Sicherheitsschwachstellen, nicht angemessene Performanz unter hoher Last oder nicht ordnungsgemäßer Betrieb auf einer unterstützten Plattform</li></ol>Spezifische Ansätze und Verantwortlichkeiten<br><br>Der Abnahmetest liegt häufig in der Verantwortung der Kunden, Fachanwender, Product Owner oder Betreiber eines Systems. Andere Stakeholder können ebenfalls mit einbezogen werden.<br><br>Der Abnahmetest wird oft als die letzte Stufe in einem sequenziellen Entwicklungslebenszyklus verstanden, er kann aber auch zu anderen Zeitpunkten stattfinden, z.B.:<ol style=\"list-style-type: circle;\"><li>Der Abnahmetests eines kommerziellen Standardsoftwareprodukts kann zum Zeitpunkt der Installation oder Integration stattfinden</li><li>Der Abnahmetest einer neuen funktionalen Verbesserung kann vor dem Systemtest stattfinden</li></ol>In der iterativen Entwicklung können Projektteams verschiedene Formen der Abnahmetests während und am Ende einer Iteration vornehmen, wie die, die sich auf die Verifizierung eines neuen Features gegenüber seinen Abnahmekriterien konzentrieren, oder die, die sich darauf konzentrieren, zu validieren, dass ein neues Feature die Bedürfnisse der Benutzer erfüllt. Darüber hinaus können Alpha- und Beta-Tests entweder am Ende jeder Iteration, nach Abschluss jeder Iteration oder nach einer Serie von Iterationen stattfinden. Benutzerabnahmetests, betriebliche Abnahmetests, regulatorische Abnahmetests und vertragliche Abnahmetests können ebenfalls entweder zum Abschluss jeder Iteration, nach Abschluss jeder Iteration oder nach einer Serie von Iterationen stattfinden.",
      "b": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Aufgrund der obigen Beschreibung und des CTFL Lehrplans 2018, Abschnitt 2.2 erkennt man:<br><ol style=\"list-style-type: circle;\"><li>„Er basiert auf Schnittstellenspezifikationen” – Die Testbasis für Integrationstests enthält die Spezifikationen von Schnittstellen (zusammen mit Kommunikationsprotokollen). Hingegen enthält keine der anderen angegebenen Teststufen diese Arbeitsergebnisse als Testbasis.</li><li>„Der Schwerpunkt liegt auf dem Finden von Fehlerwirkungen in der Kommunikation” –Fehlerwirkungen in der Kommunikation der getesteten Komponenten sind eine der typischen Fehlerarten, welche man beim Integrationstest findet, während diese Fehlerart bei keiner anderen der angegebenen Teststufen im Schwerpunkt liegt.</li><li>„Die Testvorgehensweise wendet sowohl funktionale als auch strukturelle Testarten an” –Funktionale und strukturelle Testarten sind beim Integrationstest beide als Vorgehensweise möglich, wie sie auch für jede andere Teststufe geeignet wären. Im Lehrplan werden sie allerdings nur noch beim Systemtest explizit erwähnt.</li></ol>Folglich ist Option a) richtig.<br><br>2.2 Teststufen<br><br> Teststufen sind Gruppen von Testaktivitäten, die gemeinsam organisiert und verwaltet werden. Jede Teststufe ist eine Instanz des Testprozesses, der aus Aktivitäten besteht, die in Abschnitt 1.4 Testprozess beschrieben wurden. Diese Testaktivitäten beziehen sich auf die Software einer festgelegten Entwicklungsstufe von einzelnen Einheiten oder Komponenten bis hin zu vollständigen Systemen oder, falls zutreffend, von Systemen von Systemen. Die Teststufen stehen mit anderen Aktivitäten innerhalb des Softwareentwicklungslebenszyklus in Verbindung. In diesem Lehrplan werden die folgenden Teststufen verwendet: <ol style=\"list-style-type: circle;\"><li>Komponententest</li> <li>Integrationstest</li> <li>Systemtest</li> <li>Abnahmetest</li> </ol>Teststufen sind durch die folgenden Eigenschaften gekennzeichnet: <ol style=\"list-style-type: circle;\"><li>Spezifische Ziele</li> <li>Testbasis, um mit Bezug darauf Testfälle abzuleiten</li><li>Testobjekt (d.h., was wird getestet)</li> <li>Typische Fehlerzustände und Fehlerwirkungen</li><li>Spezifische Ansätze und Verantwortlichkeiten</li></ol>Für jede Teststufe ist eine passende Testumgebung erforderlich. Für den Abnahmetest ist beispielsweise eine produktionsähnliche Umgebung ideal, während die Entwickler im Komponententest üblicherweise ihre eigene Entwicklungsumgebung nutzen.<br><br>2.2.1 Komponententest <br><br>Ziele des Komponententests <br><br>Der Komponententest (auch Unit- oder Modultest genannt) konzentriert sich auf Komponenten, die einzeln testbar sind. Die Ziele des Komponententests beinhalten:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen der Komponente dem Entwurf und der Spezifikation entsprechen</li><li>Schaffen von Vertrauen in die Qualität der Komponente</li><li>Finden von Fehlerzuständen in der Komponente</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen weitergegeben werden</li></ol>In manchen Fällen, insbesondere in inkrementellen und iterativen Entwicklungsmodellen (z.B. agilen Entwicklungsmodellen), in denen Codeänderungen stetig erfolgen, spielen automatisierte Komponentenregressionstests eine Schlüsselrolle. Diese sollen Vertrauen schaffen, dass Änderungen bestehende Komponenten nicht beschädigt haben.<br><br>Der Komponententest wird häufig isoliert vom Rest des Systems vorgenommen. In Abhängigkeit vom Softwareentwicklungslebenszyklus-Modell und vom System erfordert dies eventuell Mock-Objekte, Service-Virtualisierung, Rahmen, Platzhalter und Treiber. Der Komponententest kann die Funktionalität (z.B. die Korrektheit von Berechnungen), nicht-funktionale Eigenschaften (z.B. Suche nach Speicherengpässen) und strukturelle Merkmale (z.B. Entscheidungstests) abdecken.<br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Komponententests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>Feinentwurf</li><li>Code</li><li>Datenmodelle</li><li>Komponentenspezifikationen</li></ol>Testobjekte<br><br>Gängige Testobjekte für Komponententests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Komponenten, Units oder Module</li><li>Code und Datenstrukturen</li><li>Klassen</li><li>Datenbankmodule</li></ol>Gängige Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für gängige Fehlerzustände und Fehlerwirkungen für Komponententests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Nicht korrekte Funktionalität (z.B. nicht wie in den Entwurfsspezifikationen beschrieben)</li><li>Datenflussprobleme</li><li>Nicht korrekter Code und nicht korrekte Logik</li></ol>Fehlerzustände werden in der Regel behoben, sobald sie gefunden werden, oftmals ohne formales Fehlermanagement. Wenn Entwickler allerdings Fehlerzustände berichten, liefert dies wichtige Informationen für die Grundursachenanalyse und die Prozessverbesserung.<br><br>Spezifische Ansätze und Verantwortlichkeiten <br><br>Komponententests werden üblicherweise von dem Entwickler durchgeführt, der den Code geschrieben hat. Zumindest aber erfordert dies den Zugang zum Code, der getestet werden soll. Entwickler können zwischen der Entwicklung einer Komponente und dem Finden und Beheben von Fehlerzuständen wechseln. Entwickler schreiben oft Tests und führen diese aus, nachdem sie den Code für eine Komponente entwickelt haben. Insbesondere in der agilen Entwicklung kann es jedoch auch sein, dass das Schreiben von automatisierten Komponententestfällen dem Schreiben von Anwendungscode vorangeht.<br><br>Nehmen wir zum Beispiel die testgetriebene Entwicklung (test driven development, TDD). Die testgetriebene Entwicklung ist hoch iterativ und basiert auf Zyklen zur Entwicklung automatisierter Testfälle, dann erfolgt die Entwicklung und Integration kleiner Teile von Code, gefolgt von der Durchführung von Komponententests, der Korrektur möglicher Probleme und der Restrukturierung (Refactoring) von Code. Dieser Prozess setzt sich fort, bis die Komponente vollständig erstellt und alle Komponententests erfolgreich abgeschlossen sind. Die testgetriebene Entwicklung ist ein Beispiel für den Ansatz „test first“. Obwohl die testgetriebene Entwicklung ihren Ursprung im eXtreme Programming (XP) hat, hat sie sich auch in andere Formen der agilen und in sequenzielle Lebenszyklen verbreitet (siehe ISTQB-AT).<br><br>2.2.2 Integrationstest <br><br>Ziele von Integrationstests <br><br>Integrationstests konzentrieren sich auf die Interaktion zwischen Komponenten oder Systemen. Ziele der Integrationstests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen der Schnittstellen dem Entwurf und der Spezifikation entsprechen</li><li>Vertrauen schaffen in die Qualität der Schnittstellen</li><li>Fehlerzustände finden (die in den Schnittstellen selbst oder innerhalb der Komponenten oder des Systems liegen können)</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen weitergegeben werden</li></ol>Wie beim Komponententest liefern automatisierte Integrationsregressionstests in manchen Fällen das Vertrauen, dass Änderungen bestehende Schnittstellen, Komponenten oder Systeme nicht beschädigt haben.<br><br>In diesem Lehrplan wird der Test von zwei Integrationsstufen beschrieben, der auf Testobjekte unterschiedlicher Größe ausgeübt werden kann:<ol style=\"list-style-type: circle;\"><li>Komponentenintegrationstests konzentrieren sich auf die Interaktionen und die Schnittstellen zwischen integrierten Komponenten. Komponentenintegrationstests werden nach Komponententests durchgeführt und sind generell automatisiert. In der iterativen und inkrementellen Entwicklung sind Integrationstests in der Regel Teil des kontinuierlichen Integrationsprozesses (continuous integration).</li><li>Systemintegrationstests konzentrieren sich auf die Interaktionen und Schnittstellen zwischen Systemen, Paketen und Microservices. Systemintegrationstests können auch Interaktionen und Schnittstellen abdecken, die von externen Organisationen bereitgestellt werden (z.B. Webservices). In diesem Fall hat die entwickelnde Organisation keinen Einfluss auf die externen Schnittstellen. Dies kann zu verschiedenen Herausforderungen im Testen führen (z.B. Sicherstellen, dass testblockierende Fehlerzustände im Code der externen Organisation behoben sind, Bereitstellen von Testumgebungen usw.). Der Systemintegrationstest kann nach den Systemtests oder parallel zu andauernden Systemtestaktivitäten stattfinden (sowohl in der sequenziellen Entwicklung als auch in der iterativen und inkrementellen Entwicklung).</li></ol>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Integrationstests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>Software- und Systementwurf</li><li>Sequenzdiagramme</li><li>Spezifikationen von Schnittstellen und Kommunikationsprotokollen</li><li>Anwendungsfälle</li><li>Architektur auf Komponenten- oder Systemebene</li><li>Workflows</li><li>Externe Schnittstellendefinitionen</li></ol>Testobjekte <br><br>Gängige Testobjekte für Integrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Subsysteme</li><li>Datenbanken</li><li>Infrastruktur</li><li>Schnittstellen</li><li>APIs</li><li>Microservices</li></ol>Typische Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für typische Fehlerzustände und Fehlerwirkungen für Komponentenintegrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Falsche Daten, fehlende Daten oder falsche Datenverschlüsselung</li><li>Falsche Reihenfolge oder fehlerhafte zeitliche Abfolge von Schnittstellenaufrufen</li><li>Falsch angepasste Schnittstellen</li><li>Fehlerwirkungen in der Kommunikation zwischen Komponenten</li><li>Nicht behandelte oder nicht ordnungsgemäß behandelte Fehlerwirkungen in der Kommunikation</li><li>zwischen den Komponenten</li><li>Nicht korrekte Annahmen über die Bedeutung, Einheiten oder Grenzen der Daten, die zwischen den Komponenten hin- und hergereicht werden</li></ol>Beispiele typischer Fehlerzustände und Fehlerwirkungen für Systemintegrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Inkonsistente Nachrichtenstrukturen zwischen den Systemen</li><li>Falsche Daten, fehlende Daten oder falsche Datenverschlüsselung</li><li>Falsch angepasste Schnittstellen</li><li>Fehlerwirkungen in der Kommunikation zwischen den Systemen</li><li>Nicht behandelte oder nicht ordnungsgemäß behandelte Fehlerwirkungen in der Kommunikation zwischen den Systemen</li><li>Falsche Annahmen über die Bedeutung, Einheiten oder Grenzen der Daten, die zwischen den Systemen hin- und hergereicht werden</li><li>Fehlende Konformität mit erforderlichen Richtlinien zur IT-Sicherheit</li></ol>Spezifische Ansätze und Verantwortlichkeiten <br><br>Komponentenintegrationstests und Systemintegrationstests sollten sich auf die Integration selbst konzentrieren. Zum Beispiel, wenn das Modul A mit dem Modul B integriert wird, sollten sich die Tests auf die Kommunikation zwischen diesen Modulen konzentrieren und nicht auf die Funktionalität der einzelnen Module, da diese in den Komponententests abgedeckt sein sollte. Wenn System X mit System Y integriert wird, sollten sich die Tests auf die Kommunikation zwischen den Systemen konzentrieren, nicht auf die Funktionalität der einzelnen Systeme, da diese in den Systemtests abgedeckt sein sollte. Funktionale, nicht-funktionale und strukturelle Testarten sind geeignet. <br><br>Komponentenintegrationstests liegen häufig in der Verantwortung der Entwickler. Systemintegrationstests liegen im Allgemeinen in der Verantwortung der Tester. Idealerweise sollten Tester, die Systemintegrationstests durchführen, die Systemarchitektur verstehen und die Integrationsplanung beeinflusst haben. <br><br>Wenn Integrationstests und die Integrationsstrategie geplant werden, bevor Komponenten oder Systeme entwickelt werden, können diese Komponenten oder Systeme in der Reihenfolge entwickelt werden, die für das effizienteste Testen erforderlich ist. Systematische Integrationsstrategien können auf der Systemarchitektur (z.B. Top-down und Bottom-up), auf funktionellen Aufgaben, auf der Reihenfolge der Transaktionsverarbeitung oder auf anderen Aspekten des Systems oder der Komponenten basieren. Um die Isolation von Fehlerzuständen zu vereinfachen und Fehlerzustände früh zu erkennen, sollte die Integration normalerweise inkrementell erfolgen (d.h. nur eine kleine Anzahl von zusätzlichen Komponenten oder Systemen zur gleichen Zeit) statt in einer Art „Big Bang“ (d.h. Integration aller Komponenten oder Systeme in einem einzigen Schritt). Eine Risikoanalyse der komplexesten Schnittstellen kann dabei helfen, die Integrationstests zielgerichtet einzusetzen. <br><br>Je größer der Umfang der Integration, desto schwieriger wird es, die Fehlerzustände in einer spezifischen Komponente oder einem spezifischen System zu isolieren. Dies führt zu einem höheren Risiko und einem größeren Zeitaufwand für die Fehlerbehebung. Das ist ein Grund dafür, dass kontinuierliche Integration, bei der Software auf Komponentenbasis integriert wird (d.h. funktionale Integration), zur gängigen Vorgehensweise geworden ist. Eine derartige kontinuierliche Integration (continuous integration) beinhaltet häufig automatisierte Regressionstests, idealerweise auf mehreren Teststufen<br><br>2.2.3 Systemtest <br><br>Systemtests konzentrieren sich auf das Verhalten und die Fähigkeiten des Systems oder Produkts. Dies geschieht oft unter Berücksichtigung der End-to-End-Aufgaben, die das System leisten kann, und der nicht-funktionalen Verhaltensweisen, die bei der Verarbeitung dieser Aufgaben zu Tage treten. Ziele des Systemtests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen des Systems dem Entwurf und den Spezifikationen entsprechen</li><li>Validierung, dass das System vollständig ist und wie erwartet funktionieren wird</li><li>Vertrauen in die Qualität des Systems als Ganzes schaffen</li><li>Finden von Fehlerzuständen</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen oder in die Produktion weitergegeben werden</li></ol>Für einige Systeme kann auch die Verifizierung der Datenqualität ein Ziel sein. Wie beim Komponententest und beim Integrationstest bieten in einigen Fällen automatisierte Systemregressionstests die Gewissheit, dass Änderungen nicht die bestehenden Features oder End-to-End-Fähigkeiten beeinträchtigt haben.<br>Systemtests liefern häufig Informationen, die von Stakeholdern für Freigabeentscheidungen genutzt werden. Systemtests können auch zur Erfüllung rechtlicher oder regulatorischer Anforderungen oder Standards notwendig sein.<br><br>Die Testumgebung sollte idealerweise der finalen Ziel- oder der Produktivumgebung entsprechen. <br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Systemtests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>System- und Softwareanforderungsspezifikationen (funktional und nicht-funktional)</li><li>Risikoanalyseberichte</li><li>Anwendungsfälle</li><li>Epics und User-Stories</li><li>Modelle des Systemverhaltens</li><li>Zustandsdiagramme</li><li>System- und Benutzeranleitungen</li></ol>Testobjekte<br><br>Gängige Testobjekte für Systemtests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Anwendungen</li><li>Hardware/Softwaresysteme</li> <li>Betriebssysteme</li><li>Systeme unter Test (SUT)</li><li>Systemkonfiguration und Konfigurationsdaten</li></ol>Typische Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für typische Fehlerzustände und Fehlerwirkungen für Systemtests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Falsche Berechnungen</li><li>Falsche oder unerwartete funktionale oder nicht-funktionale Systemverhaltensweisen</li><li>Falsche Kontrollflüsse und/oder Datenflüsse innerhalb des Systems</li><li>Versagen bei der korrekten oder vollständigen Ausführung von funktionalen End-to-End-Aufgaben</li><li>Versagen des Systems bei der ordnungsgemäßen Arbeit in der/den Systemumgebung/en</li><li>Das System funktioniert nicht wie in den System- oder Benutzeranleitungen beschrieben</li></ol>Spezifische Ansätze und Verantwortlichkeiten <br><br>Systemtests sollten sich auf das allgemeine End-to-End-Verhalten des Systems als Ganzes konzentrieren, sowohl in funktionaler als auch in nicht-funktionaler Hinsicht. Systemtests sollten die Verfahren nutzen, die am besten für die zu testenden Aspekte des Systems geeignet sind (siehe Kapitel 4). Beispielsweise kann eine Entscheidungstabelle erstellt werden, um zu verifizieren, ob ein funktionales Verhalten den Beschreibungen in den Geschäftsregeln entspricht.<br><br>Systemtests werden in der Regel von unabhängigen Testern durchgeführt, die sich stark auf Spezifikationen stützen. Fehlerzustände in Spezifikationen (z.B. fehlende User-Stories, falsch benannte Fachanforderungen usw.) können zu einem Verständnisproblem oder Unstimmigkeiten über das erwartete Systemverhalten führen. Derartige Situationen können zu „falsch positiven“ und „falsch negativen“ Ergebnissen führen. Dies verschwendet Zeit und reduziert entsprechend die Effektivität der Fehleridentifikation. Das frühe Einbeziehen von Testern in User-Story-Verfeinerungen (Refinements) oder statische Testaktivitäten, wie Reviews, helfen dabei, das Auftreten solcher Situationen zu reduzieren.<br><br>2.2.4 Abnahmetest <br><br>Ziele des Abnahmetests <br><br>Der Abnahmetest konzentriert sich wie der Systemtest typischerweise auf das Verhalten und die Fähigkeiten eines gesamten Systems oder Produkts. Ziele des Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Vertrauen in die Qualität des Systems als Ganzen aufbauen</li><li>Validieren, ob das System vollständig ist und wie erwartet funktionieren wird</li><li>Verifizieren, ob funktionale und nicht-funktionale Verhaltensweisen des Systems den Spezifikationen entsprechen</li></ol>Der Abnahmetest kann Informationen bereitstellen, mit denen sich die Bereitschaft des Systems für den Einsatz und die Nutzung durch den Kunden (Endanwender) beurteilen lässt. Im Abnahmetest können Fehlerzustände gefunden werden, aber das Finden von Fehlerzuständen ist häufig nicht das Ziel und das Finden einer großen Anzahl von Fehlerzuständen im Abnahmetest wird in manchen Fällen als großes Projektrisiko angesehen. Der Abnahmetest kann auch notwendig sein, um rechtliche oder regulatorische Anforderungen oder Standards zu erfüllen.<br><br>Häufige Ausprägungen von Abnahmetests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Benutzerabnahmetest</li><li>Betrieblicher Abnahmetest</li><li>Vertraglicher und regulatorischer Abnahmetest</li><li>Alpha- und Beta-Test</li></ol>Jeder dieser Ausprägungen wird in den folgenden vier Unterabschnitten genauer beschrieben. <br><br>Benutzerabnahmetest (User Acceptance Testing (UAT))<br><br>Der Abnahmetest des Systems ist üblicherweise darauf konzentriert, die Bereitschaft des Systems zur Nutzung durch Benutzer in einer realen oder simulierten Betriebsumgebung zu validieren. Das Hauptziel ist es, Vertrauen darin zu schaffen, dass die Benutzer das System so nutzen können, dass es ihre Bedürfnisse und Anforderungen erfüllt und ihre Geschäftsprozesse mit einem Minimum an Schwierigkeiten, Kosten und Risiken ausführt.<br><br>Betrieblicher Abnahmetest (Operational Acceptance Testing (OAT)) <br><br>Der Abnahmetests des Systems durch Mitarbeiter des Betriebs oder Systemadministratoren wird üblicherweise in einer (simulierten) Produktivumgebung durchgeführt. Der Fokus des Tests liegt dabei auf betrieblichen Aspekten, u.a.:<ol style=\"list-style-type: circle;\"><li>Testen von Backups und Wiederherstellungen</li><li>Installieren, Deinstallieren und Aktualisieren</li><li>Notfallwiederherstellung (Disaster-Recovery)</li><li>Benutzerverwaltung</li><li>Wartungsaufgaben</li><li>Datenladeaufgaben und Migrationsaufgaben</li><li>Prüfen von IT-Sicherheitsschwachstellen</li><li>Performanztest</li></ol>Das Hauptziel von betrieblichen Abnahmetests ist es, Vertrauen darin aufzubauen, dass die Betreiber oder Systemadministratoren das System in der betrieblichen Umgebung ordnungsgemäß für die Benutzer funktionsfähig halten können, selbst unter außergewöhnlichen oder schwierigen Bedingungen.<br><br>Vertraglicher oder regulatorischer Abnahmetest<br><br>Der vertragliche Abnahmetest wird aufgrund von vertraglichen Abnahmekriterien für die Herstellung von kundenspezifisch entwickelter Software durchgeführt. Abnahmekriterien sollten zu dem Zeitpunkt definiert werden, an dem sich die Vertragsparteien auf den Vertrag einigen. Vertragliche Abnahmetests werden häufig durch Benutzer oder unabhängige Tester durchgeführt. <br><br>Regulatorische Abnahmetests werden gegen Regularien durchgeführt, die eingehalten werden müssen, beispielsweise staatliche, gesetzliche oder Vorschriften zur funktionalen Sicherheit. Regulatorische Abnahmetests werden häufig von Benutzern oder unabhängigen Testern durchgeführt. Manchmal werden die Ergebnisse von Aufsichtsbehörden bestätigt oder auditiert. <br><br>Das Hauptziel von vertraglichen oder regulatorischen Abnahmetests ist es, Vertrauen darin aufzubauen, dass die vertragliche oder regulatorische Konformität gegeben ist. <br><br>Alpha- und Beta-Tests <br><br>Alpha- und Beta-Tests werden üblicherweise von Entwicklern von kommerzieller Standardsoftware genutzt, die Rückmeldungen von ihren potenziellen oder bestehenden Benutzern, Kunden und/oder Betreibern erhalten wollen, bevor die Software auf den Markt kommt. Alpha-Tests werden auf Seiten des entwickelnden Unternehmens vorgenommen, nicht vom Entwicklungsteam, sondern von potenziellen oder bestehenden Kunden und/oder Betreibern oder von einem unabhängigen Testteam. Beta-Tests werden von potenziellen oder bestehenden Kunden und/oder Betreibern an ihren eigenen Standorten durchgeführt.<br>Beta-Tests können nach Alpha-Tests erfolgen oder auch ohne, dass ein vorausgehender Alpha-Test stattfand. <br><br>Ein Ziel des Alpha- und Beta-Testens ist es, Vertrauen bei potenziellen oder bestehenden Kunden und/oder Betreibern darüber zu schaffen, dass sie das System unter normalen alltäglichen Umständen in der Produktivumgebung(en) nutzen können, um ihre Ziele bequem und mit geringsten Kosten und Risiken zu erreichen. Ein weiteres Ziel kann das Finden von Fehlerzuständen sein, die sich auf die Bedingungen und Umgebungen beziehen, in denen das System genutzt werden wird, insbesondere dann, wenn diese Bedingungen und Umgebungen durch das Entwicklungsteam nur schwer nachzubilden sind.<br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für jegliche Form von Abnahmetests verwendet werden können, sind u.a.:<ol style=\"list-style-type: circle;\"><li>Geschäftsprozesse</li><li>Benutzer- oder Fachanforderungen</li><li>Vorschriften, rechtliche Verträge und Standards</li><li>Anwendungsfälle und/oder User Stories</li><li>Systemanforderungen</li><li>System- oder Benutzerdokumentation</li><li>Installationsverfahren</li><li>Risikoanalyseberichte</li></ol>Zusätzlich können eines oder mehrere der folgenden Arbeitsergebnisse als Testbasis für die Ableitung von Testfällen für betriebliche Abnahmetests genutzt werden:<ol style=\"list-style-type: circle;\"><li>Sicherungsverfahren und Wiederherstellungsverfahren</li><li>Disaster-Recovery-Verfahren</li><li>Nicht-funktionale Anforderungen</li><li>Betriebsdokumentation</li><li>Bereitstellungsanweisungen und Installationsanweisungen</li><li>Performanzziele</li><li>Datenbankpakete</li><li>Standards oder Vorschriften bzgl. IT-Sicherheit</li></ol>Typische Testobjekte<br><br>Typische Testobjekte für jegliche Form von Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>System unter Test (SUT)</li><li>Systemkonfigurationen und Konfigurationsdaten</li><li>Geschäftsprozesse des vollintegrierten Systems</li><li>Wiederherstellungssysteme und Hot Sites (für Tests zur Business-Continuity (Betriebskontinuität) und Notfallwiederherstellung)</li><li>Betriebs- und Wartungsprozesse</li><li>Formulare</li><li>Berichte</li><li>Bestehende und konvertierte Produktionsdaten</li></ol>Typische Fehlerzustände und Fehlerwirkungen<br><br>Beispiele für typische Fehlerzustände für jegliche Form von Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Systemworkflows erfüllen nicht die Fach- oder Benutzeranforderungen</li><li>Geschäftsregeln wurden nicht korrekt umgesetzt</li><li>Das System erfüllt nicht die vertraglichen oder regulatorischen Anforderungen</li><li>Nicht-funktionale Fehlerwirkungen wie IT-Sicherheitsschwachstellen, nicht angemessene Performanz unter hoher Last oder nicht ordnungsgemäßer Betrieb auf einer unterstützten Plattform</li></ol>Spezifische Ansätze und Verantwortlichkeiten<br><br>Der Abnahmetest liegt häufig in der Verantwortung der Kunden, Fachanwender, Product Owner oder Betreiber eines Systems. Andere Stakeholder können ebenfalls mit einbezogen werden.<br><br>Der Abnahmetest wird oft als die letzte Stufe in einem sequenziellen Entwicklungslebenszyklus verstanden, er kann aber auch zu anderen Zeitpunkten stattfinden, z.B.:<ol style=\"list-style-type: circle;\"><li>Der Abnahmetests eines kommerziellen Standardsoftwareprodukts kann zum Zeitpunkt der Installation oder Integration stattfinden</li><li>Der Abnahmetest einer neuen funktionalen Verbesserung kann vor dem Systemtest stattfinden</li></ol>In der iterativen Entwicklung können Projektteams verschiedene Formen der Abnahmetests während und am Ende einer Iteration vornehmen, wie die, die sich auf die Verifizierung eines neuen Features gegenüber seinen Abnahmekriterien konzentrieren, oder die, die sich darauf konzentrieren, zu validieren, dass ein neues Feature die Bedürfnisse der Benutzer erfüllt. Darüber hinaus können Alpha- und Beta-Tests entweder am Ende jeder Iteration, nach Abschluss jeder Iteration oder nach einer Serie von Iterationen stattfinden. Benutzerabnahmetests, betriebliche Abnahmetests, regulatorische Abnahmetests und vertragliche Abnahmetests können ebenfalls entweder zum Abschluss jeder Iteration, nach Abschluss jeder Iteration oder nach einer Serie von Iterationen stattfinden.",
      "c": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Aufgrund der obigen Beschreibung und des CTFL Lehrplans 2018, Abschnitt 2.2 erkennt man:<br><ol style=\"list-style-type: circle;\"><li>„Er basiert auf Schnittstellenspezifikationen” – Die Testbasis für Integrationstests enthält die Spezifikationen von Schnittstellen (zusammen mit Kommunikationsprotokollen). Hingegen enthält keine der anderen angegebenen Teststufen diese Arbeitsergebnisse als Testbasis.</li><li>„Der Schwerpunkt liegt auf dem Finden von Fehlerwirkungen in der Kommunikation” –Fehlerwirkungen in der Kommunikation der getesteten Komponenten sind eine der typischen Fehlerarten, welche man beim Integrationstest findet, während diese Fehlerart bei keiner anderen der angegebenen Teststufen im Schwerpunkt liegt.</li><li>„Die Testvorgehensweise wendet sowohl funktionale als auch strukturelle Testarten an” –Funktionale und strukturelle Testarten sind beim Integrationstest beide als Vorgehensweise möglich, wie sie auch für jede andere Teststufe geeignet wären. Im Lehrplan werden sie allerdings nur noch beim Systemtest explizit erwähnt.</li></ol>Folglich ist Option a) richtig.<br><br>2.2 Teststufen<br><br> Teststufen sind Gruppen von Testaktivitäten, die gemeinsam organisiert und verwaltet werden. Jede Teststufe ist eine Instanz des Testprozesses, der aus Aktivitäten besteht, die in Abschnitt 1.4 Testprozess beschrieben wurden. Diese Testaktivitäten beziehen sich auf die Software einer festgelegten Entwicklungsstufe von einzelnen Einheiten oder Komponenten bis hin zu vollständigen Systemen oder, falls zutreffend, von Systemen von Systemen. Die Teststufen stehen mit anderen Aktivitäten innerhalb des Softwareentwicklungslebenszyklus in Verbindung. In diesem Lehrplan werden die folgenden Teststufen verwendet: <ol style=\"list-style-type: circle;\"><li>Komponententest</li> <li>Integrationstest</li> <li>Systemtest</li> <li>Abnahmetest</li> </ol>Teststufen sind durch die folgenden Eigenschaften gekennzeichnet: <ol style=\"list-style-type: circle;\"><li>Spezifische Ziele</li> <li>Testbasis, um mit Bezug darauf Testfälle abzuleiten</li><li>Testobjekt (d.h., was wird getestet)</li> <li>Typische Fehlerzustände und Fehlerwirkungen</li><li>Spezifische Ansätze und Verantwortlichkeiten</li></ol>Für jede Teststufe ist eine passende Testumgebung erforderlich. Für den Abnahmetest ist beispielsweise eine produktionsähnliche Umgebung ideal, während die Entwickler im Komponententest üblicherweise ihre eigene Entwicklungsumgebung nutzen.<br><br>2.2.1 Komponententest <br><br>Ziele des Komponententests <br><br>Der Komponententest (auch Unit- oder Modultest genannt) konzentriert sich auf Komponenten, die einzeln testbar sind. Die Ziele des Komponententests beinhalten:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen der Komponente dem Entwurf und der Spezifikation entsprechen</li><li>Schaffen von Vertrauen in die Qualität der Komponente</li><li>Finden von Fehlerzuständen in der Komponente</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen weitergegeben werden</li></ol>In manchen Fällen, insbesondere in inkrementellen und iterativen Entwicklungsmodellen (z.B. agilen Entwicklungsmodellen), in denen Codeänderungen stetig erfolgen, spielen automatisierte Komponentenregressionstests eine Schlüsselrolle. Diese sollen Vertrauen schaffen, dass Änderungen bestehende Komponenten nicht beschädigt haben.<br><br>Der Komponententest wird häufig isoliert vom Rest des Systems vorgenommen. In Abhängigkeit vom Softwareentwicklungslebenszyklus-Modell und vom System erfordert dies eventuell Mock-Objekte, Service-Virtualisierung, Rahmen, Platzhalter und Treiber. Der Komponententest kann die Funktionalität (z.B. die Korrektheit von Berechnungen), nicht-funktionale Eigenschaften (z.B. Suche nach Speicherengpässen) und strukturelle Merkmale (z.B. Entscheidungstests) abdecken.<br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Komponententests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>Feinentwurf</li><li>Code</li><li>Datenmodelle</li><li>Komponentenspezifikationen</li></ol>Testobjekte<br><br>Gängige Testobjekte für Komponententests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Komponenten, Units oder Module</li><li>Code und Datenstrukturen</li><li>Klassen</li><li>Datenbankmodule</li></ol>Gängige Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für gängige Fehlerzustände und Fehlerwirkungen für Komponententests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Nicht korrekte Funktionalität (z.B. nicht wie in den Entwurfsspezifikationen beschrieben)</li><li>Datenflussprobleme</li><li>Nicht korrekter Code und nicht korrekte Logik</li></ol>Fehlerzustände werden in der Regel behoben, sobald sie gefunden werden, oftmals ohne formales Fehlermanagement. Wenn Entwickler allerdings Fehlerzustände berichten, liefert dies wichtige Informationen für die Grundursachenanalyse und die Prozessverbesserung.<br><br>Spezifische Ansätze und Verantwortlichkeiten <br><br>Komponententests werden üblicherweise von dem Entwickler durchgeführt, der den Code geschrieben hat. Zumindest aber erfordert dies den Zugang zum Code, der getestet werden soll. Entwickler können zwischen der Entwicklung einer Komponente und dem Finden und Beheben von Fehlerzuständen wechseln. Entwickler schreiben oft Tests und führen diese aus, nachdem sie den Code für eine Komponente entwickelt haben. Insbesondere in der agilen Entwicklung kann es jedoch auch sein, dass das Schreiben von automatisierten Komponententestfällen dem Schreiben von Anwendungscode vorangeht.<br><br>Nehmen wir zum Beispiel die testgetriebene Entwicklung (test driven development, TDD). Die testgetriebene Entwicklung ist hoch iterativ und basiert auf Zyklen zur Entwicklung automatisierter Testfälle, dann erfolgt die Entwicklung und Integration kleiner Teile von Code, gefolgt von der Durchführung von Komponententests, der Korrektur möglicher Probleme und der Restrukturierung (Refactoring) von Code. Dieser Prozess setzt sich fort, bis die Komponente vollständig erstellt und alle Komponententests erfolgreich abgeschlossen sind. Die testgetriebene Entwicklung ist ein Beispiel für den Ansatz „test first“. Obwohl die testgetriebene Entwicklung ihren Ursprung im eXtreme Programming (XP) hat, hat sie sich auch in andere Formen der agilen und in sequenzielle Lebenszyklen verbreitet (siehe ISTQB-AT).<br><br>2.2.2 Integrationstest <br><br>Ziele von Integrationstests <br><br>Integrationstests konzentrieren sich auf die Interaktion zwischen Komponenten oder Systemen. Ziele der Integrationstests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen der Schnittstellen dem Entwurf und der Spezifikation entsprechen</li><li>Vertrauen schaffen in die Qualität der Schnittstellen</li><li>Fehlerzustände finden (die in den Schnittstellen selbst oder innerhalb der Komponenten oder des Systems liegen können)</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen weitergegeben werden</li></ol>Wie beim Komponententest liefern automatisierte Integrationsregressionstests in manchen Fällen das Vertrauen, dass Änderungen bestehende Schnittstellen, Komponenten oder Systeme nicht beschädigt haben.<br><br>In diesem Lehrplan wird der Test von zwei Integrationsstufen beschrieben, der auf Testobjekte unterschiedlicher Größe ausgeübt werden kann:<ol style=\"list-style-type: circle;\"><li>Komponentenintegrationstests konzentrieren sich auf die Interaktionen und die Schnittstellen zwischen integrierten Komponenten. Komponentenintegrationstests werden nach Komponententests durchgeführt und sind generell automatisiert. In der iterativen und inkrementellen Entwicklung sind Integrationstests in der Regel Teil des kontinuierlichen Integrationsprozesses (continuous integration).</li><li>Systemintegrationstests konzentrieren sich auf die Interaktionen und Schnittstellen zwischen Systemen, Paketen und Microservices. Systemintegrationstests können auch Interaktionen und Schnittstellen abdecken, die von externen Organisationen bereitgestellt werden (z.B. Webservices). In diesem Fall hat die entwickelnde Organisation keinen Einfluss auf die externen Schnittstellen. Dies kann zu verschiedenen Herausforderungen im Testen führen (z.B. Sicherstellen, dass testblockierende Fehlerzustände im Code der externen Organisation behoben sind, Bereitstellen von Testumgebungen usw.). Der Systemintegrationstest kann nach den Systemtests oder parallel zu andauernden Systemtestaktivitäten stattfinden (sowohl in der sequenziellen Entwicklung als auch in der iterativen und inkrementellen Entwicklung).</li></ol>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Integrationstests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>Software- und Systementwurf</li><li>Sequenzdiagramme</li><li>Spezifikationen von Schnittstellen und Kommunikationsprotokollen</li><li>Anwendungsfälle</li><li>Architektur auf Komponenten- oder Systemebene</li><li>Workflows</li><li>Externe Schnittstellendefinitionen</li></ol>Testobjekte <br><br>Gängige Testobjekte für Integrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Subsysteme</li><li>Datenbanken</li><li>Infrastruktur</li><li>Schnittstellen</li><li>APIs</li><li>Microservices</li></ol>Typische Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für typische Fehlerzustände und Fehlerwirkungen für Komponentenintegrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Falsche Daten, fehlende Daten oder falsche Datenverschlüsselung</li><li>Falsche Reihenfolge oder fehlerhafte zeitliche Abfolge von Schnittstellenaufrufen</li><li>Falsch angepasste Schnittstellen</li><li>Fehlerwirkungen in der Kommunikation zwischen Komponenten</li><li>Nicht behandelte oder nicht ordnungsgemäß behandelte Fehlerwirkungen in der Kommunikation</li><li>zwischen den Komponenten</li><li>Nicht korrekte Annahmen über die Bedeutung, Einheiten oder Grenzen der Daten, die zwischen den Komponenten hin- und hergereicht werden</li></ol>Beispiele typischer Fehlerzustände und Fehlerwirkungen für Systemintegrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Inkonsistente Nachrichtenstrukturen zwischen den Systemen</li><li>Falsche Daten, fehlende Daten oder falsche Datenverschlüsselung</li><li>Falsch angepasste Schnittstellen</li><li>Fehlerwirkungen in der Kommunikation zwischen den Systemen</li><li>Nicht behandelte oder nicht ordnungsgemäß behandelte Fehlerwirkungen in der Kommunikation zwischen den Systemen</li><li>Falsche Annahmen über die Bedeutung, Einheiten oder Grenzen der Daten, die zwischen den Systemen hin- und hergereicht werden</li><li>Fehlende Konformität mit erforderlichen Richtlinien zur IT-Sicherheit</li></ol>Spezifische Ansätze und Verantwortlichkeiten <br><br>Komponentenintegrationstests und Systemintegrationstests sollten sich auf die Integration selbst konzentrieren. Zum Beispiel, wenn das Modul A mit dem Modul B integriert wird, sollten sich die Tests auf die Kommunikation zwischen diesen Modulen konzentrieren und nicht auf die Funktionalität der einzelnen Module, da diese in den Komponententests abgedeckt sein sollte. Wenn System X mit System Y integriert wird, sollten sich die Tests auf die Kommunikation zwischen den Systemen konzentrieren, nicht auf die Funktionalität der einzelnen Systeme, da diese in den Systemtests abgedeckt sein sollte. Funktionale, nicht-funktionale und strukturelle Testarten sind geeignet. <br><br>Komponentenintegrationstests liegen häufig in der Verantwortung der Entwickler. Systemintegrationstests liegen im Allgemeinen in der Verantwortung der Tester. Idealerweise sollten Tester, die Systemintegrationstests durchführen, die Systemarchitektur verstehen und die Integrationsplanung beeinflusst haben. <br><br>Wenn Integrationstests und die Integrationsstrategie geplant werden, bevor Komponenten oder Systeme entwickelt werden, können diese Komponenten oder Systeme in der Reihenfolge entwickelt werden, die für das effizienteste Testen erforderlich ist. Systematische Integrationsstrategien können auf der Systemarchitektur (z.B. Top-down und Bottom-up), auf funktionellen Aufgaben, auf der Reihenfolge der Transaktionsverarbeitung oder auf anderen Aspekten des Systems oder der Komponenten basieren. Um die Isolation von Fehlerzuständen zu vereinfachen und Fehlerzustände früh zu erkennen, sollte die Integration normalerweise inkrementell erfolgen (d.h. nur eine kleine Anzahl von zusätzlichen Komponenten oder Systemen zur gleichen Zeit) statt in einer Art „Big Bang“ (d.h. Integration aller Komponenten oder Systeme in einem einzigen Schritt). Eine Risikoanalyse der komplexesten Schnittstellen kann dabei helfen, die Integrationstests zielgerichtet einzusetzen. <br><br>Je größer der Umfang der Integration, desto schwieriger wird es, die Fehlerzustände in einer spezifischen Komponente oder einem spezifischen System zu isolieren. Dies führt zu einem höheren Risiko und einem größeren Zeitaufwand für die Fehlerbehebung. Das ist ein Grund dafür, dass kontinuierliche Integration, bei der Software auf Komponentenbasis integriert wird (d.h. funktionale Integration), zur gängigen Vorgehensweise geworden ist. Eine derartige kontinuierliche Integration (continuous integration) beinhaltet häufig automatisierte Regressionstests, idealerweise auf mehreren Teststufen<br><br>2.2.3 Systemtest <br><br>Systemtests konzentrieren sich auf das Verhalten und die Fähigkeiten des Systems oder Produkts. Dies geschieht oft unter Berücksichtigung der End-to-End-Aufgaben, die das System leisten kann, und der nicht-funktionalen Verhaltensweisen, die bei der Verarbeitung dieser Aufgaben zu Tage treten. Ziele des Systemtests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen des Systems dem Entwurf und den Spezifikationen entsprechen</li><li>Validierung, dass das System vollständig ist und wie erwartet funktionieren wird</li><li>Vertrauen in die Qualität des Systems als Ganzes schaffen</li><li>Finden von Fehlerzuständen</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen oder in die Produktion weitergegeben werden</li></ol>Für einige Systeme kann auch die Verifizierung der Datenqualität ein Ziel sein. Wie beim Komponententest und beim Integrationstest bieten in einigen Fällen automatisierte Systemregressionstests die Gewissheit, dass Änderungen nicht die bestehenden Features oder End-to-End-Fähigkeiten beeinträchtigt haben.<br>Systemtests liefern häufig Informationen, die von Stakeholdern für Freigabeentscheidungen genutzt werden. Systemtests können auch zur Erfüllung rechtlicher oder regulatorischer Anforderungen oder Standards notwendig sein.<br><br>Die Testumgebung sollte idealerweise der finalen Ziel- oder der Produktivumgebung entsprechen. <br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Systemtests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>System- und Softwareanforderungsspezifikationen (funktional und nicht-funktional)</li><li>Risikoanalyseberichte</li><li>Anwendungsfälle</li><li>Epics und User-Stories</li><li>Modelle des Systemverhaltens</li><li>Zustandsdiagramme</li><li>System- und Benutzeranleitungen</li></ol>Testobjekte<br><br>Gängige Testobjekte für Systemtests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Anwendungen</li><li>Hardware/Softwaresysteme</li> <li>Betriebssysteme</li><li>Systeme unter Test (SUT)</li><li>Systemkonfiguration und Konfigurationsdaten</li></ol>Typische Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für typische Fehlerzustände und Fehlerwirkungen für Systemtests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Falsche Berechnungen</li><li>Falsche oder unerwartete funktionale oder nicht-funktionale Systemverhaltensweisen</li><li>Falsche Kontrollflüsse und/oder Datenflüsse innerhalb des Systems</li><li>Versagen bei der korrekten oder vollständigen Ausführung von funktionalen End-to-End-Aufgaben</li><li>Versagen des Systems bei der ordnungsgemäßen Arbeit in der/den Systemumgebung/en</li><li>Das System funktioniert nicht wie in den System- oder Benutzeranleitungen beschrieben</li></ol>Spezifische Ansätze und Verantwortlichkeiten <br><br>Systemtests sollten sich auf das allgemeine End-to-End-Verhalten des Systems als Ganzes konzentrieren, sowohl in funktionaler als auch in nicht-funktionaler Hinsicht. Systemtests sollten die Verfahren nutzen, die am besten für die zu testenden Aspekte des Systems geeignet sind (siehe Kapitel 4). Beispielsweise kann eine Entscheidungstabelle erstellt werden, um zu verifizieren, ob ein funktionales Verhalten den Beschreibungen in den Geschäftsregeln entspricht.<br><br>Systemtests werden in der Regel von unabhängigen Testern durchgeführt, die sich stark auf Spezifikationen stützen. Fehlerzustände in Spezifikationen (z.B. fehlende User-Stories, falsch benannte Fachanforderungen usw.) können zu einem Verständnisproblem oder Unstimmigkeiten über das erwartete Systemverhalten führen. Derartige Situationen können zu „falsch positiven“ und „falsch negativen“ Ergebnissen führen. Dies verschwendet Zeit und reduziert entsprechend die Effektivität der Fehleridentifikation. Das frühe Einbeziehen von Testern in User-Story-Verfeinerungen (Refinements) oder statische Testaktivitäten, wie Reviews, helfen dabei, das Auftreten solcher Situationen zu reduzieren.<br><br>2.2.4 Abnahmetest <br><br>Ziele des Abnahmetests <br><br>Der Abnahmetest konzentriert sich wie der Systemtest typischerweise auf das Verhalten und die Fähigkeiten eines gesamten Systems oder Produkts. Ziele des Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Vertrauen in die Qualität des Systems als Ganzen aufbauen</li><li>Validieren, ob das System vollständig ist und wie erwartet funktionieren wird</li><li>Verifizieren, ob funktionale und nicht-funktionale Verhaltensweisen des Systems den Spezifikationen entsprechen</li></ol>Der Abnahmetest kann Informationen bereitstellen, mit denen sich die Bereitschaft des Systems für den Einsatz und die Nutzung durch den Kunden (Endanwender) beurteilen lässt. Im Abnahmetest können Fehlerzustände gefunden werden, aber das Finden von Fehlerzuständen ist häufig nicht das Ziel und das Finden einer großen Anzahl von Fehlerzuständen im Abnahmetest wird in manchen Fällen als großes Projektrisiko angesehen. Der Abnahmetest kann auch notwendig sein, um rechtliche oder regulatorische Anforderungen oder Standards zu erfüllen.<br><br>Häufige Ausprägungen von Abnahmetests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Benutzerabnahmetest</li><li>Betrieblicher Abnahmetest</li><li>Vertraglicher und regulatorischer Abnahmetest</li><li>Alpha- und Beta-Test</li></ol>Jeder dieser Ausprägungen wird in den folgenden vier Unterabschnitten genauer beschrieben. <br><br>Benutzerabnahmetest (User Acceptance Testing (UAT))<br><br>Der Abnahmetest des Systems ist üblicherweise darauf konzentriert, die Bereitschaft des Systems zur Nutzung durch Benutzer in einer realen oder simulierten Betriebsumgebung zu validieren. Das Hauptziel ist es, Vertrauen darin zu schaffen, dass die Benutzer das System so nutzen können, dass es ihre Bedürfnisse und Anforderungen erfüllt und ihre Geschäftsprozesse mit einem Minimum an Schwierigkeiten, Kosten und Risiken ausführt.<br><br>Betrieblicher Abnahmetest (Operational Acceptance Testing (OAT)) <br><br>Der Abnahmetests des Systems durch Mitarbeiter des Betriebs oder Systemadministratoren wird üblicherweise in einer (simulierten) Produktivumgebung durchgeführt. Der Fokus des Tests liegt dabei auf betrieblichen Aspekten, u.a.:<ol style=\"list-style-type: circle;\"><li>Testen von Backups und Wiederherstellungen</li><li>Installieren, Deinstallieren und Aktualisieren</li><li>Notfallwiederherstellung (Disaster-Recovery)</li><li>Benutzerverwaltung</li><li>Wartungsaufgaben</li><li>Datenladeaufgaben und Migrationsaufgaben</li><li>Prüfen von IT-Sicherheitsschwachstellen</li><li>Performanztest</li></ol>Das Hauptziel von betrieblichen Abnahmetests ist es, Vertrauen darin aufzubauen, dass die Betreiber oder Systemadministratoren das System in der betrieblichen Umgebung ordnungsgemäß für die Benutzer funktionsfähig halten können, selbst unter außergewöhnlichen oder schwierigen Bedingungen.<br><br>Vertraglicher oder regulatorischer Abnahmetest<br><br>Der vertragliche Abnahmetest wird aufgrund von vertraglichen Abnahmekriterien für die Herstellung von kundenspezifisch entwickelter Software durchgeführt. Abnahmekriterien sollten zu dem Zeitpunkt definiert werden, an dem sich die Vertragsparteien auf den Vertrag einigen. Vertragliche Abnahmetests werden häufig durch Benutzer oder unabhängige Tester durchgeführt. <br><br>Regulatorische Abnahmetests werden gegen Regularien durchgeführt, die eingehalten werden müssen, beispielsweise staatliche, gesetzliche oder Vorschriften zur funktionalen Sicherheit. Regulatorische Abnahmetests werden häufig von Benutzern oder unabhängigen Testern durchgeführt. Manchmal werden die Ergebnisse von Aufsichtsbehörden bestätigt oder auditiert. <br><br>Das Hauptziel von vertraglichen oder regulatorischen Abnahmetests ist es, Vertrauen darin aufzubauen, dass die vertragliche oder regulatorische Konformität gegeben ist. <br><br>Alpha- und Beta-Tests <br><br>Alpha- und Beta-Tests werden üblicherweise von Entwicklern von kommerzieller Standardsoftware genutzt, die Rückmeldungen von ihren potenziellen oder bestehenden Benutzern, Kunden und/oder Betreibern erhalten wollen, bevor die Software auf den Markt kommt. Alpha-Tests werden auf Seiten des entwickelnden Unternehmens vorgenommen, nicht vom Entwicklungsteam, sondern von potenziellen oder bestehenden Kunden und/oder Betreibern oder von einem unabhängigen Testteam. Beta-Tests werden von potenziellen oder bestehenden Kunden und/oder Betreibern an ihren eigenen Standorten durchgeführt.<br>Beta-Tests können nach Alpha-Tests erfolgen oder auch ohne, dass ein vorausgehender Alpha-Test stattfand. <br><br>Ein Ziel des Alpha- und Beta-Testens ist es, Vertrauen bei potenziellen oder bestehenden Kunden und/oder Betreibern darüber zu schaffen, dass sie das System unter normalen alltäglichen Umständen in der Produktivumgebung(en) nutzen können, um ihre Ziele bequem und mit geringsten Kosten und Risiken zu erreichen. Ein weiteres Ziel kann das Finden von Fehlerzuständen sein, die sich auf die Bedingungen und Umgebungen beziehen, in denen das System genutzt werden wird, insbesondere dann, wenn diese Bedingungen und Umgebungen durch das Entwicklungsteam nur schwer nachzubilden sind.<br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für jegliche Form von Abnahmetests verwendet werden können, sind u.a.:<ol style=\"list-style-type: circle;\"><li>Geschäftsprozesse</li><li>Benutzer- oder Fachanforderungen</li><li>Vorschriften, rechtliche Verträge und Standards</li><li>Anwendungsfälle und/oder User Stories</li><li>Systemanforderungen</li><li>System- oder Benutzerdokumentation</li><li>Installationsverfahren</li><li>Risikoanalyseberichte</li></ol>Zusätzlich können eines oder mehrere der folgenden Arbeitsergebnisse als Testbasis für die Ableitung von Testfällen für betriebliche Abnahmetests genutzt werden:<ol style=\"list-style-type: circle;\"><li>Sicherungsverfahren und Wiederherstellungsverfahren</li><li>Disaster-Recovery-Verfahren</li><li>Nicht-funktionale Anforderungen</li><li>Betriebsdokumentation</li><li>Bereitstellungsanweisungen und Installationsanweisungen</li><li>Performanzziele</li><li>Datenbankpakete</li><li>Standards oder Vorschriften bzgl. IT-Sicherheit</li></ol>Typische Testobjekte<br><br>Typische Testobjekte für jegliche Form von Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>System unter Test (SUT)</li><li>Systemkonfigurationen und Konfigurationsdaten</li><li>Geschäftsprozesse des vollintegrierten Systems</li><li>Wiederherstellungssysteme und Hot Sites (für Tests zur Business-Continuity (Betriebskontinuität) und Notfallwiederherstellung)</li><li>Betriebs- und Wartungsprozesse</li><li>Formulare</li><li>Berichte</li><li>Bestehende und konvertierte Produktionsdaten</li></ol>Typische Fehlerzustände und Fehlerwirkungen<br><br>Beispiele für typische Fehlerzustände für jegliche Form von Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Systemworkflows erfüllen nicht die Fach- oder Benutzeranforderungen</li><li>Geschäftsregeln wurden nicht korrekt umgesetzt</li><li>Das System erfüllt nicht die vertraglichen oder regulatorischen Anforderungen</li><li>Nicht-funktionale Fehlerwirkungen wie IT-Sicherheitsschwachstellen, nicht angemessene Performanz unter hoher Last oder nicht ordnungsgemäßer Betrieb auf einer unterstützten Plattform</li></ol>Spezifische Ansätze und Verantwortlichkeiten<br><br>Der Abnahmetest liegt häufig in der Verantwortung der Kunden, Fachanwender, Product Owner oder Betreiber eines Systems. Andere Stakeholder können ebenfalls mit einbezogen werden.<br><br>Der Abnahmetest wird oft als die letzte Stufe in einem sequenziellen Entwicklungslebenszyklus verstanden, er kann aber auch zu anderen Zeitpunkten stattfinden, z.B.:<ol style=\"list-style-type: circle;\"><li>Der Abnahmetests eines kommerziellen Standardsoftwareprodukts kann zum Zeitpunkt der Installation oder Integration stattfinden</li><li>Der Abnahmetest einer neuen funktionalen Verbesserung kann vor dem Systemtest stattfinden</li></ol>In der iterativen Entwicklung können Projektteams verschiedene Formen der Abnahmetests während und am Ende einer Iteration vornehmen, wie die, die sich auf die Verifizierung eines neuen Features gegenüber seinen Abnahmekriterien konzentrieren, oder die, die sich darauf konzentrieren, zu validieren, dass ein neues Feature die Bedürfnisse der Benutzer erfüllt. Darüber hinaus können Alpha- und Beta-Tests entweder am Ende jeder Iteration, nach Abschluss jeder Iteration oder nach einer Serie von Iterationen stattfinden. Benutzerabnahmetests, betriebliche Abnahmetests, regulatorische Abnahmetests und vertragliche Abnahmetests können ebenfalls entweder zum Abschluss jeder Iteration, nach Abschluss jeder Iteration oder nach einer Serie von Iterationen stattfinden.",
      "d": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Aufgrund der obigen Beschreibung und des CTFL Lehrplans 2018, Abschnitt 2.2 erkennt man:<br><ol style=\"list-style-type: circle;\"><li>„Er basiert auf Schnittstellenspezifikationen” – Die Testbasis für Integrationstests enthält die Spezifikationen von Schnittstellen (zusammen mit Kommunikationsprotokollen). Hingegen enthält keine der anderen angegebenen Teststufen diese Arbeitsergebnisse als Testbasis.</li><li>„Der Schwerpunkt liegt auf dem Finden von Fehlerwirkungen in der Kommunikation” –Fehlerwirkungen in der Kommunikation der getesteten Komponenten sind eine der typischen Fehlerarten, welche man beim Integrationstest findet, während diese Fehlerart bei keiner anderen der angegebenen Teststufen im Schwerpunkt liegt.</li><li>„Die Testvorgehensweise wendet sowohl funktionale als auch strukturelle Testarten an” –Funktionale und strukturelle Testarten sind beim Integrationstest beide als Vorgehensweise möglich, wie sie auch für jede andere Teststufe geeignet wären. Im Lehrplan werden sie allerdings nur noch beim Systemtest explizit erwähnt.</li></ol>Folglich ist Option a) richtig.<br><br>2.2 Teststufen<br><br> Teststufen sind Gruppen von Testaktivitäten, die gemeinsam organisiert und verwaltet werden. Jede Teststufe ist eine Instanz des Testprozesses, der aus Aktivitäten besteht, die in Abschnitt 1.4 Testprozess beschrieben wurden. Diese Testaktivitäten beziehen sich auf die Software einer festgelegten Entwicklungsstufe von einzelnen Einheiten oder Komponenten bis hin zu vollständigen Systemen oder, falls zutreffend, von Systemen von Systemen. Die Teststufen stehen mit anderen Aktivitäten innerhalb des Softwareentwicklungslebenszyklus in Verbindung. In diesem Lehrplan werden die folgenden Teststufen verwendet: <ol style=\"list-style-type: circle;\"><li>Komponententest</li> <li>Integrationstest</li> <li>Systemtest</li> <li>Abnahmetest</li> </ol>Teststufen sind durch die folgenden Eigenschaften gekennzeichnet: <ol style=\"list-style-type: circle;\"><li>Spezifische Ziele</li> <li>Testbasis, um mit Bezug darauf Testfälle abzuleiten</li><li>Testobjekt (d.h., was wird getestet)</li> <li>Typische Fehlerzustände und Fehlerwirkungen</li><li>Spezifische Ansätze und Verantwortlichkeiten</li></ol>Für jede Teststufe ist eine passende Testumgebung erforderlich. Für den Abnahmetest ist beispielsweise eine produktionsähnliche Umgebung ideal, während die Entwickler im Komponententest üblicherweise ihre eigene Entwicklungsumgebung nutzen.<br><br>2.2.1 Komponententest <br><br>Ziele des Komponententests <br><br>Der Komponententest (auch Unit- oder Modultest genannt) konzentriert sich auf Komponenten, die einzeln testbar sind. Die Ziele des Komponententests beinhalten:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen der Komponente dem Entwurf und der Spezifikation entsprechen</li><li>Schaffen von Vertrauen in die Qualität der Komponente</li><li>Finden von Fehlerzuständen in der Komponente</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen weitergegeben werden</li></ol>In manchen Fällen, insbesondere in inkrementellen und iterativen Entwicklungsmodellen (z.B. agilen Entwicklungsmodellen), in denen Codeänderungen stetig erfolgen, spielen automatisierte Komponentenregressionstests eine Schlüsselrolle. Diese sollen Vertrauen schaffen, dass Änderungen bestehende Komponenten nicht beschädigt haben.<br><br>Der Komponententest wird häufig isoliert vom Rest des Systems vorgenommen. In Abhängigkeit vom Softwareentwicklungslebenszyklus-Modell und vom System erfordert dies eventuell Mock-Objekte, Service-Virtualisierung, Rahmen, Platzhalter und Treiber. Der Komponententest kann die Funktionalität (z.B. die Korrektheit von Berechnungen), nicht-funktionale Eigenschaften (z.B. Suche nach Speicherengpässen) und strukturelle Merkmale (z.B. Entscheidungstests) abdecken.<br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Komponententests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>Feinentwurf</li><li>Code</li><li>Datenmodelle</li><li>Komponentenspezifikationen</li></ol>Testobjekte<br><br>Gängige Testobjekte für Komponententests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Komponenten, Units oder Module</li><li>Code und Datenstrukturen</li><li>Klassen</li><li>Datenbankmodule</li></ol>Gängige Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für gängige Fehlerzustände und Fehlerwirkungen für Komponententests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Nicht korrekte Funktionalität (z.B. nicht wie in den Entwurfsspezifikationen beschrieben)</li><li>Datenflussprobleme</li><li>Nicht korrekter Code und nicht korrekte Logik</li></ol>Fehlerzustände werden in der Regel behoben, sobald sie gefunden werden, oftmals ohne formales Fehlermanagement. Wenn Entwickler allerdings Fehlerzustände berichten, liefert dies wichtige Informationen für die Grundursachenanalyse und die Prozessverbesserung.<br><br>Spezifische Ansätze und Verantwortlichkeiten <br><br>Komponententests werden üblicherweise von dem Entwickler durchgeführt, der den Code geschrieben hat. Zumindest aber erfordert dies den Zugang zum Code, der getestet werden soll. Entwickler können zwischen der Entwicklung einer Komponente und dem Finden und Beheben von Fehlerzuständen wechseln. Entwickler schreiben oft Tests und führen diese aus, nachdem sie den Code für eine Komponente entwickelt haben. Insbesondere in der agilen Entwicklung kann es jedoch auch sein, dass das Schreiben von automatisierten Komponententestfällen dem Schreiben von Anwendungscode vorangeht.<br><br>Nehmen wir zum Beispiel die testgetriebene Entwicklung (test driven development, TDD). Die testgetriebene Entwicklung ist hoch iterativ und basiert auf Zyklen zur Entwicklung automatisierter Testfälle, dann erfolgt die Entwicklung und Integration kleiner Teile von Code, gefolgt von der Durchführung von Komponententests, der Korrektur möglicher Probleme und der Restrukturierung (Refactoring) von Code. Dieser Prozess setzt sich fort, bis die Komponente vollständig erstellt und alle Komponententests erfolgreich abgeschlossen sind. Die testgetriebene Entwicklung ist ein Beispiel für den Ansatz „test first“. Obwohl die testgetriebene Entwicklung ihren Ursprung im eXtreme Programming (XP) hat, hat sie sich auch in andere Formen der agilen und in sequenzielle Lebenszyklen verbreitet (siehe ISTQB-AT).<br><br>2.2.2 Integrationstest <br><br>Ziele von Integrationstests <br><br>Integrationstests konzentrieren sich auf die Interaktion zwischen Komponenten oder Systemen. Ziele der Integrationstests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen der Schnittstellen dem Entwurf und der Spezifikation entsprechen</li><li>Vertrauen schaffen in die Qualität der Schnittstellen</li><li>Fehlerzustände finden (die in den Schnittstellen selbst oder innerhalb der Komponenten oder des Systems liegen können)</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen weitergegeben werden</li></ol>Wie beim Komponententest liefern automatisierte Integrationsregressionstests in manchen Fällen das Vertrauen, dass Änderungen bestehende Schnittstellen, Komponenten oder Systeme nicht beschädigt haben.<br><br>In diesem Lehrplan wird der Test von zwei Integrationsstufen beschrieben, der auf Testobjekte unterschiedlicher Größe ausgeübt werden kann:<ol style=\"list-style-type: circle;\"><li>Komponentenintegrationstests konzentrieren sich auf die Interaktionen und die Schnittstellen zwischen integrierten Komponenten. Komponentenintegrationstests werden nach Komponententests durchgeführt und sind generell automatisiert. In der iterativen und inkrementellen Entwicklung sind Integrationstests in der Regel Teil des kontinuierlichen Integrationsprozesses (continuous integration).</li><li>Systemintegrationstests konzentrieren sich auf die Interaktionen und Schnittstellen zwischen Systemen, Paketen und Microservices. Systemintegrationstests können auch Interaktionen und Schnittstellen abdecken, die von externen Organisationen bereitgestellt werden (z.B. Webservices). In diesem Fall hat die entwickelnde Organisation keinen Einfluss auf die externen Schnittstellen. Dies kann zu verschiedenen Herausforderungen im Testen führen (z.B. Sicherstellen, dass testblockierende Fehlerzustände im Code der externen Organisation behoben sind, Bereitstellen von Testumgebungen usw.). Der Systemintegrationstest kann nach den Systemtests oder parallel zu andauernden Systemtestaktivitäten stattfinden (sowohl in der sequenziellen Entwicklung als auch in der iterativen und inkrementellen Entwicklung).</li></ol>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Integrationstests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>Software- und Systementwurf</li><li>Sequenzdiagramme</li><li>Spezifikationen von Schnittstellen und Kommunikationsprotokollen</li><li>Anwendungsfälle</li><li>Architektur auf Komponenten- oder Systemebene</li><li>Workflows</li><li>Externe Schnittstellendefinitionen</li></ol>Testobjekte <br><br>Gängige Testobjekte für Integrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Subsysteme</li><li>Datenbanken</li><li>Infrastruktur</li><li>Schnittstellen</li><li>APIs</li><li>Microservices</li></ol>Typische Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für typische Fehlerzustände und Fehlerwirkungen für Komponentenintegrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Falsche Daten, fehlende Daten oder falsche Datenverschlüsselung</li><li>Falsche Reihenfolge oder fehlerhafte zeitliche Abfolge von Schnittstellenaufrufen</li><li>Falsch angepasste Schnittstellen</li><li>Fehlerwirkungen in der Kommunikation zwischen Komponenten</li><li>Nicht behandelte oder nicht ordnungsgemäß behandelte Fehlerwirkungen in der Kommunikation</li><li>zwischen den Komponenten</li><li>Nicht korrekte Annahmen über die Bedeutung, Einheiten oder Grenzen der Daten, die zwischen den Komponenten hin- und hergereicht werden</li></ol>Beispiele typischer Fehlerzustände und Fehlerwirkungen für Systemintegrationstests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Inkonsistente Nachrichtenstrukturen zwischen den Systemen</li><li>Falsche Daten, fehlende Daten oder falsche Datenverschlüsselung</li><li>Falsch angepasste Schnittstellen</li><li>Fehlerwirkungen in der Kommunikation zwischen den Systemen</li><li>Nicht behandelte oder nicht ordnungsgemäß behandelte Fehlerwirkungen in der Kommunikation zwischen den Systemen</li><li>Falsche Annahmen über die Bedeutung, Einheiten oder Grenzen der Daten, die zwischen den Systemen hin- und hergereicht werden</li><li>Fehlende Konformität mit erforderlichen Richtlinien zur IT-Sicherheit</li></ol>Spezifische Ansätze und Verantwortlichkeiten <br><br>Komponentenintegrationstests und Systemintegrationstests sollten sich auf die Integration selbst konzentrieren. Zum Beispiel, wenn das Modul A mit dem Modul B integriert wird, sollten sich die Tests auf die Kommunikation zwischen diesen Modulen konzentrieren und nicht auf die Funktionalität der einzelnen Module, da diese in den Komponententests abgedeckt sein sollte. Wenn System X mit System Y integriert wird, sollten sich die Tests auf die Kommunikation zwischen den Systemen konzentrieren, nicht auf die Funktionalität der einzelnen Systeme, da diese in den Systemtests abgedeckt sein sollte. Funktionale, nicht-funktionale und strukturelle Testarten sind geeignet. <br><br>Komponentenintegrationstests liegen häufig in der Verantwortung der Entwickler. Systemintegrationstests liegen im Allgemeinen in der Verantwortung der Tester. Idealerweise sollten Tester, die Systemintegrationstests durchführen, die Systemarchitektur verstehen und die Integrationsplanung beeinflusst haben. <br><br>Wenn Integrationstests und die Integrationsstrategie geplant werden, bevor Komponenten oder Systeme entwickelt werden, können diese Komponenten oder Systeme in der Reihenfolge entwickelt werden, die für das effizienteste Testen erforderlich ist. Systematische Integrationsstrategien können auf der Systemarchitektur (z.B. Top-down und Bottom-up), auf funktionellen Aufgaben, auf der Reihenfolge der Transaktionsverarbeitung oder auf anderen Aspekten des Systems oder der Komponenten basieren. Um die Isolation von Fehlerzuständen zu vereinfachen und Fehlerzustände früh zu erkennen, sollte die Integration normalerweise inkrementell erfolgen (d.h. nur eine kleine Anzahl von zusätzlichen Komponenten oder Systemen zur gleichen Zeit) statt in einer Art „Big Bang“ (d.h. Integration aller Komponenten oder Systeme in einem einzigen Schritt). Eine Risikoanalyse der komplexesten Schnittstellen kann dabei helfen, die Integrationstests zielgerichtet einzusetzen. <br><br>Je größer der Umfang der Integration, desto schwieriger wird es, die Fehlerzustände in einer spezifischen Komponente oder einem spezifischen System zu isolieren. Dies führt zu einem höheren Risiko und einem größeren Zeitaufwand für die Fehlerbehebung. Das ist ein Grund dafür, dass kontinuierliche Integration, bei der Software auf Komponentenbasis integriert wird (d.h. funktionale Integration), zur gängigen Vorgehensweise geworden ist. Eine derartige kontinuierliche Integration (continuous integration) beinhaltet häufig automatisierte Regressionstests, idealerweise auf mehreren Teststufen<br><br>2.2.3 Systemtest <br><br>Systemtests konzentrieren sich auf das Verhalten und die Fähigkeiten des Systems oder Produkts. Dies geschieht oft unter Berücksichtigung der End-to-End-Aufgaben, die das System leisten kann, und der nicht-funktionalen Verhaltensweisen, die bei der Verarbeitung dieser Aufgaben zu Tage treten. Ziele des Systemtests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Risikoreduktion</li><li>Verifizierung, ob die funktionalen und nicht-funktionalen Verhaltensweisen des Systems dem Entwurf und den Spezifikationen entsprechen</li><li>Validierung, dass das System vollständig ist und wie erwartet funktionieren wird</li><li>Vertrauen in die Qualität des Systems als Ganzes schaffen</li><li>Finden von Fehlerzuständen</li><li>Verhindern, dass Fehlerzustände an höhere Teststufen oder in die Produktion weitergegeben werden</li></ol>Für einige Systeme kann auch die Verifizierung der Datenqualität ein Ziel sein. Wie beim Komponententest und beim Integrationstest bieten in einigen Fällen automatisierte Systemregressionstests die Gewissheit, dass Änderungen nicht die bestehenden Features oder End-to-End-Fähigkeiten beeinträchtigt haben.<br>Systemtests liefern häufig Informationen, die von Stakeholdern für Freigabeentscheidungen genutzt werden. Systemtests können auch zur Erfüllung rechtlicher oder regulatorischer Anforderungen oder Standards notwendig sein.<br><br>Die Testumgebung sollte idealerweise der finalen Ziel- oder der Produktivumgebung entsprechen. <br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für Systemtests genutzt werden können, sind u.a.: <ol style=\"list-style-type: circle;\"><li>System- und Softwareanforderungsspezifikationen (funktional und nicht-funktional)</li><li>Risikoanalyseberichte</li><li>Anwendungsfälle</li><li>Epics und User-Stories</li><li>Modelle des Systemverhaltens</li><li>Zustandsdiagramme</li><li>System- und Benutzeranleitungen</li></ol>Testobjekte<br><br>Gängige Testobjekte für Systemtests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Anwendungen</li><li>Hardware/Softwaresysteme</li> <li>Betriebssysteme</li><li>Systeme unter Test (SUT)</li><li>Systemkonfiguration und Konfigurationsdaten</li></ol>Typische Fehlerzustände und Fehlerwirkungen <br><br>Beispiele für typische Fehlerzustände und Fehlerwirkungen für Systemtests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Falsche Berechnungen</li><li>Falsche oder unerwartete funktionale oder nicht-funktionale Systemverhaltensweisen</li><li>Falsche Kontrollflüsse und/oder Datenflüsse innerhalb des Systems</li><li>Versagen bei der korrekten oder vollständigen Ausführung von funktionalen End-to-End-Aufgaben</li><li>Versagen des Systems bei der ordnungsgemäßen Arbeit in der/den Systemumgebung/en</li><li>Das System funktioniert nicht wie in den System- oder Benutzeranleitungen beschrieben</li></ol>Spezifische Ansätze und Verantwortlichkeiten <br><br>Systemtests sollten sich auf das allgemeine End-to-End-Verhalten des Systems als Ganzes konzentrieren, sowohl in funktionaler als auch in nicht-funktionaler Hinsicht. Systemtests sollten die Verfahren nutzen, die am besten für die zu testenden Aspekte des Systems geeignet sind (siehe Kapitel 4). Beispielsweise kann eine Entscheidungstabelle erstellt werden, um zu verifizieren, ob ein funktionales Verhalten den Beschreibungen in den Geschäftsregeln entspricht.<br><br>Systemtests werden in der Regel von unabhängigen Testern durchgeführt, die sich stark auf Spezifikationen stützen. Fehlerzustände in Spezifikationen (z.B. fehlende User-Stories, falsch benannte Fachanforderungen usw.) können zu einem Verständnisproblem oder Unstimmigkeiten über das erwartete Systemverhalten führen. Derartige Situationen können zu „falsch positiven“ und „falsch negativen“ Ergebnissen führen. Dies verschwendet Zeit und reduziert entsprechend die Effektivität der Fehleridentifikation. Das frühe Einbeziehen von Testern in User-Story-Verfeinerungen (Refinements) oder statische Testaktivitäten, wie Reviews, helfen dabei, das Auftreten solcher Situationen zu reduzieren.<br><br>2.2.4 Abnahmetest <br><br>Ziele des Abnahmetests <br><br>Der Abnahmetest konzentriert sich wie der Systemtest typischerweise auf das Verhalten und die Fähigkeiten eines gesamten Systems oder Produkts. Ziele des Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Vertrauen in die Qualität des Systems als Ganzen aufbauen</li><li>Validieren, ob das System vollständig ist und wie erwartet funktionieren wird</li><li>Verifizieren, ob funktionale und nicht-funktionale Verhaltensweisen des Systems den Spezifikationen entsprechen</li></ol>Der Abnahmetest kann Informationen bereitstellen, mit denen sich die Bereitschaft des Systems für den Einsatz und die Nutzung durch den Kunden (Endanwender) beurteilen lässt. Im Abnahmetest können Fehlerzustände gefunden werden, aber das Finden von Fehlerzuständen ist häufig nicht das Ziel und das Finden einer großen Anzahl von Fehlerzuständen im Abnahmetest wird in manchen Fällen als großes Projektrisiko angesehen. Der Abnahmetest kann auch notwendig sein, um rechtliche oder regulatorische Anforderungen oder Standards zu erfüllen.<br><br>Häufige Ausprägungen von Abnahmetests sind u.a.: <ol style=\"list-style-type: circle;\"><li>Benutzerabnahmetest</li><li>Betrieblicher Abnahmetest</li><li>Vertraglicher und regulatorischer Abnahmetest</li><li>Alpha- und Beta-Test</li></ol>Jeder dieser Ausprägungen wird in den folgenden vier Unterabschnitten genauer beschrieben. <br><br>Benutzerabnahmetest (User Acceptance Testing (UAT))<br><br>Der Abnahmetest des Systems ist üblicherweise darauf konzentriert, die Bereitschaft des Systems zur Nutzung durch Benutzer in einer realen oder simulierten Betriebsumgebung zu validieren. Das Hauptziel ist es, Vertrauen darin zu schaffen, dass die Benutzer das System so nutzen können, dass es ihre Bedürfnisse und Anforderungen erfüllt und ihre Geschäftsprozesse mit einem Minimum an Schwierigkeiten, Kosten und Risiken ausführt.<br><br>Betrieblicher Abnahmetest (Operational Acceptance Testing (OAT)) <br><br>Der Abnahmetests des Systems durch Mitarbeiter des Betriebs oder Systemadministratoren wird üblicherweise in einer (simulierten) Produktivumgebung durchgeführt. Der Fokus des Tests liegt dabei auf betrieblichen Aspekten, u.a.:<ol style=\"list-style-type: circle;\"><li>Testen von Backups und Wiederherstellungen</li><li>Installieren, Deinstallieren und Aktualisieren</li><li>Notfallwiederherstellung (Disaster-Recovery)</li><li>Benutzerverwaltung</li><li>Wartungsaufgaben</li><li>Datenladeaufgaben und Migrationsaufgaben</li><li>Prüfen von IT-Sicherheitsschwachstellen</li><li>Performanztest</li></ol>Das Hauptziel von betrieblichen Abnahmetests ist es, Vertrauen darin aufzubauen, dass die Betreiber oder Systemadministratoren das System in der betrieblichen Umgebung ordnungsgemäß für die Benutzer funktionsfähig halten können, selbst unter außergewöhnlichen oder schwierigen Bedingungen.<br><br>Vertraglicher oder regulatorischer Abnahmetest<br><br>Der vertragliche Abnahmetest wird aufgrund von vertraglichen Abnahmekriterien für die Herstellung von kundenspezifisch entwickelter Software durchgeführt. Abnahmekriterien sollten zu dem Zeitpunkt definiert werden, an dem sich die Vertragsparteien auf den Vertrag einigen. Vertragliche Abnahmetests werden häufig durch Benutzer oder unabhängige Tester durchgeführt. <br><br>Regulatorische Abnahmetests werden gegen Regularien durchgeführt, die eingehalten werden müssen, beispielsweise staatliche, gesetzliche oder Vorschriften zur funktionalen Sicherheit. Regulatorische Abnahmetests werden häufig von Benutzern oder unabhängigen Testern durchgeführt. Manchmal werden die Ergebnisse von Aufsichtsbehörden bestätigt oder auditiert. <br><br>Das Hauptziel von vertraglichen oder regulatorischen Abnahmetests ist es, Vertrauen darin aufzubauen, dass die vertragliche oder regulatorische Konformität gegeben ist. <br><br>Alpha- und Beta-Tests <br><br>Alpha- und Beta-Tests werden üblicherweise von Entwicklern von kommerzieller Standardsoftware genutzt, die Rückmeldungen von ihren potenziellen oder bestehenden Benutzern, Kunden und/oder Betreibern erhalten wollen, bevor die Software auf den Markt kommt. Alpha-Tests werden auf Seiten des entwickelnden Unternehmens vorgenommen, nicht vom Entwicklungsteam, sondern von potenziellen oder bestehenden Kunden und/oder Betreibern oder von einem unabhängigen Testteam. Beta-Tests werden von potenziellen oder bestehenden Kunden und/oder Betreibern an ihren eigenen Standorten durchgeführt.<br>Beta-Tests können nach Alpha-Tests erfolgen oder auch ohne, dass ein vorausgehender Alpha-Test stattfand. <br><br>Ein Ziel des Alpha- und Beta-Testens ist es, Vertrauen bei potenziellen oder bestehenden Kunden und/oder Betreibern darüber zu schaffen, dass sie das System unter normalen alltäglichen Umständen in der Produktivumgebung(en) nutzen können, um ihre Ziele bequem und mit geringsten Kosten und Risiken zu erreichen. Ein weiteres Ziel kann das Finden von Fehlerzuständen sein, die sich auf die Bedingungen und Umgebungen beziehen, in denen das System genutzt werden wird, insbesondere dann, wenn diese Bedingungen und Umgebungen durch das Entwicklungsteam nur schwer nachzubilden sind.<br><br>Testbasis<br><br>Beispiele für Arbeitsergebnisse, die als Testbasis für jegliche Form von Abnahmetests verwendet werden können, sind u.a.:<ol style=\"list-style-type: circle;\"><li>Geschäftsprozesse</li><li>Benutzer- oder Fachanforderungen</li><li>Vorschriften, rechtliche Verträge und Standards</li><li>Anwendungsfälle und/oder User Stories</li><li>Systemanforderungen</li><li>System- oder Benutzerdokumentation</li><li>Installationsverfahren</li><li>Risikoanalyseberichte</li></ol>Zusätzlich können eines oder mehrere der folgenden Arbeitsergebnisse als Testbasis für die Ableitung von Testfällen für betriebliche Abnahmetests genutzt werden:<ol style=\"list-style-type: circle;\"><li>Sicherungsverfahren und Wiederherstellungsverfahren</li><li>Disaster-Recovery-Verfahren</li><li>Nicht-funktionale Anforderungen</li><li>Betriebsdokumentation</li><li>Bereitstellungsanweisungen und Installationsanweisungen</li><li>Performanzziele</li><li>Datenbankpakete</li><li>Standards oder Vorschriften bzgl. IT-Sicherheit</li></ol>Typische Testobjekte<br><br>Typische Testobjekte für jegliche Form von Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>System unter Test (SUT)</li><li>Systemkonfigurationen und Konfigurationsdaten</li><li>Geschäftsprozesse des vollintegrierten Systems</li><li>Wiederherstellungssysteme und Hot Sites (für Tests zur Business-Continuity (Betriebskontinuität) und Notfallwiederherstellung)</li><li>Betriebs- und Wartungsprozesse</li><li>Formulare</li><li>Berichte</li><li>Bestehende und konvertierte Produktionsdaten</li></ol>Typische Fehlerzustände und Fehlerwirkungen<br><br>Beispiele für typische Fehlerzustände für jegliche Form von Abnahmetests sind u.a.:<ol style=\"list-style-type: circle;\"><li>Systemworkflows erfüllen nicht die Fach- oder Benutzeranforderungen</li><li>Geschäftsregeln wurden nicht korrekt umgesetzt</li><li>Das System erfüllt nicht die vertraglichen oder regulatorischen Anforderungen</li><li>Nicht-funktionale Fehlerwirkungen wie IT-Sicherheitsschwachstellen, nicht angemessene Performanz unter hoher Last oder nicht ordnungsgemäßer Betrieb auf einer unterstützten Plattform</li></ol>Spezifische Ansätze und Verantwortlichkeiten<br><br>Der Abnahmetest liegt häufig in der Verantwortung der Kunden, Fachanwender, Product Owner oder Betreiber eines Systems. Andere Stakeholder können ebenfalls mit einbezogen werden.<br><br>Der Abnahmetest wird oft als die letzte Stufe in einem sequenziellen Entwicklungslebenszyklus verstanden, er kann aber auch zu anderen Zeitpunkten stattfinden, z.B.:<ol style=\"list-style-type: circle;\"><li>Der Abnahmetests eines kommerziellen Standardsoftwareprodukts kann zum Zeitpunkt der Installation oder Integration stattfinden</li><li>Der Abnahmetest einer neuen funktionalen Verbesserung kann vor dem Systemtest stattfinden</li></ol>In der iterativen Entwicklung können Projektteams verschiedene Formen der Abnahmetests während und am Ende einer Iteration vornehmen, wie die, die sich auf die Verifizierung eines neuen Features gegenüber seinen Abnahmekriterien konzentrieren, oder die, die sich darauf konzentrieren, zu validieren, dass ein neues Feature die Bedürfnisse der Benutzer erfüllt. Darüber hinaus können Alpha- und Beta-Tests entweder am Ende jeder Iteration, nach Abschluss jeder Iteration oder nach einer Serie von Iterationen stattfinden. Benutzerabnahmetests, betriebliche Abnahmetests, regulatorische Abnahmetests und vertragliche Abnahmetests können ebenfalls entweder zum Abschluss jeder Iteration, nach Abschluss jeder Iteration oder nach einer Serie von Iterationen stattfinden."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen über Testarten und Teststufen ist ZUTREFFEND?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Funktionaler und nicht-funktionaler Test können auf den Teststufen System und Abnahmetest durchgeführt werden, während der White-Box-Test auf Komponenten- und Integrationstests beschränkt ist.",
      "b": "Funktionaler Test kann auf jeder Teststufe durchgeführt werden, während der White-Box-Test auf Komponententest beschränkt ist.",
      "c": "Es ist möglich, funktionalen, nicht-funktionalen und White-Box-Test in jeder Teststufe durchzuführen.",
      "d": "Funktionaler und nicht-funktionaler Test können auf jeder Teststufe durchgeführt werden, während der White-Box-Test auf Komponenten- und Integrationstests beschränkt ist."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Es ist möglich, jede der Testarten (funktional, nicht-funktional, White-Box) in jeder Teststufe durchzuführen. Obwohl die Aussage richtig ist, dass funktionaler und nicht-funktionaler Test auf den Teststufen System- und Abnahmetest durchgeführt werden können, ist die Aussage falsch, dass White-Box-Test auf Komponenten- und Integrationstests beschränkt ist. (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.5)<br><br>2.3.5 Testarten und Teststufen<br><br>Es ist möglich, jede der oben genannten Testarten in jeder Teststufe durchzuführen. Um dies zu veranschaulichen, werden für eine Bankanwendung Beispiele für funktionale, nicht-funktionale, White-Box- und änderungsbezogene Tests über alle Teststufen hinweg gegeben, beginnend mit funktionalen Tests: <ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests auf der Grundlage dessen entworfen, wie eine Komponente Zinseszinsen berechnet.</li><li>Für Komponentenintegrationstests werden Tests auf der Grundlage dessen entworfen, wie Kontoinformationen, die auf der Benutzeroberfläche erfasst werden, in die fachliche Logik übertragen werden.</li><li>Für Systemtests werden Tests auf Grundlage dessen entworfen, wie Kontoinhaber eine Kreditlinie für ihr Konto beantragen können.</li><li>Für Systemintegrationstests werden Tests auf Grundlage dessen entworfen, wie das System einen externen Microservice dafür nutzt, die Bonität eines Kontoinhabers zu prüfen.</li><li>Für Abnahmetests werden Tests auf Grundlage dessen entworfen, wie der Bankmitarbeiter über die Annahme oder die Ablehnung einer Kreditanfrage entscheidet.</li></ol>Die folgenden Tests sind Beispiele nicht-funktionaler Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die die Anzahl von CPU-Zyklen bewerten, die erforderlich sind, um eine komplexe Gesamtverzinsung zu berechnen.</li><li>Für Komponentenintegrationstests werden IT-Sicherheitstests für SpeicherüberlaufSchwachstellen aufgrund von Daten, die von der Benutzungsschnittstelle an die fachliche Logik übertragen werden, entworfen.</li><li>Für Systemtests werden Übertragbarkeitstests entworfen, um zu prüfen, ob die Präsentationsschicht auf allen unterstützten Browsern und mobilen Endgeräten funktioniert.</li><li>Für Systemintegrationstests werden Zuverlässigkeitstests entworfen, die die Robustheit des Systems bewerten, falls der Bonitäts-Microservice nicht antwortet.</li><li>Für Abnahmetests werden Gebrauchstauglichkeitstests entworfen, die die Barrierefreiheit der Kreditbearbeitungsoberfläche des Bankmitarbeiters für Menschen mit Behinderung bewerten.</li></ol>Folgende Tests sind Beispiele für White-Box-Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die vollständige Anweisungsüberdeckung und Entscheidungsüberdeckung (siehe Abschnitt 4.3 White-Box-Testverfahren) für alle Komponenten, die Finanzberechnungen durchführen, erzielen sollen.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die testen, wie jeder Bildschirm der Browserbenutzungsoberfläche Daten an den nächsten Bildschirm und an die Fachlogik überträgt.</li><li>Für Systemtests werden Tests entworfen, die Reihenfolgen von Webseiten abdecken, die während einer Kreditanfrage auftauchen können.</li><li>Für Systemintegrationstests werden Tests entworfen, die alle möglichen Anfragearten ausführen, die an den Bonitäts-Microservice gesendet werden können.</li><li>Für Abnahmetests werden Tests entworfen, die alle unterstützten Dateistrukturen der Finanzdaten und Wertebereiche für zwischenbankliche Banküberweisungen abdecken.</li></ol>Die folgenden Tests sind schließlich Beispiele für änderungsbezogenes Testen:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden automatisierte Regressionstests für jede Komponente entworfen und innerhalb des Continuous-Integration-Frameworks integriert.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die die Beseitigung von schnittstellenbezogenen Fehlerzuständen bestätigen, sobald die Korrekturen im Code-Repository eingecheckt werden.</li><li>Für Systemtests werden alle Tests eines vorgegebenen Workflows wiederholt, falls ein Bildschirm in diesem Workflow sich geändert hat.</li><li>Für Systemintegrationstests werden Tests der Anwendung, die mit dem Bonitäts-Microservice interagiert, täglich als Teil der kontinuierlichen Verteilung (continuous deployment) des Microservice wiederholt.</li><li>Für Abnahmetests werden alle zuvor fehlgeschlagenen Tests wiederholt, nachdem ein Fehlerzustand, der bei Abnahmetests gefunden wurde, behoben worden ist.</li></ol>Obwohl dieser Abschnitt Beispiele für jede Testart in jeder Teststufe bereitstellt, ist es nicht für jede Software notwendig, jede Testart in jeder Stufe abzubilden. Allerdings ist es wichtig, in jeder Stufe angemessene Tests laufen zu lassen, insbesondere auf der untersten Stufe, auf der die Testart vorkommt.",
      "b": "FALSCH<br><br>Es ist möglich, jede der Testarten (funktional, nicht-funktional, White-Box) in jeder Teststufe durchzuführen. Deswegen ist die Aussage falsch, dass White-Box-Test auf Komponententests beschränkt ist. (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.5)<br><br>2.3.5 Testarten und Teststufen<br><br>Es ist möglich, jede der oben genannten Testarten in jeder Teststufe durchzuführen. Um dies zu veranschaulichen, werden für eine Bankanwendung Beispiele für funktionale, nicht-funktionale, White-Box- und änderungsbezogene Tests über alle Teststufen hinweg gegeben, beginnend mit funktionalen Tests: <ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests auf der Grundlage dessen entworfen, wie eine Komponente Zinseszinsen berechnet.</li><li>Für Komponentenintegrationstests werden Tests auf der Grundlage dessen entworfen, wie Kontoinformationen, die auf der Benutzeroberfläche erfasst werden, in die fachliche Logik übertragen werden.</li><li>Für Systemtests werden Tests auf Grundlage dessen entworfen, wie Kontoinhaber eine Kreditlinie für ihr Konto beantragen können.</li><li>Für Systemintegrationstests werden Tests auf Grundlage dessen entworfen, wie das System einen externen Microservice dafür nutzt, die Bonität eines Kontoinhabers zu prüfen.</li><li>Für Abnahmetests werden Tests auf Grundlage dessen entworfen, wie der Bankmitarbeiter über die Annahme oder die Ablehnung einer Kreditanfrage entscheidet.</li></ol>Die folgenden Tests sind Beispiele nicht-funktionaler Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die die Anzahl von CPU-Zyklen bewerten, die erforderlich sind, um eine komplexe Gesamtverzinsung zu berechnen.</li><li>Für Komponentenintegrationstests werden IT-Sicherheitstests für SpeicherüberlaufSchwachstellen aufgrund von Daten, die von der Benutzungsschnittstelle an die fachliche Logik übertragen werden, entworfen.</li><li>Für Systemtests werden Übertragbarkeitstests entworfen, um zu prüfen, ob die Präsentationsschicht auf allen unterstützten Browsern und mobilen Endgeräten funktioniert.</li><li>Für Systemintegrationstests werden Zuverlässigkeitstests entworfen, die die Robustheit des Systems bewerten, falls der Bonitäts-Microservice nicht antwortet.</li><li>Für Abnahmetests werden Gebrauchstauglichkeitstests entworfen, die die Barrierefreiheit der Kreditbearbeitungsoberfläche des Bankmitarbeiters für Menschen mit Behinderung bewerten.</li></ol>Folgende Tests sind Beispiele für White-Box-Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die vollständige Anweisungsüberdeckung und Entscheidungsüberdeckung (siehe Abschnitt 4.3 White-Box-Testverfahren) für alle Komponenten, die Finanzberechnungen durchführen, erzielen sollen.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die testen, wie jeder Bildschirm der Browserbenutzungsoberfläche Daten an den nächsten Bildschirm und an die Fachlogik überträgt.</li><li>Für Systemtests werden Tests entworfen, die Reihenfolgen von Webseiten abdecken, die während einer Kreditanfrage auftauchen können.</li><li>Für Systemintegrationstests werden Tests entworfen, die alle möglichen Anfragearten ausführen, die an den Bonitäts-Microservice gesendet werden können.</li><li>Für Abnahmetests werden Tests entworfen, die alle unterstützten Dateistrukturen der Finanzdaten und Wertebereiche für zwischenbankliche Banküberweisungen abdecken.</li></ol>Die folgenden Tests sind schließlich Beispiele für änderungsbezogenes Testen:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden automatisierte Regressionstests für jede Komponente entworfen und innerhalb des Continuous-Integration-Frameworks integriert.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die die Beseitigung von schnittstellenbezogenen Fehlerzuständen bestätigen, sobald die Korrekturen im Code-Repository eingecheckt werden.</li><li>Für Systemtests werden alle Tests eines vorgegebenen Workflows wiederholt, falls ein Bildschirm in diesem Workflow sich geändert hat.</li><li>Für Systemintegrationstests werden Tests der Anwendung, die mit dem Bonitäts-Microservice interagiert, täglich als Teil der kontinuierlichen Verteilung (continuous deployment) des Microservice wiederholt.</li><li>Für Abnahmetests werden alle zuvor fehlgeschlagenen Tests wiederholt, nachdem ein Fehlerzustand, der bei Abnahmetests gefunden wurde, behoben worden ist.</li></ol>Obwohl dieser Abschnitt Beispiele für jede Testart in jeder Teststufe bereitstellt, ist es nicht für jede Software notwendig, jede Testart in jeder Stufe abzubilden. Allerdings ist es wichtig, in jeder Stufe angemessene Tests laufen zu lassen, insbesondere auf der untersten Stufe, auf der die Testart vorkommt.",
      "c": "KORREKT<br><br>Es ist möglich, jede der Testarten (funktional, nicht-funktional, White-Box Test) in jeder Teststufe durchzuführen. (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.5)<br><br>2.3.5 Testarten und Teststufen<br><br>Es ist möglich, jede der oben genannten Testarten in jeder Teststufe durchzuführen. Um dies zu veranschaulichen, werden für eine Bankanwendung Beispiele für funktionale, nicht-funktionale, White-Box- und änderungsbezogene Tests über alle Teststufen hinweg gegeben, beginnend mit funktionalen Tests: <ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests auf der Grundlage dessen entworfen, wie eine Komponente Zinseszinsen berechnet.</li><li>Für Komponentenintegrationstests werden Tests auf der Grundlage dessen entworfen, wie Kontoinformationen, die auf der Benutzeroberfläche erfasst werden, in die fachliche Logik übertragen werden.</li><li>Für Systemtests werden Tests auf Grundlage dessen entworfen, wie Kontoinhaber eine Kreditlinie für ihr Konto beantragen können.</li><li>Für Systemintegrationstests werden Tests auf Grundlage dessen entworfen, wie das System einen externen Microservice dafür nutzt, die Bonität eines Kontoinhabers zu prüfen.</li><li>Für Abnahmetests werden Tests auf Grundlage dessen entworfen, wie der Bankmitarbeiter über die Annahme oder die Ablehnung einer Kreditanfrage entscheidet.</li></ol>Die folgenden Tests sind Beispiele nicht-funktionaler Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die die Anzahl von CPU-Zyklen bewerten, die erforderlich sind, um eine komplexe Gesamtverzinsung zu berechnen.</li><li>Für Komponentenintegrationstests werden IT-Sicherheitstests für SpeicherüberlaufSchwachstellen aufgrund von Daten, die von der Benutzungsschnittstelle an die fachliche Logik übertragen werden, entworfen.</li><li>Für Systemtests werden Übertragbarkeitstests entworfen, um zu prüfen, ob die Präsentationsschicht auf allen unterstützten Browsern und mobilen Endgeräten funktioniert.</li><li>Für Systemintegrationstests werden Zuverlässigkeitstests entworfen, die die Robustheit des Systems bewerten, falls der Bonitäts-Microservice nicht antwortet.</li><li>Für Abnahmetests werden Gebrauchstauglichkeitstests entworfen, die die Barrierefreiheit der Kreditbearbeitungsoberfläche des Bankmitarbeiters für Menschen mit Behinderung bewerten.</li></ol>Folgende Tests sind Beispiele für White-Box-Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die vollständige Anweisungsüberdeckung und Entscheidungsüberdeckung (siehe Abschnitt 4.3 White-Box-Testverfahren) für alle Komponenten, die Finanzberechnungen durchführen, erzielen sollen.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die testen, wie jeder Bildschirm der Browserbenutzungsoberfläche Daten an den nächsten Bildschirm und an die Fachlogik überträgt.</li><li>Für Systemtests werden Tests entworfen, die Reihenfolgen von Webseiten abdecken, die während einer Kreditanfrage auftauchen können.</li><li>Für Systemintegrationstests werden Tests entworfen, die alle möglichen Anfragearten ausführen, die an den Bonitäts-Microservice gesendet werden können.</li><li>Für Abnahmetests werden Tests entworfen, die alle unterstützten Dateistrukturen der Finanzdaten und Wertebereiche für zwischenbankliche Banküberweisungen abdecken.</li></ol>Die folgenden Tests sind schließlich Beispiele für änderungsbezogenes Testen:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden automatisierte Regressionstests für jede Komponente entworfen und innerhalb des Continuous-Integration-Frameworks integriert.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die die Beseitigung von schnittstellenbezogenen Fehlerzuständen bestätigen, sobald die Korrekturen im Code-Repository eingecheckt werden.</li><li>Für Systemtests werden alle Tests eines vorgegebenen Workflows wiederholt, falls ein Bildschirm in diesem Workflow sich geändert hat.</li><li>Für Systemintegrationstests werden Tests der Anwendung, die mit dem Bonitäts-Microservice interagiert, täglich als Teil der kontinuierlichen Verteilung (continuous deployment) des Microservice wiederholt.</li><li>Für Abnahmetests werden alle zuvor fehlgeschlagenen Tests wiederholt, nachdem ein Fehlerzustand, der bei Abnahmetests gefunden wurde, behoben worden ist.</li></ol>Obwohl dieser Abschnitt Beispiele für jede Testart in jeder Teststufe bereitstellt, ist es nicht für jede Software notwendig, jede Testart in jeder Stufe abzubilden. Allerdings ist es wichtig, in jeder Stufe angemessene Tests laufen zu lassen, insbesondere auf der untersten Stufe, auf der die Testart vorkommt.",
      "d": "FALSCH<br><br>Es ist möglich, jede der Testarten (funktional, nicht-funktional, White-Box) in jeder Teststufe durchzuführen. Deswegen ist die Aussage falsch, dass White-Box-Test auf Komponenten- und Integrationstests beschränkt ist. (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.5)<br><br>2.3.5 Testarten und Teststufen<br><br>Es ist möglich, jede der oben genannten Testarten in jeder Teststufe durchzuführen. Um dies zu veranschaulichen, werden für eine Bankanwendung Beispiele für funktionale, nicht-funktionale, White-Box- und änderungsbezogene Tests über alle Teststufen hinweg gegeben, beginnend mit funktionalen Tests: <ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests auf der Grundlage dessen entworfen, wie eine Komponente Zinseszinsen berechnet.</li><li>Für Komponentenintegrationstests werden Tests auf der Grundlage dessen entworfen, wie Kontoinformationen, die auf der Benutzeroberfläche erfasst werden, in die fachliche Logik übertragen werden.</li><li>Für Systemtests werden Tests auf Grundlage dessen entworfen, wie Kontoinhaber eine Kreditlinie für ihr Konto beantragen können.</li><li>Für Systemintegrationstests werden Tests auf Grundlage dessen entworfen, wie das System einen externen Microservice dafür nutzt, die Bonität eines Kontoinhabers zu prüfen.</li><li>Für Abnahmetests werden Tests auf Grundlage dessen entworfen, wie der Bankmitarbeiter über die Annahme oder die Ablehnung einer Kreditanfrage entscheidet.</li></ol>Die folgenden Tests sind Beispiele nicht-funktionaler Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die die Anzahl von CPU-Zyklen bewerten, die erforderlich sind, um eine komplexe Gesamtverzinsung zu berechnen.</li><li>Für Komponentenintegrationstests werden IT-Sicherheitstests für SpeicherüberlaufSchwachstellen aufgrund von Daten, die von der Benutzungsschnittstelle an die fachliche Logik übertragen werden, entworfen.</li><li>Für Systemtests werden Übertragbarkeitstests entworfen, um zu prüfen, ob die Präsentationsschicht auf allen unterstützten Browsern und mobilen Endgeräten funktioniert.</li><li>Für Systemintegrationstests werden Zuverlässigkeitstests entworfen, die die Robustheit des Systems bewerten, falls der Bonitäts-Microservice nicht antwortet.</li><li>Für Abnahmetests werden Gebrauchstauglichkeitstests entworfen, die die Barrierefreiheit der Kreditbearbeitungsoberfläche des Bankmitarbeiters für Menschen mit Behinderung bewerten.</li></ol>Folgende Tests sind Beispiele für White-Box-Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die vollständige Anweisungsüberdeckung und Entscheidungsüberdeckung (siehe Abschnitt 4.3 White-Box-Testverfahren) für alle Komponenten, die Finanzberechnungen durchführen, erzielen sollen.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die testen, wie jeder Bildschirm der Browserbenutzungsoberfläche Daten an den nächsten Bildschirm und an die Fachlogik überträgt.</li><li>Für Systemtests werden Tests entworfen, die Reihenfolgen von Webseiten abdecken, die während einer Kreditanfrage auftauchen können.</li><li>Für Systemintegrationstests werden Tests entworfen, die alle möglichen Anfragearten ausführen, die an den Bonitäts-Microservice gesendet werden können.</li><li>Für Abnahmetests werden Tests entworfen, die alle unterstützten Dateistrukturen der Finanzdaten und Wertebereiche für zwischenbankliche Banküberweisungen abdecken.</li></ol>Die folgenden Tests sind schließlich Beispiele für änderungsbezogenes Testen:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden automatisierte Regressionstests für jede Komponente entworfen und innerhalb des Continuous-Integration-Frameworks integriert.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die die Beseitigung von schnittstellenbezogenen Fehlerzuständen bestätigen, sobald die Korrekturen im Code-Repository eingecheckt werden.</li><li>Für Systemtests werden alle Tests eines vorgegebenen Workflows wiederholt, falls ein Bildschirm in diesem Workflow sich geändert hat.</li><li>Für Systemintegrationstests werden Tests der Anwendung, die mit dem Bonitäts-Microservice interagiert, täglich als Teil der kontinuierlichen Verteilung (continuous deployment) des Microservice wiederholt.</li><li>Für Abnahmetests werden alle zuvor fehlgeschlagenen Tests wiederholt, nachdem ein Fehlerzustand, der bei Abnahmetests gefunden wurde, behoben worden ist.</li></ol>Obwohl dieser Abschnitt Beispiele für jede Testart in jeder Teststufe bereitstellt, ist es nicht für jede Software notwendig, jede Testart in jeder Stufe abzubilden. Allerdings ist es wichtig, in jeder Stufe angemessene Tests laufen zu lassen, insbesondere auf der untersten Stufe, auf der die Testart vorkommt."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen vergleicht die Zwecke der Fehlernachtests und Regressionstests AM BESTEN miteinander?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Der Regressionstest stellt sicher, dass alle früher durchgeführten Tests immer noch korrekt laufen, während der Fehlernachtest sicherstellt, dass Korrekturen an einem Teil des Systems die anderen Teile nicht negativ beeinflussen.",
      "b": "Der Fehlernachtest prüft, dass ein vorher gefundener Fehlerzustand korrigiert wurde, während der Regressionstest sicherstellt, dass die Korrektur keine anderen Teile des Systems negativ beeinflusst hat.",
      "c": "Der Regressionstest stellt sicher, dass Korrekturen an einem Teil des Systems die anderen Teile nicht negativ beeinflussen, während der Fehlernachtest prüft, dass alle früher durchgeführten Tests immer noch die gleichen Ergebnisse produzieren.",
      "d": "Der Fehlernachtest bestätigt, dass die Änderungen am System erfolgreich durchgeführt wurden, während der Regressionstest Tests durchführt, die vorher fehlgeschlagen sind, um sicherzustellen, dass sie jetzt korrekt funktionieren."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Obwohl die Beschreibung des Regressionstests weitgehend richtig ist, ist die Beschreibung des Fehlernachtests (welcher bestätigen sollte, dass ein Fehlerzustand behoben wurde) falsch.",
      "b": "KORREKT<br><br>Die Beschreibungen von Fehlernachtest und Regressionstest entsprechen sinngemäß dem CTFL Lehrplan 2018, Abschnitt 2.3. Testarten<br><br>2.3 Testarten<br><br>Eine Testart ist eine Gruppe von Testaktivitäten, die darauf abzielt, spezifische Merkmale eines Softwaresystems oder eines Teils eines Systems auf der Grundlage spezifischer Testziele zu testen. Solche Ziele können u.a. sein:<ol style=\"list-style-type: circle;\"><li>Bewertung funktionaler Qualitätsmerkmale wie Vollständigkeit, Korrektheit und Angemessenheit</li><li>Bewertung nicht-funktionaler Qualitätsmerkmale wie Zuverlässigkeit, Performanz, IT-Sicherheit, Kompatibilität und Gebrauchstauglichkeit (Usability)</li><li>Bewertung, ob die Struktur oder Architektur der Komponente oder des Systems korrekt und vollständig ist und den Spezifikationen entspricht</li><li>Bewertung der Auswirkungen von Änderungen wie die Bestätigung, dass Fehlerzustände behoben wurden (Fehlernachtests), und die Suche nach nicht gewünschten Änderungen im Verhalten, die sich aus Software- oder Umgebungsänderungen ergeben (Regressionstests)</ol>2.3.1 Funktionale Tests<br><br>Funktionales Testen eines Systems beinhaltet Tests, die Funktionen bewerten, die das System ausführen soll. Funktionale Anforderungen können in Arbeitsergebnissen wie fachliche Anforderungsspezifikation, Epics, User-Stories, Anwendungsfällen oder funktionalen Spezifikationen beschrieben sein. Sie können allerdings auch undokumentiert sein. Die Funktionen sind das, „was” das System tun sollte.<br><br>Funktionale Tests sollten in allen Teststufen durchgeführt werden (z.B. können Komponententests auf einer Komponentenspezifikation basieren), obwohl der Fokus auf jeder Stufe ein anderer ist (siehe Abschnitt 2.2 Teststufen).<br><br>Funktionales Testen betrifft das Verhalten der Software. So können Black-Box-Verfahren genutzt werden,um Testbedingungen und Testfälle für die Funktionalität der Komponente oder des Systems abzuleiten (siehe Abschnitt 4.2 Black-Box-Testverfahren).<br><br>Die Gründlichkeit von funktionalen Tests kann durch die funktionale Überdeckung gemessen werden. Die funktionale Überdeckung ist der Grad, in dem eine gewisse Funktionalität durch Testen ausgeführt wurde, und wird als Prozentsatz der Arten ausgedrückt, die abgedeckt sind. Durch die Nutzung der Verfolgbarkeit zwischen Tests und funktionalen Anforderungen kann beispielsweise der Prozentsatz dieser Anforderungen, die durch die Tests angesprochen werden, berechnet werden. So können potenzielle Überdeckungslücken identifiziert werden.<br><br>Funktionaler Testentwurf und die Durchführung funktionaler Tests können spezielle Fähigkeiten oder Wissen erfordern, wie die Kenntnis des bestimmten Fachproblems, das die Software löst (z.B. geologische Modellierungssoftware für die Öl- und Gasindustrie).<br><br>2.3.2 Nicht-funktionale Tests<br><br>Nicht-funktionale Tests eines Systems bewerten Merkmale von Systemen und Software wie Gebrauchstauglichkeit, Performanz oder IT-Sicherheit. In der ISO-Norm ISO/IEC 25010 findet sich eine Klassifizierung von Softwarequalitätsmerkmalen. Nicht-funktionale Tests sind die Tests, die zeigen, “wie gut“ das System sich verhält.<br><br>Im Gegensatz zu gängigen Fehleinschätzungen können und sollten nicht-funktionale Tests in den meisten Fällen in allen Teststufen und das so früh wie möglich durchgeführt werden. Das späte Entdecken von nicht-funktionalen Fehlerzuständen kann für den Erfolg eines Projekts extrem gefährlich sein.<br><br>Um Testbedingungen und Testfälle für nicht-funktionale Tests abzuleiten, können Black-Box-Verfahren (siehe Abschnitt 4.2 Black-Box-Testverfahren) genutzt werden. Beispielsweise kann die Grenzwertanalyse genutzt werden, um die Stressbedingungen für Performanztests festzulegen.<br><br>Die Gründlichkeit von nicht-funktionalen Tests kann durch die nicht-funktionale Überdeckung gemessen werden. Nicht-funktionale Überdeckung ist der Grad, zu dem einige Arten von nicht-funktionalen Elementen durch Tests ausgeführt wurden, und wird als Prozentsatz der Arten der Elemente ausgedrückt, die abgedeckt sind. Beispielsweise lässt sich durch die Nutzung der Verfolgbarkeit zwischen Tests und unterstützten Endgeräten bei mobilen Applikationen der Prozentsatz der Endgeräte, die durch die Kompatibilitätstests betrachtet werden, berechnen, wodurch sich möglicherweise Überdeckungslücken aufdecken lassen.<br><br>Nicht-funktionaler Testentwurf und die Durchführung nicht-funktionaler Tests können spezielle Fähigkeiten oder Kenntnisse erfordern, wie die Kenntnis der zugrunde liegenden Schwächen eines Entwurfs oder einer Technologie (z.B. IT-Sicherheitsschwachstellen, die mit bestimmten Programmiersprachen verbunden sind) oder einer bestimmten Benutzergruppe (z.B. die Personas (Anwenderprofil (Scrum)) von Verwaltungssystemen für Gesundheitseinrichtungen).<br><br>In den ISTQB-ATA, ISTQB-ATTA und ISTQB-SEC sowie in anderen ISTQB-Spezialistenmodulen finden sich weitere Details bezüglich des Testens von nicht-funktionalen Qualitätsmerkmalen.<br><br>2.3.3 White-Box-Tests<br><br>White-Box-Tests leiten Tests auf Basis der internen Struktur oder der Implementierung eines Systems ab. Die interne Struktur kann Code, Architektur, Workflows und/oder Datenflüsse innerhalb des Systems enthalten (siehe Abschnitt 4.3 White-Box-Testverfahren).<br><br>Die Gründlichkeit von White-Box-Tests kann durch strukturelle Überdeckung gemessen werden. Strukturelle Überdeckung ist der Grad, zu dem einige Arten von strukturellen Elementen durch Tests ausgeführt wurden, und wird ausgedrückt durch den Prozentsatz der Elementart, die übergedeckt wurde.<br><br>Auf Stufe der Komponententests basiert die Codeüberdeckung auf dem Prozentsatz des Komponentencodes, der getestet wurde. Die Überdeckung kann in Bezug auf verschiedene Aspekte des Codes (Überdeckungselemente) gemessen werden, wie den Prozentsatz von ausführbaren Anweisungen oder den Prozentsatz von Entscheidungsergebnissen, die in der Komponente getestet wurden. Diese Überdeckungsarten werden zusammengefasst als Codeüberdeckung bezeichnet. Auf der Stufe der Komponentenintegrationstests kann White-Box-Testen auf der Architektur eines Systems basieren, wie den Schnittstellen zwischen den Komponenten. Die strukturelle Überdeckung kann hinsichtlich des Prozentsatzes der Schnittstellen gemessen werden, die durch die Tests ausgeführt wurden.<br><br>White-Box-Testentwurf und die Durchführung von White-Box-Tests können spezielle Fähigkeiten und Kenntnisse erfordern, wie Kenntnisse über die Art und Weise, wie der Code aufgebaut ist, wie Daten gespeichert werden (z.B. um mögliche Datenbankanfragen zu bewerten) und wie die Überdeckungswerkzeuge genutzt und ihre Ergebnisse korrekt interpretiert werden.<br><br>2.3.4 Änderungsbezogenes Testen<br><br>Wenn Änderungen an einem System vorgenommen werden, entweder um einen Fehlerzustand zu korrigieren oder aufgrund einer neuen oder geänderten Funktionalität, sollten Tests durchgeführt werden, um zu bestätigen, dass die Änderungen den Fehlerzustand korrigiert oder die Funktionalität korrekt umgesetzt haben und keine unvorhergesehenen nachteiligen Folgen hervorgerufen haben.<ol style=\"list-style-type: circle;\"><li>Fehlernachtests: Nachdem ein Fehlerzustand korrigiert wurde, muss die Software mit allen Testfällen getestet werden, die aufgrund des Fehlerzustands fehlgeschlagen sind. Diese sollten mit der neuen Softwareversion erneut ausgeführt werden. Die Software kann auch mit neuen Tests getestet werden, um Änderungen abzudecken, die nötig waren, um einen Fehlerzustand zu beheben. Zumindest müssen die Schritte, die die Fehlerwirkung, die durch den Fehlerzustand entstanden ist, reproduzieren konnten, in der neuen Softwareversion erneut durchgeführt werden. Der Zweck eines Fehlernachtests ist es, zu bestätigen, dass der ursprüngliche Fehlerzustand erfolgreich behoben wurde.</li><li>Regressionstests: Es ist möglich, dass eine Änderung, die in einem Teil des Codes gemacht wurde (egal, ob aufgrund einer Fehlerbehebung oder aufgrund einer anderen Art von Änderung) versehentlich das Verhalten anderer Teile des Codes beeinflusst. Sei es innerhalb der gleichen Komponente, in anderen Komponenten des gleichen Systems oder sogar in anderen Systemen. Änderungen können Änderungen in der Umgebung sein, wie z.B. eine neue Version eines Betriebssystems oder eines Datenbankmanagementsystems. Solche nicht gewünschten Nebeneffekte nennt man Regressionen. Regressionstests beinhalten die Durchführung von Tests, um solche unbeabsichtigten Nebeneffekte zu finden.</li></ol>Fehlernachtests und Regressionstests werden in allen Teststufen durchgeführt.<br><br>Insbesondere in iterativen und inkrementellen Entwicklungslebenszyklen (z.B. agile) resultieren neue Features, Änderungen zu bestehenden Features und Code-Restrukturierung (Refactoring) in häufigen Änderungen am Code, was in gleicher Weise änderungsbezogenes Testen erfordert. Aufgrund der sich kontinuierlich entwickelnden Beschaffenheit des Systems sind Fehlernachtests und Regressionstests sehr wichtig. Dies gilt insbesondere für Systeme des Internets der Dinge, bei denen individuelle Objekte (z.B. Endgeräte) häufig aktualisiert oder ersetzt werden.<br><br>Regressionstestsuiten laufen viele Male und entwickeln sich in der Regel nur langsam. So sind Regressionstests ein starker Kandidat für Testautomatisierung. Die Automatisierung dieser Tests sollte früh im Projekt beginnen (siehe Kapitel 6).<br><br>2.3.5 Testarten und Teststufen<br><br>Es ist möglich, jede der oben genannten Testarten in jeder Teststufe durchzuführen. Um dies zu veranschaulichen, werden für eine Bankanwendung Beispiele für funktionale, nicht-funktionale, White-Box- und änderungsbezogene Tests über alle Teststufen hinweg gegeben, beginnend mit funktionalen Tests:<br><ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests auf der Grundlage dessen entworfen, wie eine Komponente Zinseszinsen berechnet.</li><li>Für Komponentenintegrationstests werden Tests auf der Grundlage dessen entworfen, wie Kontoinformationen, die auf der Benutzeroberfläche erfasst werden, in die fachliche Logik übertragen werden.</li><li>Für Systemtests werden Tests auf Grundlage dessen entworfen, wie Kontoinhaber eine Kreditlinie für ihr Konto beantragen können.</li><li>Für Systemintegrationstests werden Tests auf Grundlage dessen entworfen, wie das System einen externen Microservice dafür nutzt, die Bonität eines Kontoinhabers zu prüfen.</li><li>Für Abnahmetests werden Tests auf Grundlage dessen entworfen, wie der Bankmitarbeiter über die Annahme oder die Ablehnung einer Kreditanfrage entscheidet.</li></ol>Die folgenden Tests sind Beispiele nicht-funktionaler Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die die Anzahl von CPU-Zyklen bewerten, die erforderlich sind, um eine komplexe Gesamtverzinsung zu berechnen.</li><li>Für Komponentenintegrationstests werden IT-Sicherheitstests für SpeicherüberlaufSchwachstellen aufgrund von Daten, die von der Benutzungsschnittstelle an die fachliche Logik übertragen werden, entworfen.</li><li>Für Systemtests werden Übertragbarkeitstests entworfen, um zu prüfen, ob die Präsentationsschicht auf allen unterstützten Browsern und mobilen Endgeräten funktioniert.</li><li>Für Systemintegrationstests werden Zuverlässigkeitstests entworfen, die die Robustheit des Systems bewerten, falls der Bonitäts-Microservice nicht antwortet.</li><li>Für Abnahmetests werden Gebrauchstauglichkeitstests entworfen, die die Barrierefreiheit der Kreditbearbeitungsoberfläche des Bankmitarbeiters für Menschen mit Behinderung bewerten.</li></ol>Folgende Tests sind Beispiele für White-Box-Tests:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden Tests entworfen, die vollständige Anweisungsüberdeckung und Entscheidungsüberdeckung (siehe Abschnitt 4.3 White-Box-Testverfahren) für alle Komponenten, die Finanzberechnungen durchführen, erzielen sollen.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die testen, wie jeder Bildschirm der Browserbenutzungsoberfläche Daten an den nächsten Bildschirm und an die Fachlogik überträgt.</li><li>Für Systemtests werden Tests entworfen, die Reihenfolgen von Webseiten abdecken, die während einer Kreditanfrage auftauchen können.</li><li>Für Systemintegrationstests werden Tests entworfen, die alle möglichen Anfragearten ausführen, die an den Bonitäts-Microservice gesendet werden können.</li><li>Für Abnahmetests werden Tests entworfen, die alle unterstützten Dateistrukturen der Finanzdaten und Wertebereiche für zwischenbankliche Banküberweisungen abdecken.</li></ol>Die folgenden Tests sind schließlich Beispiele für änderungsbezogenes Testen:<ol style=\"list-style-type: circle;\"><li>Für Komponententests werden automatisierte Regressionstests für jede Komponente entworfen und innerhalb des Continuous-Integration-Frameworks integriert.</li><li>Für Komponentenintegrationstests werden Tests entworfen, die die Beseitigung von schnittstellenbezogenen Fehlerzuständen bestätigen, sobald die Korrekturen im Code-Repository eingecheckt werden.</li><li>Für Systemtests werden alle Tests eines vorgegebenen Workflows wiederholt, falls ein Bildschirm in diesem Workflow sich geändert hat.</li><li>Für Systemintegrationstests werden Tests der Anwendung, die mit dem Bonitäts-Microservice interagiert, täglich als Teil der kontinuierlichen Verteilung (continuous deployment) des Microservice wiederholt.</li><li>Für Abnahmetests werden alle zuvor fehlgeschlagenen Tests wiederholt, nachdem ein Fehlerzustand, der bei Abnahmetests gefunden wurde, behoben worden ist.</li></ol>Obwohl dieser Abschnitt Beispiele für jede Testart in jeder Teststufe bereitstellt, ist es nicht für jede Software notwendig, jede Testart in jeder Stufe abzubilden. Allerdings ist es wichtig, in jeder Stufe angemessene Tests laufen zu lassen, insbesondere auf der untersten Stufe, auf der die Testart vorkommt.",
      "c": "FALSCH<br><br>Obwohl die Beschreibung des Regressionstests weitgehend richtig ist, ist die Beschreibung des Fehlernachtests (erneute Durchführung aller früher durchgeführten Tests) falsch. Der Zweck des Fehlernachtests ist zu prüfen, ob Tests, die früher fehlgeschlagen sind, jetzt korrekt funktionieren.",
      "d": "FALSCH<br><br>Obwohl die Beschreibung des Fehlernachtests weitgehend richtig ist, ist die Beschreibung des Regressionstests (Tests durchzuführen, die vorher fehlgeschlagen sind) falsch. Das würde eher einer detaillierteren Beschreibung des Fehlernachtests entsprechen."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen beschreibt eine Aufgabe der Auswirkungsanalyse im Wartungstest KORREKT?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die Auswirkungsanalyse unterstützt bei der Entscheidung, ob sich eine Fehlerkorrektur beim zu wartenden System lohnt.",
      "b": "Die Auswirkungsanalyse identifiziert, wie Daten in das gewartete System zu migrieren sind.",
      "c": "Die Auswirkungsanalyse unterstützt bei der Entscheidung, welche Hot Fixes den meisten Nutzen für den Benutzer haben.",
      "d": "Die Auswirkungsanalyse unterstützt die Ermittlung der Effektivität neuer Wartungstestfälle."
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Die Auswirkungsanalyse kann verwendet werden, um die Bereiche des Systems zu identifizieren, die von einer Fehlerbehebung betroffen sind. Daher kann das Ausmaß der Auswirkungen (z. B. nötige Regressionstests) verwendet werden, um bei der Entscheidung zu helfen, ob die Veränderung vorgenommen werden sollte (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.4.2).<br><br>2.4.2 Auswirkungsanalyse für Wartung<br><br>Die Auswirkungsanalyse bewertet die Veränderungen, die für ein Wartungsrelease gemacht wurden, um die gewünschten Folgen sowie die erwarteten als auch möglichen Nebeneffekte einer Veränderung zu identifizieren und um die Bereiche des Systems zu identifizieren, die von der Veränderung betroffen sind.<br>Die Auswirkungsanalyse kann auch dabei helfen, die Wirkung einer Veränderung auf bestehende Tests zu identifizieren. Die Nebeneffekte und betroffenen Bereiche im System müssen für Regressionen getestet werden, möglicherweise nach der Aktualisierung aller bestehenden Tests, die von der Veränderung betroffen sind.<br><br>Die Auswirkungsanalyse kann vor der Veränderung durchgeführt werden, um bei der Entscheidung zu helfen, ob die Veränderung vorgenommen werden sollte. Dies erfolgt auf der Grundlage der potenziellen Folgen für andere Bereiche des Systems.<br><br>Die Auswirkungsanalyse kann schwierig sein, wenn:<br><ol style=\"list-style-type: circle;\"><li>Spezifikationen (z.B. Fachanforderungen, User-Stories, Architektur) veraltet sind oder fehlen</li><li>Testfälle nicht dokumentiert oder veraltet sind</li><li>Bidirektionale Verfolgbarkeit zwischen Tests und der Testbasis nicht aufrechterhalten wurde</li><li>Werkzeugunterstützung schwach ist oder nicht existiert</li><li>Die beteiligten Personen keine Fach- oder Systemkenntnis haben</li><li>Während der Entwicklung nur ungenügende Aufmerksamkeit auf die Wartbarkeit der Software gelegt wurde</li></ol>",
      "b": "FALSCH<br><br>Obwohl der Test der migrierten Daten Teil des Wartungstests ist (siehe Konvertierungstest), ermittelt die Auswirkungsanalyse nicht, wie dieser Test auszusehen hat.",
      "c": "FALSCH<br><br>Die Auswirkungsanalyse ermittelt, welche Teile eines Systems von einer Änderung betroffen sind. Somit kann sie den Unterschied zwischen verschiedenen Hot Fixes in Hinsicht auf die Auswirkungen auf das System aufzeigen. Sie gibt aber keine Hinweise darauf, welchen Nutzen die Änderungen für den Benutzer haben.",
      "d": "FALSCH<br><br>Die Auswirkungsanalyse ermittelt, welche Teile eines Systems von einer Änderung betroffen sind. Sie kann aber keine Anhaltspunkte zur Effektivität von Testfällen liefern."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen gibt den Nutzen des statischen Tests KORREKT wieder?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Nach der Einführung von Reviews stellten wir fest, dass sich sowohl die Qualität der Spezifikationen als auch die für Entwicklung und Test benötigte Zeit erhöht haben.",
      "b": "Durch die Anwendung von statischem Test können wir den Test besser steuern und haben ein günstigeres Fehlermanagement, weil sich Fehlerzustände später im Lebenszyklus leichter finden lassen.",
      "c": "Da wir jetzt statische Analyse nutzen, haben fehlende Anforderungen abgenommen und die Kommunikation zwischen Testern und Entwicklern hat sich verbessert.",
      "d": "Seitdem wir statische Analysen eingeführt haben, finden wir Programmierfehler, die wir allein durch dynamischen Test möglicherweise nicht gefunden hätten."
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Reviews sollten die Qualität der Spezifikationen erhöhen, aber die für Entwicklung und Test benötigte Zeit verringern<br><br>(Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.1.2).<br><br>Statische Testverfahren haben eine Reihe von Vorteilen. Wenn sie früh im Softwareentwicklungslebenszyklus eingesetzt werden, können statische Tests das frühe Erkennen von Fehlerzuständen ermöglichen, noch bevor dynamische Tests durchgeführt werden (z.B. in Anforderungs- oder Entwurfsspezifikationsreviews, in Backlog-Refinements usw.). Fehlerzustände, die früh gefunden werden, lassen sich häufig kostengünstiger entfernen als Fehlerzustände, die später im Lebenszyklus gefunden werden, insbesondere im Vergleich zu Fehlerzuständen, die erst gefunden werden, nachdem die Software auf die Zielumgebung gebracht wurde und aktiv in Nutzung ist. Die Nutzung statischer Testverfahren zum Auffinden von Fehlerzuständen und die folgende prompte Behebung dieser Fehlerzustände ist für das Unternehmen fast immer kostengünstiger als der Einsatz dynamischer Tests zum Auffinden von Fehlerzuständen im Testobjekt und deren Behebung. Dies gilt insbesondere unter Berücksichtigung der zusätzlichen Kosten, die mit der Aktualisierung anderer Arbeitsergebnisse sowie der Durchführung von Fehlernachtests und Regressionstests einhergehen.<br><br>Zusätzliche Vorteile statischer Tests können u.a. sein:<br><br><ol style=\"list-style-type: circle;\"><li>Effizienteres Erkennen und Korrigieren von Fehlerzuständen schon vor der Durchführung dynamischer Tests</li><li>Identifizieren von Fehlerzuständen, die in dynamischen Tests nicht leicht zu finden sind</li><li>Verhindern von Fehlerzuständen im Entwurf oder der Kodierung durch das Aufdecken von Inkonsistenzen, Mehrdeutigkeiten, Widersprüchen, Auslassungen, Ungenauigkeiten und Redundanzen in Anforderungen</li><li>Erhöhen der Entwicklungsproduktivität (z.B. durch verbesserte Entwürfe, mehr wartungsfähigen Code)</li><li>Reduzieren von Entwicklungskosten und -zeit</li><li>Reduzieren von Testkosten und -zeit</li><li>Reduzieren der Gesamtkosten der Qualität über die Lebenszeit der Software hinweg, aufgrund</li>von weniger Fehlerwirkungen zu einem späteren Zeitpunkt im Lebenszyklus oder nach Auslieferung in die Produktion</li><li>Verbesserte Kommunikation zwischen Teammitgliedern durch die Teilnahme an Reviews</li></ol>",
      "b": "FALSCH<br><br>Die Behebung von Fehlerzuständen ist im Allgemeinen früher im Lebenszyklus leichter<br><br>(Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.1.2).<br><br>Statische Testverfahren haben eine Reihe von Vorteilen. Wenn sie früh im Softwareentwicklungslebenszyklus eingesetzt werden, können statische Tests das frühe Erkennen von Fehlerzuständen ermöglichen, noch bevor dynamische Tests durchgeführt werden (z.B. in Anforderungs- oder Entwurfsspezifikationsreviews, in Backlog-Refinements usw.). Fehlerzustände, die früh gefunden werden, lassen sich häufig kostengünstiger entfernen als Fehlerzustände, die später im Lebenszyklus gefunden werden, insbesondere im Vergleich zu Fehlerzuständen, die erst gefunden werden, nachdem die Software auf die Zielumgebung gebracht wurde und aktiv in Nutzung ist. Die Nutzung statischer Testverfahren zum Auffinden von Fehlerzuständen und die folgende prompte Behebung dieser Fehlerzustände ist für das Unternehmen fast immer kostengünstiger als der Einsatz dynamischer Tests zum Auffinden von Fehlerzuständen im Testobjekt und deren Behebung. Dies gilt insbesondere unter Berücksichtigung der zusätzlichen Kosten, die mit der Aktualisierung anderer Arbeitsergebnisse sowie der Durchführung von Fehlernachtests und Regressionstests einhergehen.<br><br>Zusätzliche Vorteile statischer Tests können u.a. sein:<br><br><ol style=\"list-style-type: circle;\"><li>Effizienteres Erkennen und Korrigieren von Fehlerzuständen schon vor der Durchführung dynamischer Tests</li><li>Identifizieren von Fehlerzuständen, die in dynamischen Tests nicht leicht zu finden sind</li><li>Verhindern von Fehlerzuständen im Entwurf oder der Kodierung durch das Aufdecken von Inkonsistenzen, Mehrdeutigkeiten, Widersprüchen, Auslassungen, Ungenauigkeiten und Redundanzen in Anforderungen</li><li>Erhöhen der Entwicklungsproduktivität (z.B. durch verbesserte Entwürfe, mehr wartungsfähigen Code)</li><li>Reduzieren von Entwicklungskosten und -zeit</li><li>Reduzieren von Testkosten und -zeit</li><li>Reduzieren der Gesamtkosten der Qualität über die Lebenszeit der Software hinweg, aufgrund</li>von weniger Fehlerwirkungen zu einem späteren Zeitpunkt im Lebenszyklus oder nach Auslieferung in die Produktion</li><li>Verbesserte Kommunikation zwischen Teammitgliedern durch die Teilnahme an Reviews</li></ol>",
      "c": "FALSCH<br><br>Reviews führen zu weniger fehlenden Anforderungen und besserer Kommunikation zwischen Testern und Entwicklern, aber Letzteres gilt nicht für statische Analysen<br><br>(Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.1.2)<br><br>Statische Testverfahren haben eine Reihe von Vorteilen. Wenn sie früh im Softwareentwicklungslebenszyklus eingesetzt werden, können statische Tests das frühe Erkennen von Fehlerzuständen ermöglichen, noch bevor dynamische Tests durchgeführt werden (z.B. in Anforderungs- oder Entwurfsspezifikationsreviews, in Backlog-Refinements usw.). Fehlerzustände, die früh gefunden werden, lassen sich häufig kostengünstiger entfernen als Fehlerzustände, die später im Lebenszyklus gefunden werden, insbesondere im Vergleich zu Fehlerzuständen, die erst gefunden werden, nachdem die Software auf die Zielumgebung gebracht wurde und aktiv in Nutzung ist. Die Nutzung statischer Testverfahren zum Auffinden von Fehlerzuständen und die folgende prompte Behebung dieser Fehlerzustände ist für das Unternehmen fast immer kostengünstiger als der Einsatz dynamischer Tests zum Auffinden von Fehlerzuständen im Testobjekt und deren Behebung. Dies gilt insbesondere unter Berücksichtigung der zusätzlichen Kosten, die mit der Aktualisierung anderer Arbeitsergebnisse sowie der Durchführung von Fehlernachtests und Regressionstests einhergehen.<br><br>Zusätzliche Vorteile statischer Tests können u.a. sein:<br><br><ol style=\"list-style-type: circle;\"><li>Effizienteres Erkennen und Korrigieren von Fehlerzuständen schon vor der Durchführung dynamischer Tests</li><li>Identifizieren von Fehlerzuständen, die in dynamischen Tests nicht leicht zu finden sind</li><li>Verhindern von Fehlerzuständen im Entwurf oder der Kodierung durch das Aufdecken von Inkonsistenzen, Mehrdeutigkeiten, Widersprüchen, Auslassungen, Ungenauigkeiten und Redundanzen in Anforderungen</li><li>Erhöhen der Entwicklungsproduktivität (z.B. durch verbesserte Entwürfe, mehr wartungsfähigen Code)</li><li>Reduzieren von Entwicklungskosten und -zeit</li><li>Reduzieren von Testkosten und -zeit</li><li>Reduzieren der Gesamtkosten der Qualität über die Lebenszeit der Software hinweg, aufgrund</li>von weniger Fehlerwirkungen zu einem späteren Zeitpunkt im Lebenszyklus oder nach Auslieferung in die Produktion</li><li>Verbesserte Kommunikation zwischen Teammitgliedern durch die Teilnahme an Reviews</li></ol>.",
      "d": "KORREKT<br><br>Dies ist ein Nutzen der statischen Analyse<br><br>(Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.1.2).<br><br>3.1.2 Vorteile des statischen Tests<br><br>Statische Testverfahren haben eine Reihe von Vorteilen. Wenn sie früh im Softwareentwicklungslebenszyklus eingesetzt werden, können statische Tests das frühe Erkennen von Fehlerzuständen ermöglichen, noch bevor dynamische Tests durchgeführt werden (z.B. in Anforderungs- oder Entwurfsspezifikationsreviews, in Backlog-Refinements usw.). Fehlerzustände, die früh gefunden werden, lassen sich häufig kostengünstiger entfernen als Fehlerzustände, die später im Lebenszyklus gefunden werden, insbesondere im Vergleich zu Fehlerzuständen, die erst gefunden werden, nachdem die Software auf die Zielumgebung gebracht wurde und aktiv in Nutzung ist. Die Nutzung statischer Testverfahren zum Auffinden von Fehlerzuständen und die folgende prompte Behebung dieser Fehlerzustände ist für das Unternehmen fast immer kostengünstiger als der Einsatz dynamischer Tests zum Auffinden von Fehlerzuständen im Testobjekt und deren Behebung. Dies gilt insbesondere unter Berücksichtigung der zusätzlichen Kosten, die mit der Aktualisierung anderer Arbeitsergebnisse sowie der Durchführung von Fehlernachtests und Regressionstests einhergehen.<br><br>Zusätzliche Vorteile statischer Tests können u.a. sein:<br><br><ol style=\"list-style-type: circle;\"><li>Effizienteres Erkennen und Korrigieren von Fehlerzuständen schon vor der Durchführung dynamischer Tests</li><li>Identifizieren von Fehlerzuständen, die in dynamischen Tests nicht leicht zu finden sind</li><li>Verhindern von Fehlerzuständen im Entwurf oder der Kodierung durch das Aufdecken von Inkonsistenzen, Mehrdeutigkeiten, Widersprüchen, Auslassungen, Ungenauigkeiten und Redundanzen in Anforderungen</li><li>Erhöhen der Entwicklungsproduktivität (z.B. durch verbesserte Entwürfe, mehr wartungsfähigen Code)</li><li>Reduzieren von Entwicklungskosten und -zeit</li><li>Reduzieren von Testkosten und -zeit</li><li>Reduzieren der Gesamtkosten der Qualität über die Lebenszeit der Software hinweg, aufgrund</li>von weniger Fehlerwirkungen zu einem späteren Zeitpunkt im Lebenszyklus oder nach Auslieferung in die Produktion</li><li>Verbesserte Kommunikation zwischen Teammitgliedern durch die Teilnahme an Reviews</li></ol>"
    }
  },
  {
    "frage": "Welche der folgenden Aussagen zur Anwendung von Checklisten bei einem formalen Review ist KORREKT?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Im Rahmen der Planung des Reviews erstellen die Reviewer die für das Review benötigten Checklisten.",
      "b": "Im Rahmen der Befundkommunikation füllen die Reviewer die für das Review bereitgestellten Checklisten aus.",
      "c": "Im Rahmen der Reviewsitzung erstellen die Reviewer auf Basis der für das Review bereitgestellten Checklisten Fehlerberichte.",
      "d": "Im Rahmen des Reviewbeginns (Kick-Off) erhalten die Reviewer die für das Review benötigten Checklisten."
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>In der Planung wird entschieden, ob Checklisten eingesetzt werden (vgl. Lehrplan, Abschnitt 3.2.1). Die Erstellung der Checklisten ist nicht Teil der Planung. Außerdem sind die Reviewer weder in die Planung involviert, noch für die Erstellung der Checklisten verantwortlich<br><br>(Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).<br><br>3.2.1 Reviewprozess für Arbeitsergebnisse<br>Der Reviewprozess umfasst die folgenden Hauptaktivitäten:<br><br>Planung<br><ol style=\"list-style-type: circle;\"><li>Definition des Umfangs inklusive des Zwecks des Reviews, welche Dokumente oder Teile von Dokumenten im Review einbezogen werden sollen und der Qualitätsmerkmale, die bewertet werden sollen</li><li>Schätzung von Aufwand und Zeitbedarf</li><li>Identifizieren von Revieweigenschaften wie der Reviewart mit Rollen, Aktivitäten und Checklisten</li><li>Auswahl der Personen, die am Review teilnehmen sollen, und Zuordnung der Rollen</li><li>Definition der Eingangs- und Endekriterien für formalere Reviewarten (z.B. Inspektionen)</li><li>Prüfung, ob Eingangskriterien erfüllt sind (für formalere Reviewarten)</li></ol>Reviewbeginn<br><ol style=\"list-style-type: circle;\"><li>Verteilen des Arbeitsergebnisses (physisch oder elektronisch) und anderer Materialien, wie Befund-Template, Checklisten und zugehörige Arbeitsergebnisse</li><li>Erläutern des Umfangs, der Ziele, des Prozesses, der Rollen und der Arbeitsergebnisse gegenüber den Teilnehmern</li><li>Beantwortung von Fragen, die die Teilnehmer zum Review haben könnten</li></ol>Individuelles Review (d.h. individuelle Vorbereitung)<br><ol style=\"list-style-type: circle;\"><li>Review des gesamten oder von Teilen des Arbeitsergebnisses</li><li>Aufzeichnung potenzieller Fehlerzustände, Empfehlungen und Fragen</li></ol>Befundkommunikation und -analyse<br><ol style=\"list-style-type: circle;\"><li>Kommunikation identifizierter potenzieller Fehlerzustände (z.B. in einer Reviewsitzung)</li><li>Analyse potenzieller Fehlerzustände, Zuweisung von Zuständigkeit und Status</li><li>Bewertung und Dokumentation von Qualitätsmerkmalen</li><li>Bewertung der Reviewbefunde gegenüber den Endekriterien, um eine Reviewentscheidung zu treffen (ablehnen, umfangreiche Änderungen notwendig, annehmen, vielleicht mit geringfügigen Änderungen)</li></ol>Fehlerbehebung und Bericht<br><ol style=\"list-style-type: circle;\"><li>Für die Befunde, die Änderungen an einem Arbeitsergebnis erfordern, Fehlerberichte erstellen</li><li>Beheben von im geprüften Arbeitsergebnis gefundenen Fehlerzuständen (üblicherweise durch den Autor)</li><li>Kommunikation von Fehlerzuständen an die zuständige Person oder das zuständige Team (wenn sie in einem Arbeitsergebnis gefunden wurden, das zu dem Arbeitsergebnis, welches geprüft wurde, in Beziehung steht)</li><li>Aufzeichnung des aktualisierten Status der Fehlerzustände (in formalen Reviews), potenziell auch mit der Zustimmung der Person, die den Befund erstellte</li><li>Sammeln von Metriken (für formalere Reviewarten)</li><li>Prüfen, dass Endekriterien erfüllt sind (für formalere Reviewarten)</li><li>Abnahme des Arbeitsergebnisses, wenn die Endekriterien erreicht sind</li></ol>Die Reviewergebnisse eines Arbeitsergebnisses können in Abhängigkeit von der Reviewart und der Formalität variieren, wie in Abschnitt 3.2.3 Reviewarten beschrieben.",
      "b": "FALSCH<br><br>In der Befundkommunikation werden im individuellen Review identifizierte potenzielle Fehlerzustände kommuniziert. Das Ausfüllen von Checklisten durch die Reviewer erfolgt, wenn überhaupt, bereits im individuellen Review (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.1).<br><br>3.2.1 Reviewprozess für Arbeitsergebnisse<br>Der Reviewprozess umfasst die folgenden Hauptaktivitäten:<br><br>Planung<br><ol style=\"list-style-type: circle;\"><li>Definition des Umfangs inklusive des Zwecks des Reviews, welche Dokumente oder Teile von Dokumenten im Review einbezogen werden sollen und der Qualitätsmerkmale, die bewertet werden sollen</li><li>Schätzung von Aufwand und Zeitbedarf</li><li>Identifizieren von Revieweigenschaften wie der Reviewart mit Rollen, Aktivitäten und Checklisten</li><li>Auswahl der Personen, die am Review teilnehmen sollen, und Zuordnung der Rollen</li><li>Definition der Eingangs- und Endekriterien für formalere Reviewarten (z.B. Inspektionen)</li><li>Prüfung, ob Eingangskriterien erfüllt sind (für formalere Reviewarten)</li></ol>Reviewbeginn<br><ol style=\"list-style-type: circle;\"><li>Verteilen des Arbeitsergebnisses (physisch oder elektronisch) und anderer Materialien, wie Befund-Template, Checklisten und zugehörige Arbeitsergebnisse</li><li>Erläutern des Umfangs, der Ziele, des Prozesses, der Rollen und der Arbeitsergebnisse gegenüber den Teilnehmern</li><li>Beantwortung von Fragen, die die Teilnehmer zum Review haben könnten</li></ol>Individuelles Review (d.h. individuelle Vorbereitung)<br><ol style=\"list-style-type: circle;\"><li>Review des gesamten oder von Teilen des Arbeitsergebnisses</li><li>Aufzeichnung potenzieller Fehlerzustände, Empfehlungen und Fragen</li></ol>Befundkommunikation und -analyse<br><ol style=\"list-style-type: circle;\"><li>Kommunikation identifizierter potenzieller Fehlerzustände (z.B. in einer Reviewsitzung)</li><li>Analyse potenzieller Fehlerzustände, Zuweisung von Zuständigkeit und Status</li><li>Bewertung und Dokumentation von Qualitätsmerkmalen</li><li>Bewertung der Reviewbefunde gegenüber den Endekriterien, um eine Reviewentscheidung zu treffen (ablehnen, umfangreiche Änderungen notwendig, annehmen, vielleicht mit geringfügigen Änderungen)</li></ol>Fehlerbehebung und Bericht<br><ol style=\"list-style-type: circle;\"><li>Für die Befunde, die Änderungen an einem Arbeitsergebnis erfordern, Fehlerberichte erstellen</li><li>Beheben von im geprüften Arbeitsergebnis gefundenen Fehlerzuständen (üblicherweise durch den Autor)</li><li>Kommunikation von Fehlerzuständen an die zuständige Person oder das zuständige Team (wenn sie in einem Arbeitsergebnis gefunden wurden, das zu dem Arbeitsergebnis, welches geprüft wurde, in Beziehung steht)</li><li>Aufzeichnung des aktualisierten Status der Fehlerzustände (in formalen Reviews), potenziell auch mit der Zustimmung der Person, die den Befund erstellte</li><li>Sammeln von Metriken (für formalere Reviewarten)</li><li>Prüfen, dass Endekriterien erfüllt sind (für formalere Reviewarten)</li><li>Abnahme des Arbeitsergebnisses, wenn die Endekriterien erreicht sind</li></ol>Die Reviewergebnisse eines Arbeitsergebnisses können in Abhängigkeit von der Reviewart und der Formalität variieren, wie in Abschnitt 3.2.3 Reviewarten beschrieben.",
      "c": "FALSCH<br><br>In der Reviewsitzung kommunizieren die Reviewer die im Rahmen des individuellen Reviews identifizierten potenziellen Fehlerzustände des Arbeitsergebnisses (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.1). Fehlerberichte werden erst in der Aktivität Fehlerbehebung und Bericht erstellt.<br><br>3.2.1 Reviewprozess für Arbeitsergebnisse<br>Der Reviewprozess umfasst die folgenden Hauptaktivitäten:<br><br>Planung<br><ol style=\"list-style-type: circle;\"><li>Definition des Umfangs inklusive des Zwecks des Reviews, welche Dokumente oder Teile von Dokumenten im Review einbezogen werden sollen und der Qualitätsmerkmale, die bewertet werden sollen</li><li>Schätzung von Aufwand und Zeitbedarf</li><li>Identifizieren von Revieweigenschaften wie der Reviewart mit Rollen, Aktivitäten und Checklisten</li><li>Auswahl der Personen, die am Review teilnehmen sollen, und Zuordnung der Rollen</li><li>Definition der Eingangs- und Endekriterien für formalere Reviewarten (z.B. Inspektionen)</li><li>Prüfung, ob Eingangskriterien erfüllt sind (für formalere Reviewarten)</li></ol>Reviewbeginn<br><ol style=\"list-style-type: circle;\"><li>Verteilen des Arbeitsergebnisses (physisch oder elektronisch) und anderer Materialien, wie Befund-Template, Checklisten und zugehörige Arbeitsergebnisse</li><li>Erläutern des Umfangs, der Ziele, des Prozesses, der Rollen und der Arbeitsergebnisse gegenüber den Teilnehmern</li><li>Beantwortung von Fragen, die die Teilnehmer zum Review haben könnten</li></ol>Individuelles Review (d.h. individuelle Vorbereitung)<br><ol style=\"list-style-type: circle;\"><li>Review des gesamten oder von Teilen des Arbeitsergebnisses</li><li>Aufzeichnung potenzieller Fehlerzustände, Empfehlungen und Fragen</li></ol>Befundkommunikation und -analyse<br><ol style=\"list-style-type: circle;\"><li>Kommunikation identifizierter potenzieller Fehlerzustände (z.B. in einer Reviewsitzung)</li><li>Analyse potenzieller Fehlerzustände, Zuweisung von Zuständigkeit und Status</li><li>Bewertung und Dokumentation von Qualitätsmerkmalen</li><li>Bewertung der Reviewbefunde gegenüber den Endekriterien, um eine Reviewentscheidung zu treffen (ablehnen, umfangreiche Änderungen notwendig, annehmen, vielleicht mit geringfügigen Änderungen)</li></ol>Fehlerbehebung und Bericht<br><ol style=\"list-style-type: circle;\"><li>Für die Befunde, die Änderungen an einem Arbeitsergebnis erfordern, Fehlerberichte erstellen</li><li>Beheben von im geprüften Arbeitsergebnis gefundenen Fehlerzuständen (üblicherweise durch den Autor)</li><li>Kommunikation von Fehlerzuständen an die zuständige Person oder das zuständige Team (wenn sie in einem Arbeitsergebnis gefunden wurden, das zu dem Arbeitsergebnis, welches geprüft wurde, in Beziehung steht)</li><li>Aufzeichnung des aktualisierten Status der Fehlerzustände (in formalen Reviews), potenziell auch mit der Zustimmung der Person, die den Befund erstellte</li><li>Sammeln von Metriken (für formalere Reviewarten)</li><li>Prüfen, dass Endekriterien erfüllt sind (für formalere Reviewarten)</li><li>Abnahme des Arbeitsergebnisses, wenn die Endekriterien erreicht sind</li></ol>Die Reviewergebnisse eines Arbeitsergebnisses können in Abhängigkeit von der Reviewart und der Formalität variieren, wie in Abschnitt 3.2.3 Reviewarten beschrieben.",
      "d": "KORREKT<br><br>Der Reviewbeginn (Kick-Off) umfasst das Verteilen des Arbeitsergebnisses und anderer Materialien, wie Checklisten (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.1).<br><br>3.2.1 Reviewprozess für Arbeitsergebnisse<br>Der Reviewprozess umfasst die folgenden Hauptaktivitäten:<br><br>Planung<br><ol style=\"list-style-type: circle;\"><li>Definition des Umfangs inklusive des Zwecks des Reviews, welche Dokumente oder Teile von Dokumenten im Review einbezogen werden sollen und der Qualitätsmerkmale, die bewertet werden sollen</li><li>Schätzung von Aufwand und Zeitbedarf</li><li>Identifizieren von Revieweigenschaften wie der Reviewart mit Rollen, Aktivitäten und Checklisten</li><li>Auswahl der Personen, die am Review teilnehmen sollen, und Zuordnung der Rollen</li><li>Definition der Eingangs- und Endekriterien für formalere Reviewarten (z.B. Inspektionen)</li><li>Prüfung, ob Eingangskriterien erfüllt sind (für formalere Reviewarten)</li></ol>Reviewbeginn<br><ol style=\"list-style-type: circle;\"><li>Verteilen des Arbeitsergebnisses (physisch oder elektronisch) und anderer Materialien, wie Befund-Template, Checklisten und zugehörige Arbeitsergebnisse</li><li>Erläutern des Umfangs, der Ziele, des Prozesses, der Rollen und der Arbeitsergebnisse gegenüber den Teilnehmern</li><li>Beantwortung von Fragen, die die Teilnehmer zum Review haben könnten</li></ol>Individuelles Review (d.h. individuelle Vorbereitung)<br><ol style=\"list-style-type: circle;\"><li>Review des gesamten oder von Teilen des Arbeitsergebnisses</li><li>Aufzeichnung potenzieller Fehlerzustände, Empfehlungen und Fragen</li></ol>Befundkommunikation und -analyse<br><ol style=\"list-style-type: circle;\"><li>Kommunikation identifizierter potenzieller Fehlerzustände (z.B. in einer Reviewsitzung)</li><li>Analyse potenzieller Fehlerzustände, Zuweisung von Zuständigkeit und Status</li><li>Bewertung und Dokumentation von Qualitätsmerkmalen</li><li>Bewertung der Reviewbefunde gegenüber den Endekriterien, um eine Reviewentscheidung zu treffen (ablehnen, umfangreiche Änderungen notwendig, annehmen, vielleicht mit geringfügigen Änderungen)</li></ol>Fehlerbehebung und Bericht<br><ol style=\"list-style-type: circle;\"><li>Für die Befunde, die Änderungen an einem Arbeitsergebnis erfordern, Fehlerberichte erstellen</li><li>Beheben von im geprüften Arbeitsergebnis gefundenen Fehlerzuständen (üblicherweise durch den Autor)</li><li>Kommunikation von Fehlerzuständen an die zuständige Person oder das zuständige Team (wenn sie in einem Arbeitsergebnis gefunden wurden, das zu dem Arbeitsergebnis, welches geprüft wurde, in Beziehung steht)</li><li>Aufzeichnung des aktualisierten Status der Fehlerzustände (in formalen Reviews), potenziell auch mit der Zustimmung der Person, die den Befund erstellte</li><li>Sammeln von Metriken (für formalere Reviewarten)</li><li>Prüfen, dass Endekriterien erfüllt sind (für formalere Reviewarten)</li><li>Abnahme des Arbeitsergebnisses, wenn die Endekriterien erreicht sind</li></ol>Die Reviewergebnisse eines Arbeitsergebnisses können in Abhängigkeit von der Reviewart und der Formalität variieren, wie in Abschnitt 3.2.3 Reviewarten beschrieben."
    }
  },
  {
    "frage": "Welche der folgenden Optionen gibt die Rollen und Verantwortlichkeiten in einem formalen Review KORREKT wieder?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Management – Entscheidet über die Durchführung von Reviews",
      "b": "Reviewleiter – Stellt den erfolgreichen Ablauf von Reviewsitzungen sicher",
      "c": "Protokollant – Behebt Fehlerzustände im Arbeitsergebnis, das einem Review unterzogen wurde",
      "d": "Moderator – Überwacht die stetige Kosteneffizienz"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Das Management entscheidet über die Durchführung von Reviews (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).<br><br>3.2.2 Rollen und Verantwortlichkeiten in einem formalen Review<br>Ein typisches formales Review umfasst die folgenden Rollen:<br><br>Autor<br><ol style=\"list-style-type: circle;\"><li>Erstellt das Arbeitsergebnis, das einem Review unterzogen wird</li><li>Behebt (falls notwendig) Fehlerzustände im Arbeitsergebnis, das einem Review unterzogen wurde</li></ol>Management<br><ol style=\"list-style-type: circle;\"><li>Ist verantwortlich für die Reviewplanung</li><li>Entscheidet über die Durchführung von Reviews</li><li>Legt Mitarbeiter, Budget und Fristen fest</li><li>Überwacht die stetige Kosteneffizienz</li><li>Trifft Steuerungsentscheidungen im Fall von unangemessenen Ergebnissen</li></ol>Reviewmoderator (oft auch Moderator genannt oder Facilitator)<br><ol style=\"list-style-type: circle;\"><li>Stellt den erfolgreichen Ablauf von Reviewsitzungen sicher (falls solche stattfinden)</li><li>Vermittelt, falls nötig, zwischen verschiedenen Standpunkten</li><li>Ist oft die Person, von der der Erfolg des Reviews abhängt</li></ol>Reviewleiter<br><ol style=\"list-style-type: circle;\"><li>Übernimmt die Verantwortung für das Review</li><li>Entscheidet, wer einbezogen wird, und bestimmt, wann und wo es stattfindet</li></ol>Gutachter<br><ol style=\"list-style-type: circle;\"><li>Können Fachexperten sein, Personen, die in dem Projekt arbeiten, Stakeholder mit einem Interesse an dem Arbeitsergebnis und/oder Einzelpersonen mit spezifischen technischen oder fachlichen Hintergründen</li><li>Identifizieren potenzielle Fehlerzustände des im Review befindlichen Arbeitsergebnisses</li><li>Können verschiedene Perspektiven vertreten (z.B. Tester, Entwickler, Benutzer, Betreiber, Businessanalysten, Experten für Gebrauchstauglichkeit)</li></ol>Protokollant<br><ol style=\"list-style-type: circle;\"><li>Erhebt potenzielle Fehlerzustände, die während der individuellen Reviewaktivitäten gefunden werden</li><li>Erfasst neue potenzielle Fehlerzustände, offene Punkte und Entscheidungen aus der Reviewsitzung (falls eine stattfindet)</li></ol>In einigen Reviewarten kann eine Person mehr als eine Rolle einnehmen und die Aktionen, die mit jeder Rolle in Verbindung stehen, können ebenso je nach Reviewart variieren. Darüber hinaus gibt es nach Einführung von Werkzeugen, die den Reviewprozess insbesondere bei der Aufzeichnung von Fehlerzuständen, offenen Punkten und Entscheidungen unterstützen, häufig keine Notwendigkeit mehr für einen Protokollanten.<br>Außerdem sind detailliertere Rollen möglich, wie in der ISO-Norm (ISO/IEC 20246) beschrieben.",
      "b": "FALSCH<br><br>Der Moderator stellt den erfolgreichen Ablauf von Reviewsitzungen sicher (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).<br><br>3.2.2 Rollen und Verantwortlichkeiten in einem formalen Review<br>Ein typisches formales Review umfasst die folgenden Rollen:<br><br>Autor<br><ol style=\"list-style-type: circle;\"><li>Erstellt das Arbeitsergebnis, das einem Review unterzogen wird</li><li>Behebt (falls notwendig) Fehlerzustände im Arbeitsergebnis, das einem Review unterzogen wurde</li></ol>Management<br><ol style=\"list-style-type: circle;\"><li>Ist verantwortlich für die Reviewplanung</li><li>Entscheidet über die Durchführung von Reviews</li><li>Legt Mitarbeiter, Budget und Fristen fest</li><li>Überwacht die stetige Kosteneffizienz</li><li>Trifft Steuerungsentscheidungen im Fall von unangemessenen Ergebnissen</li></ol>Reviewmoderator (oft auch Moderator genannt oder Facilitator)<br><ol style=\"list-style-type: circle;\"><li>Stellt den erfolgreichen Ablauf von Reviewsitzungen sicher (falls solche stattfinden)</li><li>Vermittelt, falls nötig, zwischen verschiedenen Standpunkten</li><li>Ist oft die Person, von der der Erfolg des Reviews abhängt</li></ol>Reviewleiter<br><ol style=\"list-style-type: circle;\"><li>Übernimmt die Verantwortung für das Review</li><li>Entscheidet, wer einbezogen wird, und bestimmt, wann und wo es stattfindet</li></ol>Gutachter<br><ol style=\"list-style-type: circle;\"><li>Können Fachexperten sein, Personen, die in dem Projekt arbeiten, Stakeholder mit einem Interesse an dem Arbeitsergebnis und/oder Einzelpersonen mit spezifischen technischen oder fachlichen Hintergründen</li><li>Identifizieren potenzielle Fehlerzustände des im Review befindlichen Arbeitsergebnisses</li><li>Können verschiedene Perspektiven vertreten (z.B. Tester, Entwickler, Benutzer, Betreiber, Businessanalysten, Experten für Gebrauchstauglichkeit)</li></ol>Protokollant<br><ol style=\"list-style-type: circle;\"><li>Erhebt potenzielle Fehlerzustände, die während der individuellen Reviewaktivitäten gefunden werden</li><li>Erfasst neue potenzielle Fehlerzustände, offene Punkte und Entscheidungen aus der Reviewsitzung (falls eine stattfindet)</li></ol>In einigen Reviewarten kann eine Person mehr als eine Rolle einnehmen und die Aktionen, die mit jeder Rolle in Verbindung stehen, können ebenso je nach Reviewart variieren. Darüber hinaus gibt es nach Einführung von Werkzeugen, die den Reviewprozess insbesondere bei der Aufzeichnung von Fehlerzuständen, offenen Punkten und Entscheidungen unterstützen, häufig keine Notwendigkeit mehr für einen Protokollanten.<br>Außerdem sind detailliertere Rollen möglich, wie in der ISO-Norm (ISO/IEC 20246) beschrieben.",
      "c": "FALSCH<br><br>Der Autor behebt Fehlerzustände im Arbeitsergebnis, das einem Review unterzogen wurde (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).<br><br>3.2.2 Rollen und Verantwortlichkeiten in einem formalen Review<br>Ein typisches formales Review umfasst die folgenden Rollen:<br><br>Autor<br><ol style=\"list-style-type: circle;\"><li>Erstellt das Arbeitsergebnis, das einem Review unterzogen wird</li><li>Behebt (falls notwendig) Fehlerzustände im Arbeitsergebnis, das einem Review unterzogen wurde</li></ol>Management<br><ol style=\"list-style-type: circle;\"><li>Ist verantwortlich für die Reviewplanung</li><li>Entscheidet über die Durchführung von Reviews</li><li>Legt Mitarbeiter, Budget und Fristen fest</li><li>Überwacht die stetige Kosteneffizienz</li><li>Trifft Steuerungsentscheidungen im Fall von unangemessenen Ergebnissen</li></ol>Reviewmoderator (oft auch Moderator genannt oder Facilitator)<br><ol style=\"list-style-type: circle;\"><li>Stellt den erfolgreichen Ablauf von Reviewsitzungen sicher (falls solche stattfinden)</li><li>Vermittelt, falls nötig, zwischen verschiedenen Standpunkten</li><li>Ist oft die Person, von der der Erfolg des Reviews abhängt</li></ol>Reviewleiter<br><ol style=\"list-style-type: circle;\"><li>Übernimmt die Verantwortung für das Review</li><li>Entscheidet, wer einbezogen wird, und bestimmt, wann und wo es stattfindet</li></ol>Gutachter<br><ol style=\"list-style-type: circle;\"><li>Können Fachexperten sein, Personen, die in dem Projekt arbeiten, Stakeholder mit einem Interesse an dem Arbeitsergebnis und/oder Einzelpersonen mit spezifischen technischen oder fachlichen Hintergründen</li><li>Identifizieren potenzielle Fehlerzustände des im Review befindlichen Arbeitsergebnisses</li><li>Können verschiedene Perspektiven vertreten (z.B. Tester, Entwickler, Benutzer, Betreiber, Businessanalysten, Experten für Gebrauchstauglichkeit)</li></ol>Protokollant<br><ol style=\"list-style-type: circle;\"><li>Erhebt potenzielle Fehlerzustände, die während der individuellen Reviewaktivitäten gefunden werden</li><li>Erfasst neue potenzielle Fehlerzustände, offene Punkte und Entscheidungen aus der Reviewsitzung (falls eine stattfindet)</li></ol>In einigen Reviewarten kann eine Person mehr als eine Rolle einnehmen und die Aktionen, die mit jeder Rolle in Verbindung stehen, können ebenso je nach Reviewart variieren. Darüber hinaus gibt es nach Einführung von Werkzeugen, die den Reviewprozess insbesondere bei der Aufzeichnung von Fehlerzuständen, offenen Punkten und Entscheidungen unterstützen, häufig keine Notwendigkeit mehr für einen Protokollanten.<br>Außerdem sind detailliertere Rollen möglich, wie in der ISO-Norm (ISO/IEC 20246) beschrieben.",
      "d": "FALSCH<br><br>Das Management überwacht die stetige Kosten-Wirksamkeits-Analyse (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).<br><br>3.2.2 Rollen und Verantwortlichkeiten in einem formalen Review<br>Ein typisches formales Review umfasst die folgenden Rollen:<br><br>Autor<br><ol style=\"list-style-type: circle;\"><li>Erstellt das Arbeitsergebnis, das einem Review unterzogen wird</li><li>Behebt (falls notwendig) Fehlerzustände im Arbeitsergebnis, das einem Review unterzogen wurde</li></ol>Management<br><ol style=\"list-style-type: circle;\"><li>Ist verantwortlich für die Reviewplanung</li><li>Entscheidet über die Durchführung von Reviews</li><li>Legt Mitarbeiter, Budget und Fristen fest</li><li>Überwacht die stetige Kosteneffizienz</li><li>Trifft Steuerungsentscheidungen im Fall von unangemessenen Ergebnissen</li></ol>Reviewmoderator (oft auch Moderator genannt oder Facilitator)<br><ol style=\"list-style-type: circle;\"><li>Stellt den erfolgreichen Ablauf von Reviewsitzungen sicher (falls solche stattfinden)</li><li>Vermittelt, falls nötig, zwischen verschiedenen Standpunkten</li><li>Ist oft die Person, von der der Erfolg des Reviews abhängt</li></ol>Reviewleiter<br><ol style=\"list-style-type: circle;\"><li>Übernimmt die Verantwortung für das Review</li><li>Entscheidet, wer einbezogen wird, und bestimmt, wann und wo es stattfindet</li></ol>Gutachter<br><ol style=\"list-style-type: circle;\"><li>Können Fachexperten sein, Personen, die in dem Projekt arbeiten, Stakeholder mit einem Interesse an dem Arbeitsergebnis und/oder Einzelpersonen mit spezifischen technischen oder fachlichen Hintergründen</li><li>Identifizieren potenzielle Fehlerzustände des im Review befindlichen Arbeitsergebnisses</li><li>Können verschiedene Perspektiven vertreten (z.B. Tester, Entwickler, Benutzer, Betreiber, Businessanalysten, Experten für Gebrauchstauglichkeit)</li></ol>Protokollant<br><ol style=\"list-style-type: circle;\"><li>Erhebt potenzielle Fehlerzustände, die während der individuellen Reviewaktivitäten gefunden werden</li><li>Erfasst neue potenzielle Fehlerzustände, offene Punkte und Entscheidungen aus der Reviewsitzung (falls eine stattfindet)</li></ol>In einigen Reviewarten kann eine Person mehr als eine Rolle einnehmen und die Aktionen, die mit jeder Rolle in Verbindung stehen, können ebenso je nach Reviewart variieren. Darüber hinaus gibt es nach Einführung von Werkzeugen, die den Reviewprozess insbesondere bei der Aufzeichnung von Fehlerzuständen, offenen Punkten und Entscheidungen unterstützen, häufig keine Notwendigkeit mehr für einen Protokollanten.<br>Außerdem sind detailliertere Rollen möglich, wie in der ISO-Norm (ISO/IEC 20246) beschrieben."
    }
  },
  {
    "frage": "Die Reviews in Ihrer Organisation haben die folgenden Eigenschaften:<ol style=\"list-style-type: circle;\"><li>Es gibt die Rolle des Protokollanten</li><li>Der Zweck ist es, potenzielle Fehlerzustände zu entdecken</li><li>Die Reviewsitzung wird vom Autor geleitet</li><li>Die Reviewer finden potenzielle Fehlerzustände durch individuelles Review</li><li>Es wird ein Reviewbericht erstellt</li></ol>Welche der folgenden Reviewarten wird hier AM WAHRSCHEINLICHSTEN verwendet?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Informelles Review",
      "b": "Walkthrough",
      "c": "Technisches Review",
      "d": "Inspektion"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Gemäß CTFL Lehrplan 2018, Abschnitt 3.2.3, lassen sich die genannten Eigenschaften wie folgt bewerten:<ol style=\"list-style-type: circle;\"><li>Es gibt die Rolle des Protokollanten – kommt bei Walkthrough, technischem Review und Inspektion vor, nicht aber bei informellem Review</li><li>Der Zweck ist es, potenzielle Fehlerzustände zu entdecken – dieser Zweck kommt bei allen Reviewarten vor</li><li>Die Reviewsitzung wird vom Autor geleitet – dies ist bei Inspektion ausgeschlossen, bei technischem Review untypisch, die Regel bei Walkthrough und erlaubt bei informellem Review</li><li>Die Reviewer finden potenzielle Fehlerzustände durch individuelles Review – alle Reviewarten einschließlich informellem Review können individuelles Review einschließen</li><li>Es wird ein Reviewbericht erstellt – bei allen Reviewarten kann ein Reviewbericht entstehen, obwohl das bei informellem Review weniger wahrscheinlich ist</li></ol>Daraus ergibt sich, dass Option b) am wahrscheinlichsten und damit korrekt ist.",
      "b": "KORREKT<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Gemäß CTFL Lehrplan 2018, Abschnitt 3.2.3, lassen sich die genannten Eigenschaften wie folgt bewerten:<ol style=\"list-style-type: circle;\"><li>Es gibt die Rolle des Protokollanten – kommt bei Walkthrough, technischem Review und Inspektion vor, nicht aber bei informellem Review</li><li>Der Zweck ist es, potenzielle Fehlerzustände zu entdecken – dieser Zweck kommt bei allen Reviewarten vor</li><li>Die Reviewsitzung wird vom Autor geleitet – dies ist bei Inspektion ausgeschlossen, bei technischem Review untypisch, die Regel bei Walkthrough und erlaubt bei informellem Review</li><li>Die Reviewer finden potenzielle Fehlerzustände durch individuelles Review – alle Reviewarten einschließlich informellem Review können individuelles Review einschließen</li><li>Es wird ein Reviewbericht erstellt – bei allen Reviewarten kann ein Reviewbericht entstehen, obwohl das bei informellem Review weniger wahrscheinlich ist</li></ol>Daraus ergibt sich, dass Option b) am wahrscheinlichsten und damit korrekt ist.",
      "c": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Gemäß CTFL Lehrplan 2018, Abschnitt 3.2.3, lassen sich die genannten Eigenschaften wie folgt bewerten:<ol style=\"list-style-type: circle;\"><li>Es gibt die Rolle des Protokollanten – kommt bei Walkthrough, technischem Review und Inspektion vor, nicht aber bei informellem Review</li><li>Der Zweck ist es, potenzielle Fehlerzustände zu entdecken – dieser Zweck kommt bei allen Reviewarten vor</li><li>Die Reviewsitzung wird vom Autor geleitet – dies ist bei Inspektion ausgeschlossen, bei technischem Review untypisch, die Regel bei Walkthrough und erlaubt bei informellem Review</li><li>Die Reviewer finden potenzielle Fehlerzustände durch individuelles Review – alle Reviewarten einschließlich informellem Review können individuelles Review einschließen</li><li>Es wird ein Reviewbericht erstellt – bei allen Reviewarten kann ein Reviewbericht entstehen, obwohl das bei informellem Review weniger wahrscheinlich ist</li></ol>Daraus ergibt sich, dass Option b) am wahrscheinlichsten und damit korrekt ist.",
      "d": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Gemäß CTFL Lehrplan 2018, Abschnitt 3.2.3, lassen sich die genannten Eigenschaften wie folgt bewerten:<ol style=\"list-style-type: circle;\"><li>Es gibt die Rolle des Protokollanten – kommt bei Walkthrough, technischem Review und Inspektion vor, nicht aber bei informellem Review</li><li>Der Zweck ist es, potenzielle Fehlerzustände zu entdecken – dieser Zweck kommt bei allen Reviewarten vor</li><li>Die Reviewsitzung wird vom Autor geleitet – dies ist bei Inspektion ausgeschlossen, bei technischem Review untypisch, die Regel bei Walkthrough und erlaubt bei informellem Review</li><li>Die Reviewer finden potenzielle Fehlerzustände durch individuelles Review – alle Reviewarten einschließlich informellem Review können individuelles Review einschließen</li><li>Es wird ein Reviewbericht erstellt – bei allen Reviewarten kann ein Reviewbericht entstehen, obwohl das bei informellem Review weniger wahrscheinlich ist</li></ol>Daraus ergibt sich, dass Option b) am wahrscheinlichsten und damit korrekt ist."
    }
  },
  {
    "frage": "Sie wurden gebeten, an einem checklistenbasierten Review des folgenden Auszuges aus einer Anforderungsspezifikation eines Bibliothekssystems teilzunehmen:<br><br>Bibliothekare können:<ol><li>Neue Nutzer registrieren.</li><li>Bücher von Nutzern zurücknehmen.</li><li>Mahngebühren für Nutzer erheben.</li><li>Neue Bücher mit deren ISBN, Autor und Titel dem System hinzufügen.</li><li>Bücher aus dem System löschen.</li><li>Systemrückmeldungen innerhalb von 5 Sekunden erhalten.</li></ol>Nutzer können:<br><ol start='7'><li>Maximal drei Bücher gleichzeitig ausleihen.</li><li>Die Historie ihrer ausgeliehen/reservierten Bücher anschauen.</li><li>Mit einer Mahngebühr wegen Nichtrückgabe eines Buches innerhalb von 3 Wochen belegt werden.</li><li>Systemrückmeldungen innerhalb von 3 Sekunden erhalten.</li><li>Ein Buch kostenfrei für maximal 4 Wochen ausleihen.</li><li>Bücher reservieren (falls sie ausgeliehen sind).</li></ol>Alle Benutzer (Bibliothekare und Nutzer):<br><ol start='13'><li>Können Bücher nach ISBN, Autor oder Titel suchen.</li><li>Können den Systemkatalog durchstöbern.</li><li>Das System soll innerhalb von 3 Sekunden auf Benutzeranfragen reagieren.</li><li>Die Benutzungsschnittstelle soll einfach zu bedienen sein.</li></ol>Ihnen wurde der Checklisteneintrag zugewiesen, der ein Review der Spezifikation auf Inkonsistenzen zwischen einzelnen Anforderungen vorsieht (beispielsweise Konflikte zwischen Anforderungen).<br><br>Welche folgenden Kombinationen weisen Inkonsistenzen zwischen Anforderungspaaren RICHTIG auf?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "6-10, 6-15, 7-12",
      "b": "6-15, 9-11",
      "c": "6-10, 6-15, 9-11",
      "d": "6-15, 7-12"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Zu betrachten werden die potenziellen Inkonsistenzen:<ol style=\"list-style-type: circle;\"><li>6-10 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das konsistent dazu, dass Nutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.</li><li>6-15 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das inkonsistent dazu, dass alle Benutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.</li><li>7-12 – Wenn sich Nutzer maximal 3 Bücher gleichzeitig ausleihen können, dann ist das konsistent dazu, dass sie sich Bücher reservieren können (falls sie ausgeliehen sind).</li><li>9-11 – Wenn ein Nutzer wegen Nichtrückgabe eines Buches innerhalb von 3 Wochen mit einer Mahngebühr belegt wird, dann ist das inkonsistent dazu, dass Bücher kostenlos für maximal 4 Wochen ausgeliehen werden dürfen. Die zwei Fristen sind unterschiedlich.</li></ol>Folglich ist Antwort b) korrekt.",
      "b": "KORREKT<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Zu betrachten werden die potenziellen Inkonsistenzen:<ol style=\"list-style-type: circle;\"><li>6-10 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das konsistent dazu, dass Nutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.</li><li>6-15 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das inkonsistent dazu, dass alle Benutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.</li><li>7-12 – Wenn sich Nutzer maximal 3 Bücher gleichzeitig ausleihen können, dann ist das konsistent dazu, dass sie sich Bücher reservieren können (falls sie ausgeliehen sind).</li><li>9-11 – Wenn ein Nutzer wegen Nichtrückgabe eines Buches innerhalb von 3 Wochen mit einer Mahngebühr belegt wird, dann ist das inkonsistent dazu, dass Bücher kostenlos für maximal 4 Wochen ausgeliehen werden dürfen. Die zwei Fristen sind unterschiedlich.</li></ol>Folglich ist Antwort b) korrekt.",
      "c": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Zu betrachten werden die potenziellen Inkonsistenzen:<ol style=\"list-style-type: circle;\"><li>6-10 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das konsistent dazu, dass Nutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.</li><li>6-15 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das inkonsistent dazu, dass alle Benutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.</li><li>7-12 – Wenn sich Nutzer maximal 3 Bücher gleichzeitig ausleihen können, dann ist das konsistent dazu, dass sie sich Bücher reservieren können (falls sie ausgeliehen sind).</li><li>9-11 – Wenn ein Nutzer wegen Nichtrückgabe eines Buches innerhalb von 3 Wochen mit einer Mahngebühr belegt wird, dann ist das inkonsistent dazu, dass Bücher kostenlos für maximal 4 Wochen ausgeliehen werden dürfen. Die zwei Fristen sind unterschiedlich.</li></ol>Folglich ist Antwort b) korrekt.",
      "d": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Zu betrachten werden die potenziellen Inkonsistenzen:<ol style=\"list-style-type: circle;\"><li>6-10 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das konsistent dazu, dass Nutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.</li><li>6-15 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das inkonsistent dazu, dass alle Benutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.</li><li>7-12 – Wenn sich Nutzer maximal 3 Bücher gleichzeitig ausleihen können, dann ist das konsistent dazu, dass sie sich Bücher reservieren können (falls sie ausgeliehen sind).</li><li>9-11 – Wenn ein Nutzer wegen Nichtrückgabe eines Buches innerhalb von 3 Wochen mit einer Mahngebühr belegt wird, dann ist das inkonsistent dazu, dass Bücher kostenlos für maximal 4 Wochen ausgeliehen werden dürfen. Die zwei Fristen sind unterschiedlich.</li></ol>Folglich ist Antwort b) korrekt."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen beschreibt AM BESTEN exploratives Testen?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Eine Testvorgehensweise/ein Testansatz, bei der eine intensive Untersuchung des Hintergrunds des Testobjekts dazu genutzt wird, mögliche Schwachstellen zu identifizieren, die durch Testfälle untersucht werden.",
      "b": "Eine Testvorgehensweise/ein Testansatz bei dem die Tester, basierend auf ihrem Wissen, der Erkundung des Testelements und dem Ergebnis früherer Tests, dynamisch Tests entwerfen und durchführen.",
      "c": "Eine Testvorgehensweise/ein Testansatz, bei dem die Testaktivitäten - insbesondere Testanalyse und Testentwurf - als unterbrechungsfreie Sitzungen geplant werden, oft in Verbindung mit checklisten-basiertem Testen.",
      "d": "Eine Testvorgehensweise/ein Testansatz, das auf der Erfahrung, dem Wissen und der Intuition des Testers basiert."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Exploratives Testen wird meistens bei kurzfristigen Zeitvorgaben durchgeführt, daher sind intensive Untersuchungen des Hintergrunds des Testobjekts eher ungewöhnlich.",
      "b": "KORREKT<br><br>Ein Testansatz, bei dem die Tests dynamisch entworfen und ausgeführt werden, basierend auf Wissen, der Erkundung des Testelements und den Ergebnissen früherer Tests.<br><br>(Definition Glossar V.3.3)<br><br>Ein Testansatz, bei dem die Tester auf der Grundlage ihres Wissens, der Erkundung des Testobjekts und der Ergebnisse früherer Tests dynamisch Tests entwerfen und durchführen.",
      "c": "FALSCH<br><br>Basiert auf der Definition des Glossars für sitzungsbasiertes Testen, jedoch wurde Testdurchführung durch Testanalyse ersetzt.",
      "d": "FALSCH<br><br>Basiert auf der Definition des Glossars für erfahrungsbasiertes Testen."
    }
  },
  {
    "frage": "Welche der folgenden Zuordnungen von Beschreibungen zu verschiedenen Kategorien von Testverfahren trifft AM BESTEN zu?<ol><li>Überdeckung wird auf Basis einer ausgewählten Struktur des Testobjektes gemessen.</li><li>Verarbeitung innerhalb des Testobjekts wird überprüft.</li><li>Tests basieren auf der Wahrscheinlichkeit von Fehlerzuständen und deren Verteilung.</li><li>Abweichungen von Anforderungen werden überprüft.</li><li>User-Stories werden als Testbasis herangezogen.</li></ol>Verwendete Notation für die folgenden 4 Optionen:<br><br>Black – Black-Box-Testverfahren<br>White – White-Box-Testverfahren<br>Erfahrung – erfahrungsbasiertes Testverfahren<br><br>Wählen Sie genau EINE korrekte Option aus! ",
    "inhalte": [],
    "antworten": {
      "a": "Black – 4, 5; White – 1, 2; Erfahrung – 3",
      "b": "Black – 3; White – 1, 2; Erfahrung – 4, 5",
      "c": "Black – 4; White – 1, 2; Erfahrung – 3, 5",
      "d": "Black – 1, 3, 5; White – 2; Erfahrung – 4"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Verknüpfung der Beschreibungen zu den verschiedenen Kategorien von Testverfahren entsprechend des Syllabus (4.1.1) ist:<br><ol style=\"list-style-type: circle;\"><li>Black-Box-Testverfahren:<br>Abweichungen von Anforderungen werden überprüft (4)<br>User-Stories werden als Testbasis herangezogen (5)</li><br><li>White-Box-Testverfahren:<br>Überdeckung wird auf Basis einer ausgewählten Struktur des Testobjektes gemessen (1)<br>Verarbeitung innerhalb des Testobjekts wird überprüft (2)</li><li>erfahrungsbasiertes Testverfahren:<br>Tests basieren auf der Wahrscheinlichkeit von Fehlerzuständen und deren Verteilung (3)</li></ol>Folglich ist Antwort a) korrekt.<br><br>4.1.1 Kategorien von Testverfahren und ihre Eigenschaften<br><br>In diesem Lehrplan werden Testverfahren als Black-Box-, White-Box- oder erfahrungsbasierte Testverfahren klassifiziert.<br>Black-Box-Testverfahren (auch spezifikationsbasierte Verfahren genannt) basieren auf einer Analyse der zugehörigen Testbasis (z.B. formale Anforderungsdokumente, Spezifikationen, Anwendungsfälle, User Stories oder Geschäftsprozesse). Diese Verfahren können sowohl auf funktionale als auch auf nichtfunktionale Tests angewendet werden. Black-Box-Testverfahren konzentrieren sich auf die Eingaben und Ausgaben des Testobjekts, ohne seine interne Struktur zu berücksichtigen.<br>White-Box-Testverfahren (auch strukturelle oder strukturbasierte Verfahren genannt) basieren auf einer Analyse der Architektur, dem Feinentwurf, der internen Struktur oder dem Code des Testobjekts. Anders als Black-Box-Testverfahren konzentrieren sich White-Box-Testverfahren auf die Struktur und die Abläufe innerhalb des Testobjekts.<br>Erfahrungsbasierte Testverfahren nutzen die Erfahrung von Entwicklern, Testern und Benutzern, um Tests zu entwerfen, umzusetzen und auszuführen. Diese Verfahren werden oft mit Black-Box- und White-Box Verfahren kombiniert<br><br>Gängige Merkmale von Black-Box-Testverfahren sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Testbedingungen, Testfälle und Testdaten werden aus einer Testbasis abgeleitet, die Softwareanforderungen, Spezifikationen, Anwendungsfälle und User-Stories beinhalten kann.</li><li>Testfälle können genutzt werden, um Lücken zwischen den Anforderungen und der Realisierung der Anforderungen sowie Abweichungen von den Anforderungen zu erkennen.</li><li>Die Überdeckung wird anhand der getesteten Elemente in der Testbasis gemessen und aufgrund der Verfahren, die auf die Testbasis angewendet wird.</li></ol>Gängige Merkmale von White-Box-Testverfahren sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Testbedingungen, Testfälle und Testdaten werden aus einer Testbasis abgeleitet, die Code, Softwarearchitektur, Feinentwurf oder andere Arten an Informationen zur Struktur der Software enthalten kann.</li><li>Die Überdeckung wird auf Basis der getesteten Elemente innerhalb einer ausgewählten Struktur gemessen (z.B. dem Code oder den Schnittstellen) und das Verfahren auf die Testbasis angewendet.</li></ol>Gängige Merkmale von erfahrungsbasierten Testverfahren sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Testbedingungen, Testfälle und Testdaten werden aus einer Testbasis abgeleitet, die schlicht aus den Kenntnissen und Erfahrungen der Tester, Entwickler, Benutzer und anderer Stakeholder bestehen kann.</li><li>Diese Kenntnisse und Erfahrungen beinhalten die erwartete Nutzung der Software, ihrer Umgebung, mögliche Fehlerzustände und die Verteilung dieser Fehlerzustände.</li></ol>Der internationale Standard ISO/IEC/IEEE 29119-4 enthält Beschreibungen von Testverfahren und ihren zugehörigen Überdeckungsmaßen (siehe Craig 2002 und Copeland 2004 für weitere Informationen über Verfahren).",
      "b": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Verknüpfung der Beschreibungen zu den verschiedenen Kategorien von Testverfahren entsprechend des Syllabus (4.1.1) ist:<br><ol style=\"list-style-type: circle;\"><li>Black-Box-Testverfahren:<br>Abweichungen von Anforderungen werden überprüft (4)<br>User-Stories werden als Testbasis herangezogen (5)</li><br><li>White-Box-Testverfahren:<br>Überdeckung wird auf Basis einer ausgewählten Struktur des Testobjektes gemessen (1)<br>Verarbeitung innerhalb des Testobjekts wird überprüft (2)</li><li>erfahrungsbasiertes Testverfahren:<br>Tests basieren auf der Wahrscheinlichkeit von Fehlerzuständen und deren Verteilung (3)</li></ol>Folglich ist Antwort a) korrekt.",
      "c": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Verknüpfung der Beschreibungen zu den verschiedenen Kategorien von Testverfahren entsprechend des Syllabus (4.1.1) ist:<br><ol style=\"list-style-type: circle;\"><li>Black-Box-Testverfahren:<br>Abweichungen von Anforderungen werden überprüft (4)<br>User-Stories werden als Testbasis herangezogen (5)</li><br><li>White-Box-Testverfahren:<br>Überdeckung wird auf Basis einer ausgewählten Struktur des Testobjektes gemessen (1)<br>Verarbeitung innerhalb des Testobjekts wird überprüft (2)</li><li>erfahrungsbasiertes Testverfahren:<br>Tests basieren auf der Wahrscheinlichkeit von Fehlerzuständen und deren Verteilung (3)</li></ol>Folglich ist Antwort a) korrekt.",
      "d": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Verknüpfung der Beschreibungen zu den verschiedenen Kategorien von Testverfahren entsprechend des Syllabus (4.1.1) ist:<br><ol style=\"list-style-type: circle;\"><li>Black-Box-Testverfahren:<br>Abweichungen von Anforderungen werden überprüft (4)<br>User-Stories werden als Testbasis herangezogen (5)</li><br><li>White-Box-Testverfahren:<br>Überdeckung wird auf Basis einer ausgewählten Struktur des Testobjektes gemessen (1)<br>Verarbeitung innerhalb des Testobjekts wird überprüft (2)</li><li>erfahrungsbasiertes Testverfahren:<br>Tests basieren auf der Wahrscheinlichkeit von Fehlerzuständen und deren Verteilung (3)</li></ol>Folglich ist Antwort a) korrekt."
    }
  },
  {
    "frage": "Eine Fitness-App misst die Anzahl der täglich gelaufenen Schritte und gibt dazu Feedback, um den Anwender zu motivieren, fit zu bleiben.<br><br>Das Feedback zu den verschiedenen Schrittzahlen soll sein:<br>",
    "inhalte": [
      {
        "typ": "tabelle",
        "inhalt": {
          "koerper": [
            [
              "Bis zu 1000",
              "- Couch Potato!"
            ],
            [
              "Über 1000, bis zu 2000",
              "- Faulpelz!"
            ],
            [
              "Über 2000, bis zu 4000 ",
              "- Die Richtung stimmt!"
            ],
            [
              "Über 4000, bis zu 6000",
              "- Nicht schlecht!"
            ],
            [
              "Über 6000",
              "- Super!"
            ]
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Welche der folgenden Gruppen von Testeingabewerten würde für die BESTE Überdeckung von Äquivalenzklassen sorgen?<br><br>Wählen Sie genau EINE korrekte Option aus."
      }
    ],
    "antworten": {
      "a": "0, 1000, 2000, 3000, 4000",
      "b": "1000, 2001, 4000, 4001, 6000",
      "c": "123, 2345, 3456, 4567, 5678",
      "d": "666, 999, 2222, 5555, 6666"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die folgenden gültigen Äquivalenzklassen können gebildet werden:<ol><li>≤ 1000 - Couch Potato!</li><li>1001 - 2000 - Faulpelz!</li><li>2001 - 4000 - Die Richtung stimmt!</li><li>4001 - 6000 - Nicht schlecht!</li><li>> 6000 - Super!</li></ol>Die Gruppen von Testeingabewerten decken daher folgende Klassen ab:<ol style=\"list-style-type: lower-alpha;\"><li>0 (1), 1000 (1), 2000 (2), 3000 (3), 4000 (3) – 3 Klassen (von 5).</li><li>1000 (1), 2001 (3), 4000 (3), 4001 (4), 6000 (4) – 3 Klassen (von 5).</li><li>123 (1), 2345 (3), 3456 (3), 4567 (4), 5678 (4) – 3 Klassen (von 5).</li><li>666 (1), 999 (1), 2222 (3), 5555 (4), 6666 (5) – 4 Klassen (von 5)</li></ol>Folglich ist Option d) richtig.",
      "b": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die folgenden gültigen Äquivalenzklassen können gebildet werden:<ol><li>≤ 1000 - Couch Potato!</li><li>1001 - 2000 - Faulpelz!</li><li>2001 - 4000 - Die Richtung stimmt!</li><li>4001 - 6000 - Nicht schlecht!</li><li>> 6000 - Super!</li></ol>Die Gruppen von Testeingabewerten decken daher folgende Klassen ab:<ol style=\"list-style-type: lower-alpha;\"><li>0 (1), 1000 (1), 2000 (2), 3000 (3), 4000 (3) – 3 Klassen (von 5).</li><li>1000 (1), 2001 (3), 4000 (3), 4001 (4), 6000 (4) – 3 Klassen (von 5).</li><li>123 (1), 2345 (3), 3456 (3), 4567 (4), 5678 (4) – 3 Klassen (von 5).</li><li>666 (1), 999 (1), 2222 (3), 5555 (4), 6666 (5) – 4 Klassen (von 5)</li></ol>Folglich ist Option d) richtig.",
      "c": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die folgenden gültigen Äquivalenzklassen können gebildet werden:<ol><li>≤ 1000 - Couch Potato!</li><li>1001 - 2000 - Faulpelz!</li><li>2001 - 4000 - Die Richtung stimmt!</li><li>4001 - 6000 - Nicht schlecht!</li><li>> 6000 - Super!</li></ol>Die Gruppen von Testeingabewerten decken daher folgende Klassen ab:<ol style=\"list-style-type: lower-alpha;\"><li>0 (1), 1000 (1), 2000 (2), 3000 (3), 4000 (3) – 3 Klassen (von 5).</li><li>1000 (1), 2001 (3), 4000 (3), 4001 (4), 6000 (4) – 3 Klassen (von 5).</li><li>123 (1), 2345 (3), 3456 (3), 4567 (4), 5678 (4) – 3 Klassen (von 5).</li><li>666 (1), 999 (1), 2222 (3), 5555 (4), 6666 (5) – 4 Klassen (von 5)</li></ol>Folglich ist Option d) richtig.",
      "d": "KORREKT<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die folgenden gültigen Äquivalenzklassen können gebildet werden:<ol><li>≤ 1000 - Couch Potato!</li><li>1001 - 2000 - Faulpelz!</li><li>2001 - 4000 - Die Richtung stimmt!</li><li>4001 - 6000 - Nicht schlecht!</li><li>> 6000 - Super!</li></ol>Die Gruppen von Testeingabewerten decken daher folgende Klassen ab:<ol style=\"list-style-type: lower-alpha;\"><li>0 (1), 1000 (1), 2000 (2), 3000 (3), 4000 (3) – 3 Klassen (von 5).</li><li>1000 (1), 2001 (3), 4000 (3), 4001 (4), 6000 (4) – 3 Klassen (von 5).</li><li>123 (1), 2345 (3), 3456 (3), 4567 (4), 5678 (4) – 3 Klassen (von 5).</li><li>666 (1), 999 (1), 2222 (3), 5555 (4), 6666 (5) – 4 Klassen (von 5)</li></ol>Folglich ist Option d) richtig."
    }
  },
  {
    "frage": "Ein Gerät zur Messung des täglichen Strahlungseinfalls für Pflanzen ermittelt einen Einstrahlungswert für Sonnenschein. Dieser ergibt sich aus der Kombination der Anzahl der Stunden, in denen eine Pflanze der Sonne ausgesetzt ist (unter 3 Stunden, 3 bis 6 Stunden, über 6 Stunden) und der durchschnittlichen Intensität des Sonnenscheins (sehr niedrig, niedrig, mittel, hoch). Die folgenden Testfälle existieren bereits:",
    "inhalte": [
      {
        "typ": "tabelle",
        "inhalt": {
          "kopf": [
            "",
            "Dauer (Stunden)",
            "Intensität",
            "Einstrahlung"
          ],
          "koerper": [
            [
              "T1",
              "1,5",
              "sehr niedrig",
              "10"
            ],
            [
              "T2",
              "7,0",
              "mittel",
              "60"
            ],
            [
              "T3",
              "0,5",
              "sehr niedrig",
              "10"
            ]
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Wie viele Testfälle müssen mindestens noch erzeugt werden, um eine vollständige Überdeckung ALLER GÜLTIGEN Eingabe-Äquivalenz klassen zu gewährleisten?<br><br>Wählen Sie genau EINE korrekte Option aus."
      }
    ],
    "antworten": {
      "a": "1",
      "b": "2",
      "c": "3",
      "d": "4"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die folgenden Äquivalenzklassen können identifiziert werden:<ol style=\"list-style-type: circle;\"><li>Dauer</li><ol><li>Unter 3 Stunden</li><li>3 – 6 Stunden</li><li>Über 6 Stunden</li></ol><li>Intensität</li><ol start='4'><li>sehr niedrig</li><li>niedrig</li><li>mittel</li><li>hoch</li></ol></ol>Die existierenden Testfälle decken die folgenden gültigen Eingabe- Äquivalenzklassen ab:<br><br>T1 1,5(1) sehr niedrig (4)<br><br>T2 7,0 (3) mittel (6)<br><br>T3 0,5 (1) sehr niedrig (4)<br><br>Folglich sind die fehlenden gültigen Eingabe- Äquivalenzklassen (2), (5) und (7).<br><br>Sie können mit zwei zusätzlichen Testfällen abgedeckt werden, da (2) sowohl mit (5) als auch mit (7) kombiniert werden kann.<br><br>Folglich ist Antwort b) richtig.",
      "b": "KORREKT<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die folgenden Äquivalenzklassen können identifiziert werden:<ol style=\"list-style-type: circle;\"><li>Dauer</li><ol><li>Unter 3 Stunden</li><li>3 – 6 Stunden</li><li>Über 6 Stunden</li></ol><li>Intensität</li><ol start='4'><li>sehr niedrig</li><li>niedrig</li><li>mittel</li><li>hoch</li></ol></ol>Die existierenden Testfälle decken die folgenden gültigen Eingabe- Äquivalenzklassen ab:<br><br>T1 1,5(1) sehr niedrig (4)<br><br>T2 7,0 (3) mittel (6)<br><br>T3 0,5 (1) sehr niedrig (4)<br><br>Folglich sind die fehlenden gültigen Eingabe- Äquivalenzklassen (2), (5) und (7).<br><br>Sie können mit zwei zusätzlichen Testfällen abgedeckt werden, da (2) sowohl mit (5) als auch mit (7) kombiniert werden kann.<br><br>Folglich ist Antwort b) richtig.",
      "c": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die folgenden Äquivalenzklassen können identifiziert werden:<ol style=\"list-style-type: circle;\"><li>Dauer</li><ol><li>Unter 3 Stunden</li><li>3 – 6 Stunden</li><li>Über 6 Stunden</li></ol><li>Intensität</li><ol start='4'><li>sehr niedrig</li><li>niedrig</li><li>mittel</li><li>hoch</li></ol></ol>Die existierenden Testfälle decken die folgenden gültigen Eingabe- Äquivalenzklassen ab:<br><br>T1 1,5(1) sehr niedrig (4)<br><br>T2 7,0 (3) mittel (6)<br><br>T3 0,5 (1) sehr niedrig (4)<br><br>Folglich sind die fehlenden gültigen Eingabe- Äquivalenzklassen (2), (5) und (7).<br><br>Sie können mit zwei zusätzlichen Testfällen abgedeckt werden, da (2) sowohl mit (5) als auch mit (7) kombiniert werden kann.<br><br>Folglich ist Antwort b) richtig.",
      "d": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die folgenden Äquivalenzklassen können identifiziert werden:<ol style=\"list-style-type: circle;\"><li>Dauer</li><ol><li>Unter 3 Stunden</li><li>3 – 6 Stunden</li><li>Über 6 Stunden</li></ol><li>Intensität</li><ol start='4'><li>sehr niedrig</li><li>niedrig</li><li>mittel</li><li>hoch</li></ol></ol>Die existierenden Testfälle decken die folgenden gültigen Eingabe- Äquivalenzklassen ab:<br><br>T1 1,5(1) sehr niedrig (4)<br><br>T2 7,0 (3) mittel (6)<br><br>T3 0,5 (1) sehr niedrig (4)<br><br>Folglich sind die fehlenden gültigen Eingabe- Äquivalenzklassen (2), (5) und (7).<br><br>Sie können mit zwei zusätzlichen Testfällen abgedeckt werden, da (2) sowohl mit (5) als auch mit (7) kombiniert werden kann.<br><br>Folglich ist Antwort b) richtig."
    }
  },
  {
    "frage": "Eine Smart-Home-App misst die durchschnittliche Temperatur im Haus während der vergangenen Woche und gibt den Bewohnern basierend auf diesem Wert Informationen zur Umweltfreundlichkeit ihres Verhaltens. Das Feedback für die verschiedenen Durchschnittstemperaturbereiche (gerundet auf die nächsten ganzen °C) soll lauten:",
    "inhalte": [
      {
        "typ": "tabelle",
        "inhalt": {
          "koerper": [
            [
              "Bis zu 10°C",
              "Eiskalt!"
            ],
            [
              "11°C bis 15°C",
              "Ganz schön schattig!"
            ],
            [
              "16°C bis 19°C",
              "Cool!"
            ],
            [
              "20°C bis 22°C",
              "Zu warm!"
            ],
            [
              "Über 22°C",
              "Sauna!"
            ]
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Welches der folgenden Testsets liefert die höchste Überdeckung von Grenzwerten, wenn die Grenzwertanalyse ausschließlich unter Verwendung der Minimal- und Maximalwerte verwendet wird?<br><br>Wählen Sie genau EINE korrekte Option aus."
      }
    ],
    "antworten": {
      "a": "0°C, 11°C, 20°C, 22°C, 23°C",
      "b": "9°C, 15°C, 19°C, 23°C, 100°C",
      "c": "10°C, 16°C, 19°C, 22°C, 23°C",
      "d": "14°C, 15°C, 18°C, 19°C, 21°C 22°C"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Bei den angegebenen Eingabe-Äquivalenzklassen ergibt das Zwei-Punkt Grenzwertverfahren folgende 8 Überdeckungselemente:<br><br>10°C, 11°C, 15°C, 16°C, 19°C, 20°C, 22°C, 23°C.<br><br>Die Überdeckung durch die Optionen ist folglich jeweils:<br><ol style=\"list-style-type: lower-alpha;\"><li>4 von 8 (11, 20 ,22 und 23).</li><li>3 von 8 (15, 19 und 23).</li><li>5 von 8 (10, 16, 19, 22 und 23).</li><li>3 von 8 (15, 19 und 22)</li></ol>Folglich ist Option c) richtig.",
      "b": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Bei den angegebenen Eingabe-Äquivalenzklassen ergibt das Zwei-Punkt Grenzwertverfahren folgende 8 Überdeckungselemente:<br><br>10°C, 11°C, 15°C, 16°C, 19°C, 20°C, 22°C, 23°C.<br><br>Die Überdeckung durch die Optionen ist folglich jeweils:<br><ol style=\"list-style-type: lower-alpha;\"><li>4 von 8 (11, 20 ,22 und 23).</li><li>3 von 8 (15, 19 und 23).</li><li>5 von 8 (10, 16, 19, 22 und 23).</li><li>3 von 8 (15, 19 und 22)</li></ol>Folglich ist Option c) richtig.",
      "c": "KORREKT<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Bei den angegebenen Eingabe-Äquivalenzklassen ergibt das Zwei-Punkt Grenzwertverfahren folgende 8 Überdeckungselemente:<br><br>10°C, 11°C, 15°C, 16°C, 19°C, 20°C, 22°C, 23°C.<br><br>Die Überdeckung durch die Optionen ist folglich jeweils:<br><ol style=\"list-style-type: lower-alpha;\"><li>4 von 8 (11, 20 ,22 und 23).</li><li>3 von 8 (15, 19 und 23).</li><li>5 von 8 (10, 16, 19, 22 und 23).</li><li>3 von 8 (15, 19 und 22)</li></ol>Folglich ist Option c) richtig.",
      "d": "FALSCH<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Bei den angegebenen Eingabe-Äquivalenzklassen ergibt das Zwei-Punkt Grenzwertverfahren folgende 8 Überdeckungselemente:<br><br>10°C, 11°C, 15°C, 16°C, 19°C, 20°C, 22°C, 23°C.<br><br>Die Überdeckung durch die Optionen ist folglich jeweils:<br><ol style=\"list-style-type: lower-alpha;\"><li>4 von 8 (11, 20 ,22 und 23).</li><li>3 von 8 (15, 19 und 23).</li><li>5 von 8 (10, 16, 19, 22 und 23).</li><li>3 von 8 (15, 19 und 22)</li></ol>Folglich ist Option c) richtig."
    }
  },
  {
    "frage": "Ein System zur Berechnung der Strafe für Geschwindigkeitsübertretungen im Straßenverkehr wird mit folgender Entscheidungstabelle spezifiziert:",
    "inhalte": [
      {
        "typ": "tabelle",
        "inhalt": {
          "kopf": [
            "",
            "Regeln",
            "R1",
            "R2",
            "R3",
            "R5"
          ],
          "koerper": [
            [
              "Bedingung",
              "Geschwindigkeit > 50",
              "J",
              "J",
              "N",
              "N"
            ],
            [
              "Bedingung",
              "Schul-Zone",
              "J",
              "N",
              "J",
              "N"
            ],
            [
              "Aktion",
              "250€ Geldstrafe",
              "-",
              "X",
              "-",
              "-"
            ],
            [
              "Aktion",
              "Führerscheinentzug",
              "X",
              "-",
              "-",
              "-"
            ]
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Für die beiden in der obigen Tabelle dargestellten Regeln R1 und R4 wurden bereits folgende zwei Testfälle generiert:<br><br>"
      },
      {
        "typ": "tabelle",
        "inhalt": {
          "kopf": [
            "ID",
            "Eingabe",
            "Erwartetes Ergebnis"
          ],
          "koerper": [
            [
              "TF1",
              "Geschwindigkeit = 65;<br><br>Schulzone = Ja",
              "Führerscheinentzug"
            ],
            [
              "TF2",
              "Geschwindigkeit = 45;<br><br>Schulzone = Nein",
              "Keine Strafe"
            ]
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Die nächste Tabelle zeigt vier zusätzliche Testfälle TF3, TF4, TF5 und TF6:<br><br>"
      },
      {
        "typ": "tabelle",
        "inhalt": {
          "kopf": [
            "ID",
            "Eingabe",
            "Erwartetes Ergebnis"
          ],
          "koerper": [
            [
              "TF3",
              "Geschwindigkeit = 55;<br>Schulzone = Ja",
              "Führerscheinentzug"
            ],
            [
              "TF4",
              "Geschwindigkeit = 44;<br>Schulzone = Ja",
              "Keine Strafe"
            ],
            [
              "TF5",
              "Geschwindigkeit = 66;<br>Schulzone = Ja",
              "Führerscheinentzug"
            ],
            [
              "TF6",
              "Geschwindigkeit = 77;<br>Schulzone = Nein",
              "250€ Geldstrafe"
            ]
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Welche zwei der zusätzlichen Testfälle würden eine 100% Überdeckung der gesamten Entscheidungstabelle erreichen (in Kombination mit den Testfällen TF1 und TF2)?<br><br>Wählen Sie genau EINE korrekte Option aus."
      }
    ],
    "antworten": {
      "a": "TF3, TF4",
      "b": "TF4, TF5",
      "c": "TF4, TF6",
      "d": "TF5, TF6"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Regel R2 ist nicht überdeckt.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die zusätzlichen Testfälle überdecken jeweils die folgenden Regeln:<br><table><tr><td>Testfall</td><td>TF3</td><td>TF4</td><td>TF5</td><td>TF6</td></tr><tr><td>Überdeckte Regel</td><td>R1</td><td>R3</td><td>R1</td><td>R2</td></tr></table>Um 100% Überdeckung zu erreichen, sind Testfälle erforderlich, die die Regeln R2 und R3 überdecken. Daher ist Option c) korrekt.",
      "b": "FALSCH<br><br>Regel R2 ist nicht überdeckt.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die zusätzlichen Testfälle überdecken jeweils die folgenden Regeln:<br><table><tr><td>Testfall</td><td>TF3</td><td>TF4</td><td>TF5</td><td>TF6</td></tr><tr><td>Überdeckte Regel</td><td>R1</td><td>R3</td><td>R1</td><td>R2</td></tr></table>Um 100% Überdeckung zu erreichen, sind Testfälle erforderlich, die die Regeln R2 und R3 überdecken. Daher ist Option c) korrekt.",
      "c": "KORREKT<br><br>R1, R2, R3 und R4 sind jeweils durch TF1, TF6, TF4 bzw. TF2 überdeckt.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die zusätzlichen Testfälle überdecken jeweils die folgenden Regeln:<br><table><tr><td>Testfall</td><td>TF3</td><td>TF4</td><td>TF5</td><td>TF6</td></tr><tr><td>Überdeckte Regel</td><td>R1</td><td>R3</td><td>R1</td><td>R2</td></tr></table>Um 100% Überdeckung zu erreichen, sind Testfälle erforderlich, die die Regeln R2 und R3 überdecken. Daher ist Option c) korrekt.",
      "d": "FALSCH<br><br>Regel R3 ist nicht überdeckt.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die zusätzlichen Testfälle überdecken jeweils die folgenden Regeln:<br><table><tr><td>Testfall</td><td>TF3</td><td>TF4</td><td>TF5</td><td>TF6</td></tr><tr><td>Überdeckte Regel</td><td>R1</td><td>R3</td><td>R1</td><td>R2</td></tr></table>Um 100% Überdeckung zu erreichen, sind Testfälle erforderlich, die die Regeln R2 und R3 überdecken. Daher ist Option c) korrekt."
    }
  },
  {
    "frage": "Gegeben sei folgendes Zustandsübergangsdiagramm für die Software eines Batterie-Ladegerätes:",
    "inhalte": [
      {
        "typ": "bild",
        "inhalt": "pics/istqb-ctfl-2018-sb-q25.png"
      },
      {
        "typ": "text",
        "inhalt": "Welche der folgenden Zustandsübergangs-Sequenzen ergibt die höchste Überdeckung der Zustandsübergänge?<br><br>Wählen Sie genau EINE korrekte Option aus!"
      }
    ],
    "antworten": {
      "a": "Aus → Warten → Aus → Warten → Erhaltungsladen → Laden → Hoch → Laden → Niedrig",
      "b": "Warten → Erhaltungsladen → Warten → Aus → Warten → Erhaltungsladen → Laden → Niedrig → Laden",
      "c": "Hoch → Laden → Niedrig → Laden → Erhaltungsladen → Warten → Erhaltungsladen → Warten → Erhaltungsladen",
      "d": "Warten → Erhaltungsladen → Laden → Hoch → Laden → Erhaltungsladen → Warten → Aus → Warten"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Aus → (1) Warten → (2) Aus → (1) Warten → (3) Erhaltungsladen → (5) Laden → (9) Hoch → (10) Laden → (7) Niedrig. Das sind 7/10=70%.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Im folgenden Zustandsdiagramm sind die Zustandsübergänge nummeriert:<br><div style='text-align: center;'><img src='pics/istqb-ctfl-2018-sb-q25b.png' alt='Zustandsdiagramm' style='max-width:100%;height:auto;'></div><br><br>Antwortoption d) erreicht mit 80% die höchste Überdeckung der Zustandsübergänge.",
      "b": "FALSCH<br><br>Warten → (3) Erhaltungsladen → (4) Warten → (2) Aus → (1) Warten → (3) Erhaltungsladen → (5) Laden → (7) Niedrig → (8) Laden. Das sind 7/10=70%.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Im folgenden Zustandsdiagramm sind die Zustandsübergänge nummeriert:<br><div style='text-align: center;'><img src='pics/istqb-ctfl-2018-sb-q25b.png' alt='Zustandsdiagramm' style='max-width:100%;height:auto;'></div><br><br>Antwortoption d) erreicht mit 80% die höchste Überdeckung der Zustandsübergänge.",
      "c": "FALSCH<br><br>Hoch → (10) Laden → (7) Niedrig → (8) Laden → (6) Erhaltungsladen → (4) Warten → (3) Erhaltungsladen → (4) Warten → (3) Erhaltungsladen. Das sind 6/10=60%.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Im folgenden Zustandsdiagramm sind die Zustandsübergänge nummeriert:<br><div style='text-align: center;'><img src='pics/istqb-ctfl-2018-sb-q25b.png' alt='Zustandsdiagramm' style='max-width:100%;height:auto;'></div><br><br>Antwortoption d) erreicht mit 80% die höchste Überdeckung der Zustandsübergänge.",
      "d": "KORREKT<br><br>Warten → (3) Erhaltungsladen → (5) Laden → (9) Hoch → (10) Laden → (6) Erhaltungsladen → (4) Warten → (2) Aus → (1) Warten. Das sind 8/10=80%.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Im folgenden Zustandsdiagramm sind die Zustandsübergänge nummeriert:<br><div style='text-align: center;'><img src='pics/istqb-ctfl-2018-sb-q25b.png' alt='Zustandsdiagramm' style='max-width:100%;height:auto;'></div><br><br>Antwortoption d) erreicht mit 80% die höchste Überdeckung der Zustandsübergänge."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen beschreibt AM BESTEN, wie Testfälle aus Anwendungsfällen entworfen werden?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Testfälle werden entworfen, um das im Anwendungsfall definierte grundlegende, Sonder- und Fehlerbehandlungs-Verhalten des Systems in Interaktion mit den Akteuren auszuführen.",
      "b": "Testfälle werden entworfen, indem die vom Anwendungsfall betroffenen Komponenten identifiziert und Integrationstests erstellt werden, welche die Interaktionen dieser Komponenten ausführen.",
      "c": "Testfälle werden entworfen, indem die Interaktionen der Akteure mit dem System analysiert werden, um sicherzustellen, dass die Benutzungsschnittstelle des Systems leicht bedienbar ist.",
      "d": "Testfälle werden entworfen, mit denen alle Entscheidungspunkte im Geschäftsprozess des Anwendungsfalls ausgeführt werden, um eine 100%-ige Entscheidungsüberdeckung zu erreichen."
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Im Lehrplan unter 4.2.5 Anwendungsfallbasierter Test steht: Jeder Anwendungsfall definiert ein bestimmtes Verhalten, das ein Objekt in Zusammenarbeit mit einem oder mehreren Akteuren ausführen kann. Weiter unten ist zu lesen: Ein Anwendungsfall besteht aus mehreren möglichen Varianten seines grundlegenden Verhaltens, was u. a. Sonder- und Fehlerbehandlungen einschließt (Antwort- und Wiederherstellungsmechanismen des Systems nach Programmier-, Anwendungs- und Kommunikationsfehler, die z. B. zu Fehlermeldungen führen). Tests werden entworfen, um das definierte Verhalten nachzuweisen (grundlegendes, außergewöhnliches oder alternatives Verhalten und die Fehlerbehandlungsroutinen).<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)",
      "b": "FALSCH<br><br>Anwendungsfälle spezifizieren normalerweise Anforderungen und schließen daher nicht die Komponenten ein, die sie implementieren.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)",
      "c": "FALSCH<br><br>Anwendungsfallbasierte Tests führen zwar Interaktionen des Systems mit einem oder mehreren Akteuren aus. Aber sie konzentrieren sich auf die Funktionalität und betrachten nicht die leichte Bedienbarkeit der Benutzungsschnittstelle.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)",
      "d": "FALSCH<br><br>Tests decken zwar die Ablaufpfade des Anwendungsfalls ab, es geht jedoch nicht um eine Entscheidungsüberdeckung in diesen Pfaden, und bestimmt nicht in den Kontrollfluss im Geschäftsprozess.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)"
    }
  },
  {
    "frage": "Welche der folgenden Beschreibungen der Anweisungsüberdeckung ist korrekt?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die Anweisungsüberdeckung ist ein Maß für die Anzahl der Quellcodezeilen (ohne Kommentare), die im Test ausgeführt wurden.",
      "b": "Die Anweisungsüberdeckung ist ein Maß für den prozentualen Anteil der ausführbaren Anweisungen im Quellcode, die im Test ausgeführt wurden.",
      "c": "Die Anweisungsüberdeckung ist ein Maß für den prozentualen Anteil der Quellcodezeilen (ohne Kommentare), die im Test ausgeführt wurden.",
      "d": "Die Anweisungsüberdeckung ist ein Maß für die Anzahl der ausführbaren Anweisungen im Quellcode, die im Test ausgeführt wurden."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Die Anweisungsüberdeckung bezieht sich auf durch Tests ausführbare Anweisungen. In einer Zeile können mehrere solcher Anweisungen stehen, und eine Anweisung kann sich über mehrere Zeilen erstrecken.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Glossareintrag Anweisungsüberdeckung: Der Anteil der Anweisungen, die durch eine Testsuite ausgeführt wurden, bezogen auf alle Anweisungen.<br><br>FL Lehrplan 4.3.1: Anweisungstests untersuchen die (potenziell) ausführbaren Anweisungen im Code. Die Überdeckung wird an der Anzahl der im Test ausgeführten Anweisungen dividiert durch die Gesamtzahl aller ausführbaren Anweisungen insgesamt im Testobjekt gemessen – üblicherweise als Prozentsatz dargestellt.",
      "b": "KORREKT<br><br>Der prozentuale Anteil der ausführbaren Anweisungen ist der Anteil im Test ausgeführter Anweisungen bezogen auf alle Anweisungen, also (Anzahl durch die Testsuite ausgeführter Anweisungen / Anzahl alle Anweisungen) x 100%.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Glossareintrag Anweisungsüberdeckung: Der Anteil der Anweisungen, die durch eine Testsuite ausgeführt wurden, bezogen auf alle Anweisungen.<br><br>FL Lehrplan 4.3.1: Anweisungstests untersuchen die (potenziell) ausführbaren Anweisungen im Code. Die Überdeckung wird an der Anzahl der im Test ausgeführten Anweisungen dividiert durch die Gesamtzahl aller ausführbaren Anweisungen insgesamt im Testobjekt gemessen – üblicherweise als Prozentsatz dargestellt.",
      "c": "FALSCH<br><br>Die Anweisungsüberdeckung bezieht sich nicht auf Quellcodezeilen, sondern auf durch Tests ausführbare Anweisungen. In einer Zeile können mehrere solcher Anweisungen stehen, und eine Anweisung kann sich über mehrere Zeilen erstrecken.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Glossareintrag Anweisungsüberdeckung: Der Anteil der Anweisungen, die durch eine Testsuite ausgeführt wurden, bezogen auf alle Anweisungen.<br><br>FL Lehrplan 4.3.1: Anweisungstests untersuchen die (potenziell) ausführbaren Anweisungen im Code. Die Überdeckung wird an der Anzahl der im Test ausgeführten Anweisungen dividiert durch die Gesamtzahl aller ausführbaren Anweisungen insgesamt im Testobjekt gemessen – üblicherweise als Prozentsatz dargestellt.",
      "d": "FALSCH<br><br>Die Anweisungsüberdeckung bezieht sich nicht auf die absolute Anzahl der von der Testsuite ausgeführten Anweisungen, sondern auf deren Anteil bezogen auf alle ausführbaren Anweisungen.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Glossareintrag Anweisungsüberdeckung: Der Anteil der Anweisungen, die durch eine Testsuite ausgeführt wurden, bezogen auf alle Anweisungen.<br><br>FL Lehrplan 4.3.1: Anweisungstests untersuchen die (potenziell) ausführbaren Anweisungen im Code. Die Überdeckung wird an der Anzahl der im Test ausgeführten Anweisungen dividiert durch die Gesamtzahl aller ausführbaren Anweisungen insgesamt im Testobjekt gemessen – üblicherweise als Prozentsatz dargestellt."
    }
  },
  {
    "frage": "Welche der folgenden Beschreibungen der Entscheidungsüberdeckung ist zutreffend?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die Entscheidungsüberdeckung ist ein Maß für den prozentualen Anteil möglicher Pfade durch den Quellcode, die im Test ausgeführt wurden.",
      "b": "Die Entscheidungsüberdeckung ist ein Maß für den prozentualen Anteil der Geschäftsabläufe durch die Komponente, die im Test ausgeführt wurden.",
      "c": "Die Entscheidungsüberdeckung ist ein Maß für die „IF-Anweisungen“ im Quellcode, die im Test sowohl mit dem Ergebnis „WAHR“ als auch mit „FALSCH“ ausgeführt wurden.",
      "d": "Die Entscheidungsüberdeckung ist ein Maß für den Anteil der Entscheidungsergebnisse, die im Test ausgeführt wurden."
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Ein Pfad durch den Quellcode ist ein möglicher Ablauf durch den Quellcode vom Eintrittspunkt zum Austrittspunkt, der eine Reihe von Entscheidungsergebnissen ausführen kann. Zwei verschiedene Pfade können bis auf einen die gleichen Entscheidungsergebnisse ausführen. Wird nur ein einziges Entscheidungsergebnis geändert, so wird ein anderer Pfad durchlaufen. Testfälle, die eine vollständige Entscheidungsabdeckung erzielen, sind in der Regel eine winzige Teilmenge der Testfälle, die eine vollständige Pfadüberdeckung erzielen würden. In der Praxis haben die meisten nicht-trivialen Programme (und alle Programme mit unbeschränkten Schleifen, z. B. 'while'-Schleifen) eine potenziell unendliche Anzahl möglicher Pfade, sodass die Messung des abgedeckten Prozentsatzes praktisch unmöglich ist.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Lehrplan 4.3.2: Der Überdeckungsgrad wird gemessen anhand der Anzahl der Entscheidungsergebnisse, die durch die Tests ausgeführt werden, dividiert durch die Gesamtzahl an möglichen Entscheidungsergebnissen im Testobjekt – üblicherweise als Prozentsatz dargestellt.<br><br>Aus diesem Grund ist d) korrekt.",
      "b": "FALSCH<br><br>Geschäftsabläufe können im anwendungsfallbasierten Test betrachtet werden. Sie werden jedoch nicht durch die Entscheidungsüberdeckung gemessen, auch wenn sie ein oder mehrere Entscheidungsergebnisse ausführen würden.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Lehrplan 4.3.2: Der Überdeckungsgrad wird gemessen anhand der Anzahl der Entscheidungsergebnisse, die durch die Tests ausgeführt werden, dividiert durch die Gesamtzahl an möglichen Entscheidungsergebnissen im Testobjekt – üblicherweise als Prozentsatz dargestellt.<br><br>Aus diesem Grund ist d) korrekt.",
      "c": "FALSCH<br><br>„IF-Anweisungen“ beinhalten zwar Entscheidungen, sind jedoch nicht die einzige Quelle für Entscheidungen, da z. B. auch Schleifen oder „CASE-Anweisungen“ Entscheidungen beinhalten, aufgrund deren Ergebnis sie ausgeführt oder nicht ausgeführt werden.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Lehrplan 4.3.2: Der Überdeckungsgrad wird gemessen anhand der Anzahl der Entscheidungsergebnisse, die durch die Tests ausgeführt werden, dividiert durch die Gesamtzahl an möglichen Entscheidungsergebnissen im Testobjekt – üblicherweise als Prozentsatz dargestellt.<br><br>Aus diesem Grund ist d) korrekt.",
      "d": "KORREKT<br><br> Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>4.3.2 Entscheidungstest und -überdeckung<br>Entscheidungstests untersuchen die Entscheidungen im Code und testen den Code, der auf Grundlage des Entscheidungsergebnisses ausgeführt wird. Dafür folgen die Testfälle bestimmten Kontrollflüssen, die von einem Entscheidungspunkt ausgehen (z.B. „wahr“ und „falsch“ bei einer IF-Anweisung, für eine CASE-Anweisung wären Testfälle für alle möglichen Ergebnisse nötig, auch für das Standardergebnis).<br>Die Überdeckung wird gemessen anhand der Anzahl der Entscheidungsergebnisse, die durch die Tests ausgeführt werden, dividiert durch die Gesamtzahl an möglichen Entscheidungsergebnissen im Testobjekt – üblicherweise als Prozentsatz dargestellt.<br><br>Aus diesem Grund ist d) korrekt."
    }
  },
  {
    "frage": "Welche der folgenden Optionen beschreibt AM BESTEN das Konzept der intuitiven Testfallermittlung?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die intuitive Testfallermittlung erfordert, dass Sie sich vorstellen, der Benutzer des Testobjekts zu sein und dass Sie Fehler erraten, die der Benutzer bei der Interaktion damit machen könnte.",
      "b": "Die intuitive Testfallermittlung bezieht Ihre persönlichen Entwicklungserfahrungen und die Fehler mit ein, die Sie als Entwickler gemacht haben.",
      "c": "Die intuitive Testfallermittlung verwendet Ihre Kenntnisse und Erfahrungen mit Fehlerzuständen, die in der Vergangenheit gefunden wurden, sowie mit typischen Fehlhandlungen von Entwicklern.",
      "d": "Die intuitive Testfallermittlung erfordert, dass Sie die Entwicklungsaufgabe schnell selbst wiederholen, um die Art von Fehlern zu identifizieren, die Entwickler dabei möglicherweise machen könnten."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Die intuitive Testfallermittlung ist kein Gebrauchstauglichkeitstestverfahren, um zu erraten, wie die Interaktion der Benutzer mit dem Testobjekt möglicherweise fehlschlagen könnte.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Lehrplan 4.4.1: Intuitive Testfallermittlung ist ein Verfahren, das das Auftreten von Fehlhandlungen, Fehlerzuständen und Fehlerwirkungen aufgrund des Wissens des Testers vermutet, u.a.:<ol style=\"list-style-type: circle;\"><li>Wie hat die Anwendung früher funktioniert?</li><li>Welche Arten von Fehlhandlungen werden üblicherweise gemacht?</li><li>Fehlerwirkungen, die in anderen Anwendungen aufgetreten sind</li></ol>Ein methodischer Ansatz für das Verfahren der intuitiven Testfallermittlung ist das Erstellen einer Liste möglicher Fehlhandlungen, Fehlerzustände und Fehlerwirkungen, zu der anschließend Tests entworfen werden, die die erwarteten Fehlerwirkungen und die Fehlerzustände offenlegen. Diese Fehlhandlungslisten, Fehlerzustandslisten und Fehlerwirkungslisten können aufgrund von Erfahrungen oder Informationen über Fehlerzustands- und Fehlerwirkungen oder auch aufgrund allgemeiner Kenntnis darüber, warum Software fehlschlägt, erstellt werden.<br><br>Aus diesem Grund ist c) korrekt.",
      "b": "FALSCH<br><br>Obwohl Tester, die früher Entwickler waren, ihre persönliche Erfahrung nutzen können, um Fehler zu erraten, basiert das Verfahren nicht auf Vorkenntnissen über die Entwicklung.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Lehrplan 4.4.1: Intuitive Testfallermittlung ist ein Verfahren, das das Auftreten von Fehlhandlungen, Fehlerzuständen und Fehlerwirkungen aufgrund des Wissens des Testers vermutet, u.a.:<ol style=\"list-style-type: circle;\"><li>Wie hat die Anwendung früher funktioniert?</li><li>Welche Arten von Fehlhandlungen werden üblicherweise gemacht?</li><li>Fehlerwirkungen, die in anderen Anwendungen aufgetreten sind</li></ol>Ein methodischer Ansatz für das Verfahren der intuitiven Testfallermittlung ist das Erstellen einer Liste möglicher Fehlhandlungen, Fehlerzustände und Fehlerwirkungen, zu der anschließend Tests entworfen werden, die die erwarteten Fehlerwirkungen und die Fehlerzustände offenlegen. Diese Fehlhandlungslisten, Fehlerzustandslisten und Fehlerwirkungslisten können aufgrund von Erfahrungen oder Informationen über Fehlerzustands- und Fehlerwirkungen oder auch aufgrund allgemeiner Kenntnis darüber, warum Software fehlschlägt, erstellt werden.<br><br>Aus diesem Grund ist c) korrekt.",
      "c": "KORREKT<br><br>Fehlhandlungen sind u. a. Fehler von Entwicklern. Das Grundkonzept der intuitiven Testfallermittlung ist, dass Tester anhand von Erfahrungswerten (und manchmal auch Checklisten) erraten, welche Fehler die Entwickler möglicherweise gemacht haben könnten und welche Fehlerzustände im Testobjekt vorliegen könnten.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Lehrplan 4.4.1: Intuitive Testfallermittlung ist ein Verfahren, das das Auftreten von Fehlhandlungen, Fehlerzuständen und Fehlerwirkungen aufgrund des Wissens des Testers vermutet, u.a.:<ol style=\"list-style-type: circle;\"><li>Wie hat die Anwendung früher funktioniert?</li><li>Welche Arten von Fehlhandlungen werden üblicherweise gemacht?</li><li>Fehlerwirkungen, die in anderen Anwendungen aufgetreten sind</li></ol>Ein methodischer Ansatz für das Verfahren der intuitiven Testfallermittlung ist das Erstellen einer Liste möglicher Fehlhandlungen, Fehlerzustände und Fehlerwirkungen, zu der anschließend Tests entworfen werden, die die erwarteten Fehlerwirkungen und die Fehlerzustände offenlegen. Diese Fehlhandlungslisten, Fehlerzustandslisten und Fehlerwirkungslisten können aufgrund von Erfahrungen oder Informationen über Fehlerzustands- und Fehlerwirkungen oder auch aufgrund allgemeiner Kenntnis darüber, warum Software fehlschlägt, erstellt werden.<br><br>Aus diesem Grund ist c) korrekt.",
      "d": "FALSCH<br><br>Das Wiederholen der Entwicklungsaufgabe ist keine intuitive Testfallermittlung. Es wäre darüber hinaus aufgrund mehrerer Probleme nicht praktikabel, z. B. der Anforderung, dass Tester über die gleichen Fähigkeiten wie Entwickler verfügen, und dem zeitlichen Aufwand für eine wiederholte Durchführung der Entwicklung.<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Lehrplan 4.4.1: Intuitive Testfallermittlung ist ein Verfahren, das das Auftreten von Fehlhandlungen, Fehlerzuständen und Fehlerwirkungen aufgrund des Wissens des Testers vermutet, u.a.:<ol style=\"list-style-type: circle;\"><li>Wie hat die Anwendung früher funktioniert?</li><li>Welche Arten von Fehlhandlungen werden üblicherweise gemacht?</li><li>Fehlerwirkungen, die in anderen Anwendungen aufgetreten sind</li></ol>Ein methodischer Ansatz für das Verfahren der intuitiven Testfallermittlung ist das Erstellen einer Liste möglicher Fehlhandlungen, Fehlerzustände und Fehlerwirkungen, zu der anschließend Tests entworfen werden, die die erwarteten Fehlerwirkungen und die Fehlerzustände offenlegen. Diese Fehlhandlungslisten, Fehlerzustandslisten und Fehlerwirkungslisten können aufgrund von Erfahrungen oder Informationen über Fehlerzustands- und Fehlerwirkungen oder auch aufgrund allgemeiner Kenntnis darüber, warum Software fehlschlägt, erstellt werden.<br><br>Aus diesem Grund ist c) korrekt."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen beschreibt am BESTEN einen Vorteil von unabhängigem Testen?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die Verwendung eines unabhängigen Testteams erlaubt dem Projektmanagement die Verantwortung für die Qualität des finalen Arbeitsergebnisses auf das Testteam zu übertragen. Somit ist jedem bewusst, dass die Qualität in der Gesamtverantwortung des Testteams liegt.",
      "b": "Wenn ein Testteam außerhalb der Organisation zur Verfügung gestellt werden kann, hat dies deutliche Vorteile, da dieses externe Team nicht so leicht von den Bedenken des Projektmanagements und der Notwendigkeit der Einhaltung strenger Lieferfristen beeinflusst wird.",
      "c": "Ein unabhängiges Testteam kann vollkommen separat von den Entwicklern arbeiten, muss sich nicht von sich ändernden Projektanforderungen ablenken lassen und kann die Kommunikation mit den Entwicklern auf das Verfassen von Fehlerberichten über das Fehlermanagementsystem beschränken.",
      "d": "Wenn Spezifikationen Mehrdeutigkeiten und/oder Inkonsistenzen enthalten, werden Annahmen zu deren Interpretation getroffen. Ein unabhängiger Tester kann hilfreich sein, um die vom Entwickler getroffenen Annahmen und vorgenommenen Interpretationen in Frage zu stellen."
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Qualität sollte in der Verantwortung aller am Projekt Beteiligten liegen und nicht in der alleinigen Verantwortung des Testteams (siehe CTFL Lehrplan 2018, Abschnitt 5.1.1 - 2.Punkt)<br><br>Mögliche Nachteile von Testunabhängigkeit sind u.a.:<ol style=\"list-style-type: circle;\"><li>Die Isolation vom Entwicklungsteam kann zu fehlender Zusammenarbeit, verzögerten Rückmeldungen an das Entwicklungsteam oder zu einem feindlichen Verhältnis zum Entwicklungsteam führen.</li><li>Entwickler können das Verantwortungsbewusstsein für Qualität verlieren.</li><li>Unabhängige Tester können als Engpass angesehen werden.</li><li>Unabhängigen Testern fehlen unter Umständen wichtige Informationen (z.B. über das Testobjekt).</ol>Viele Unternehmen sind fähig, die Vorteile der Testunabhängigkeit zu verwirklichen und die Nachteile zu vermeiden.<br><br>Aus diesem Grund ist d) korrekt.",
      "b": "FALSCH<br><br>Zum einen ist es kein Vorteil, wenn ein externes Testteam die Lieferfristen nicht einhält, und zum anderen gibt es keinen Grund zu der Annahme, dass externe Testteams das Gefühl haben, die strengen Lieferfristen nicht einhalten zu müssen (siehe CTFL Lehrplan 2018, Abschnitt 5.1.1 - 3. Punkt)<br><br>Mögliche Nachteile von Testunabhängigkeit sind u.a.:<ol style=\"list-style-type: circle;\"><li>Die Isolation vom Entwicklungsteam kann zu fehlender Zusammenarbeit, verzögerten Rückmeldungen an das Entwicklungsteam oder zu einem feindlichen Verhältnis zum Entwicklungsteam führen.</li><li>Entwickler können das Verantwortungsbewusstsein für Qualität verlieren.</li><li>Unabhängige Tester können als Engpass angesehen werden.</li><li>Unabhängigen Testern fehlen unter Umständen wichtige Informationen (z.B. über das Testobjekt).</ol>Viele Unternehmen sind fähig, die Vorteile der Testunabhängigkeit zu verwirklichen und die Nachteile zu vermeiden.<br><br>Aus diesem Grund ist d) korrekt.",
      "c": "FALSCH<br><br>Es ist eine schlechte Praxis für das Testteam, völlig isoliert zu arbeiten, und außerdem sollte sich auch ein externes Testteam mit sich ändernden Projektanforderungen befassen und gut mit den Entwicklern kommunizieren (siehe CTFL Lehrplan 2018, Abschnitt 5.1.1 - 1. Punkt)<br><br>Mögliche Nachteile von Testunabhängigkeit sind u.a.:<ol style=\"list-style-type: circle;\"><li>Die Isolation vom Entwicklungsteam kann zu fehlender Zusammenarbeit, verzögerten Rückmeldungen an das Entwicklungsteam oder zu einem feindlichen Verhältnis zum Entwicklungsteam führen.</li><li>Entwickler können das Verantwortungsbewusstsein für Qualität verlieren.</li><li>Unabhängige Tester können als Engpass angesehen werden.</li><li>Unabhängigen Testern fehlen unter Umständen wichtige Informationen (z.B. über das Testobjekt).</ol>Viele Unternehmen sind fähig, die Vorteile der Testunabhängigkeit zu verwirklichen und die Nachteile zu vermeiden.<br><br>Aus diesem Grund ist d) korrekt.",
      "d": "KORREKT<br><br>Spezifikationen sind niemals perfekt, was bedeutet, dass Annahmen vom Entwickler getroffen werden müssen. Ein unabhängiger Tester ist nützlich, um die Annahme in Frage zu stellen und zu überprüfen (siehe CTFL Lehrplan 2018, Abschnitt 5.1.1 - 2.Punkt)<br><br>Mögliche Nachteile von Testunabhängigkeit sind u.a.:<ol style=\"list-style-type: circle;\"><li>Die Isolation vom Entwicklungsteam kann zu fehlender Zusammenarbeit, verzögerten Rückmeldungen an das Entwicklungsteam oder zu einem feindlichen Verhältnis zum Entwicklungsteam führen.</li><li>Entwickler können das Verantwortungsbewusstsein für Qualität verlieren.</li><li>Unabhängige Tester können als Engpass angesehen werden.</li><li>Unabhängigen Testern fehlen unter Umständen wichtige Informationen (z.B. über das Testobjekt).</ol>Viele Unternehmen sind fähig, die Vorteile der Testunabhängigkeit zu verwirklichen und die Nachteile zu vermeiden.<br><br>Aus diesem Grund ist d) korrekt."
    }
  },
  {
    "frage": "Welche der folgenden Aufgaben wird AM WAHRSCHEINLICHSTEN vom Testmanager ausgeführt?",
    "inhalte": [],
    "antworten": {
      "a": "Erstellen von Testabschlussberichten auf der Grundlage der während des Tests gesammelten Informationen.",
      "b": "Tests prüfen, die von anderen entwickelt wurden.",
      "c": "Testdaten vorbereiten und beschaffen.",
      "d": "Anforderungen, Spezifikationen und Modelle auf Testbarkeit analysieren, prüfen und beurteilen."
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Eine der typischen Aufgaben eines Testmanagers gemäß CTFL Lehrplan 2018, Abschnitt 5.1.2.<br><br>5.1.2 Aufgaben eines Testmanagers und eines Testers<br>In diesem Lehrplan werden zwei Testrollen behandelt, und zwar Testmanager und Tester. Die Aktivitäten und Aufgaben dieser beiden Rollen hängen vom Projekt- und Produktkontext, von den Fähigkeiten der Menschen in diesen Rollen und dem Unternehmen ab.<br>Der Testmanager ist verantwortlich für den allgemeinen Testfortschritt und die erfolgreiche Leitung der Test-aktivitäten. Die Testmanagementrolle kann von einem professionellen Testmanager oder von einem Projektmanager, einem Entwicklungsmanager oder einem Qualitätssicherungsmanager eingenommen werden. In größeren Projekten oder Unternehmen können mehrere Testteams an einen Testmanager, Testcoach oder Testkoordinator berichten und jedes Team wird durch einen Testleiter oder den leitenden Tester geführt.<br>Typische Aufgaben eines Testmanagers sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Eine Testrichtlinie und Teststrategie für das Unternehmen entwickeln oder prüfen</li><li>Die Testaktivitäten unter Berücksichtigung des Kontexts und des Verständnisses der Testziele und Risiken planen. Das kann die Auswahl von Testvorgehensweisen, die Schätzung der Testdauer, des Aufwands und der Kosten, die Beschaffung von Ressourcen, die Festlegung von Teststufen und Testzyklen und die Planung des Fehlermanagements beinhalten</li><li>Testkonzepte schreiben und aktualisieren</li><li>Testkonzepte mit den Projektmanagern, Product Ownern und weiteren Beteiligten abstimmen</li><li>Einbringen der Testperspektive in andere Projektaktivitäten, beispielsweise in die Integrationsplanung</li><li>Die Analyse, den Entwurf, die Realisierung und die Durchführung von Tests anstoßen, den Testfortschritt und die Testergebnisse überwachen und den Stand der Endekriterien (oder der Definition-of-Done) prüfen sowie die Testabschlussaktivitäten ermöglichen</li><li>Testfortschrittsberichte und Testabschlussberichte auf der Grundlage der gesammelten Informationen erstellen und verteilen</li><li>Die Planung auf der Grundlage von Testergebnissen und Fortschritt anpassen (manchmal dokumentiert in Testfortschrittsberichten und/oder Testabschlussberichten für andere Tests, die im Projekt bereits abgeschlossen sind) und notwendige Maßnahmen zur Teststeuerung in die Wege leiten</li><li>Das Aufsetzen des Fehlermanagementsystems und eines angemessenen Konfigurationsmanagements für Testmittel unterstützen</li><li>Geeignete Metriken für die Messung des Testfortschritts und die Bewertung der Qualität des Testens und des Produkts einführen</li><li>Unterstützung bei der Auswahl und dem Einsatz von Werkzeugen für den Testprozess, einschließlich der Empfehlung des Budgets für die Werkzeugauswahl (und möglicherweise Kauf und/oder Support), der Zuordnung von Zeit und Aufwand für Pilotprojekte und der Bereitstellung von kontinuierlicher Unterstützung bei der Nutzung der Werkzeuge</li><li>Über die Realisierung von Testumgebungen entscheiden</li><li>Die Tester, das Testteam und das Berufsbild Tester innerhalb des Unternehmens entwickeln und fördern</li><li>Die Fähigkeiten und Aufstiegsmöglichkeiten von Testern weiterentwickeln (beispielsweise durch Schulungspläne, Leistungsbeurteilungen, Coaching usw.)</li></ol>Die Art und Weise, in der die Rolle des Testmanagers umgesetzt wird, variiert in Abhängigkeit vom Softwareentwicklungslebenszyklus. In der agilen Entwicklung beispielsweise werden einige der oben genannten Aufgaben, insbesondere solche, die die täglichen Tests innerhalb des Teams betreffen, vom agilen Team übernommen – häufig von einem im Team integrierten Tester. Einige der Aufgaben, die mehrere Teams oder das ganze Unternehmen betreffen oder die mit Personalmanagement zu tun haben, können von Testmanagern außerhalb des Entwicklungsteams wahrgenommen werden, die manchmal Test Coaches genannt werden. Siehe Black 2009 für weitere Informationen zum Management des Testprozesses.<br>Typische Aufgaben eines Testers sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Testkonzepte prüfen und zu diesen beitragen</li><li>Anforderungen, User-Stories und Abnahmekriterien, Spezifikationen und Modelle (d.h. die Testbasis) auf Testbarkeit analysieren, prüfen und beurteilen</li><li>Die Testbedingungen identifizieren und dokumentieren und die Verfolgbarkeit zwischen Testfällen, Testbedingungen und der Testbasis erfassen</li><li>Die Testumgebung(en) entwerfen, einrichten und verifizieren, oft in Abstimmung mit der Systemadministration und dem Netzwerkmanagement</li><li>Testfälle und Testabläufe entwerfen und realisieren</li><li>Testdaten vorbereiten und beschaffen</li><li>Den detaillierten Testausführungsplan erstellen</li><li>Die Tests durchführen, die Ergebnisse bewerten und Abweichungen von den erwarteten Ergebnissen dokumentieren</li><li>Geeignete Werkzeuge zur Unterstützung des Testprozesses verwenden</li><li>Bei Bedarf Tests automatisieren (dies kann durch einen Entwickler oder Testautomatisierungsexperten unterstützt werden)</li><li>Die nicht-funktionalen Eigenschaften wie Performanz, Zuverlässigkeit, Gebrauchstauglichkeit, IT-Sicherheit, Kompatibilität und Übertragbarkeit bewerten</li><li>Tests prüfen, die von anderen entwickelt wurden</li></ol>Personen, die an der Testanalyse, dem Testentwurf, spezifischen Testarten oder der Testautomatisierung arbeiten, können Spezialisten in diesen Rollen sein. Abhängig von den Risiken des Produkts oder des Projekts und dem ausgewählten Softwareentwicklungslebenszyklus-Modell können unterschiedliche Personen die Rolle des Testers in unterschiedlichen Teststufen wahrnehmen. Zum Beispiel übernimmt in der Komponententeststufe und der Komponentenintegrationsteststufe häufig ein Entwickler die Rolle des Testers. In der Abnahmeteststufe wird die Rolle des Testers oft von Businessanalysten, Fachexperten und Benutzern eingenommen. In der Systemtest- und Systemintegrationsteststufe wird die Rolle des Testers meist von einem unabhängigen Testteam übernommen. In der betrieblichen Abnahmeteststufe wird die Rolle des Testers häufig vom Betrieb und/oder von Mitarbeitern der Systemadministration wahrgenommen.",
      "b": "FALSCH<br><br>Eine der typischen Aufgaben eines Testers gemäß CTFL Lehrplan 2018, Abschnitt 5.1.2.<br><br>5.1.2 Aufgaben eines Testmanagers und eines Testers<br>In diesem Lehrplan werden zwei Testrollen behandelt, und zwar Testmanager und Tester. Die Aktivitäten und Aufgaben dieser beiden Rollen hängen vom Projekt- und Produktkontext, von den Fähigkeiten der Menschen in diesen Rollen und dem Unternehmen ab.<br>Der Testmanager ist verantwortlich für den allgemeinen Testfortschritt und die erfolgreiche Leitung der Test-aktivitäten. Die Testmanagementrolle kann von einem professionellen Testmanager oder von einem Projektmanager, einem Entwicklungsmanager oder einem Qualitätssicherungsmanager eingenommen werden. In größeren Projekten oder Unternehmen können mehrere Testteams an einen Testmanager, Testcoach oder Testkoordinator berichten und jedes Team wird durch einen Testleiter oder den leitenden Tester geführt.<br>Typische Aufgaben eines Testmanagers sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Eine Testrichtlinie und Teststrategie für das Unternehmen entwickeln oder prüfen</li><li>Die Testaktivitäten unter Berücksichtigung des Kontexts und des Verständnisses der Testziele und Risiken planen. Das kann die Auswahl von Testvorgehensweisen, die Schätzung der Testdauer, des Aufwands und der Kosten, die Beschaffung von Ressourcen, die Festlegung von Teststufen und Testzyklen und die Planung des Fehlermanagements beinhalten</li><li>Testkonzepte schreiben und aktualisieren</li><li>Testkonzepte mit den Projektmanagern, Product Ownern und weiteren Beteiligten abstimmen</li><li>Einbringen der Testperspektive in andere Projektaktivitäten, beispielsweise in die Integrationsplanung</li><li>Die Analyse, den Entwurf, die Realisierung und die Durchführung von Tests anstoßen, den Testfortschritt und die Testergebnisse überwachen und den Stand der Endekriterien (oder der Definition-of-Done) prüfen sowie die Testabschlussaktivitäten ermöglichen</li><li>Testfortschrittsberichte und Testabschlussberichte auf der Grundlage der gesammelten Informationen erstellen und verteilen</li><li>Die Planung auf der Grundlage von Testergebnissen und Fortschritt anpassen (manchmal dokumentiert in Testfortschrittsberichten und/oder Testabschlussberichten für andere Tests, die im Projekt bereits abgeschlossen sind) und notwendige Maßnahmen zur Teststeuerung in die Wege leiten</li><li>Das Aufsetzen des Fehlermanagementsystems und eines angemessenen Konfigurationsmanagements für Testmittel unterstützen</li><li>Geeignete Metriken für die Messung des Testfortschritts und die Bewertung der Qualität des Testens und des Produkts einführen</li><li>Unterstützung bei der Auswahl und dem Einsatz von Werkzeugen für den Testprozess, einschließlich der Empfehlung des Budgets für die Werkzeugauswahl (und möglicherweise Kauf und/oder Support), der Zuordnung von Zeit und Aufwand für Pilotprojekte und der Bereitstellung von kontinuierlicher Unterstützung bei der Nutzung der Werkzeuge</li><li>Über die Realisierung von Testumgebungen entscheiden</li><li>Die Tester, das Testteam und das Berufsbild Tester innerhalb des Unternehmens entwickeln und fördern</li><li>Die Fähigkeiten und Aufstiegsmöglichkeiten von Testern weiterentwickeln (beispielsweise durch Schulungspläne, Leistungsbeurteilungen, Coaching usw.)</li></ol>Die Art und Weise, in der die Rolle des Testmanagers umgesetzt wird, variiert in Abhängigkeit vom Softwareentwicklungslebenszyklus. In der agilen Entwicklung beispielsweise werden einige der oben genannten Aufgaben, insbesondere solche, die die täglichen Tests innerhalb des Teams betreffen, vom agilen Team übernommen – häufig von einem im Team integrierten Tester. Einige der Aufgaben, die mehrere Teams oder das ganze Unternehmen betreffen oder die mit Personalmanagement zu tun haben, können von Testmanagern außerhalb des Entwicklungsteams wahrgenommen werden, die manchmal Test Coaches genannt werden. Siehe Black 2009 für weitere Informationen zum Management des Testprozesses.<br>Typische Aufgaben eines Testers sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Testkonzepte prüfen und zu diesen beitragen</li><li>Anforderungen, User-Stories und Abnahmekriterien, Spezifikationen und Modelle (d.h. die Testbasis) auf Testbarkeit analysieren, prüfen und beurteilen</li><li>Die Testbedingungen identifizieren und dokumentieren und die Verfolgbarkeit zwischen Testfällen, Testbedingungen und der Testbasis erfassen</li><li>Die Testumgebung(en) entwerfen, einrichten und verifizieren, oft in Abstimmung mit der Systemadministration und dem Netzwerkmanagement</li><li>Testfälle und Testabläufe entwerfen und realisieren</li><li>Testdaten vorbereiten und beschaffen</li><li>Den detaillierten Testausführungsplan erstellen</li><li>Die Tests durchführen, die Ergebnisse bewerten und Abweichungen von den erwarteten Ergebnissen dokumentieren</li><li>Geeignete Werkzeuge zur Unterstützung des Testprozesses verwenden</li><li>Bei Bedarf Tests automatisieren (dies kann durch einen Entwickler oder Testautomatisierungsexperten unterstützt werden)</li><li>Die nicht-funktionalen Eigenschaften wie Performanz, Zuverlässigkeit, Gebrauchstauglichkeit, IT-Sicherheit, Kompatibilität und Übertragbarkeit bewerten</li><li>Tests prüfen, die von anderen entwickelt wurden</li></ol>Personen, die an der Testanalyse, dem Testentwurf, spezifischen Testarten oder der Testautomatisierung arbeiten, können Spezialisten in diesen Rollen sein. Abhängig von den Risiken des Produkts oder des Projekts und dem ausgewählten Softwareentwicklungslebenszyklus-Modell können unterschiedliche Personen die Rolle des Testers in unterschiedlichen Teststufen wahrnehmen. Zum Beispiel übernimmt in der Komponententeststufe und der Komponentenintegrationsteststufe häufig ein Entwickler die Rolle des Testers. In der Abnahmeteststufe wird die Rolle des Testers oft von Businessanalysten, Fachexperten und Benutzern eingenommen. In der Systemtest- und Systemintegrationsteststufe wird die Rolle des Testers meist von einem unabhängigen Testteam übernommen. In der betrieblichen Abnahmeteststufe wird die Rolle des Testers häufig vom Betrieb und/oder von Mitarbeitern der Systemadministration wahrgenommen.",
      "c": "FALSCH<br><br>Eine der typischen Aufgaben eines Testers gemäß CTFL Lehrplan 2018, Abschnitt 5.1.2.<br><br>5.1.2 Aufgaben eines Testmanagers und eines Testers<br>In diesem Lehrplan werden zwei Testrollen behandelt, und zwar Testmanager und Tester. Die Aktivitäten und Aufgaben dieser beiden Rollen hängen vom Projekt- und Produktkontext, von den Fähigkeiten der Menschen in diesen Rollen und dem Unternehmen ab.<br>Der Testmanager ist verantwortlich für den allgemeinen Testfortschritt und die erfolgreiche Leitung der Test-aktivitäten. Die Testmanagementrolle kann von einem professionellen Testmanager oder von einem Projektmanager, einem Entwicklungsmanager oder einem Qualitätssicherungsmanager eingenommen werden. In größeren Projekten oder Unternehmen können mehrere Testteams an einen Testmanager, Testcoach oder Testkoordinator berichten und jedes Team wird durch einen Testleiter oder den leitenden Tester geführt.<br>Typische Aufgaben eines Testmanagers sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Eine Testrichtlinie und Teststrategie für das Unternehmen entwickeln oder prüfen</li><li>Die Testaktivitäten unter Berücksichtigung des Kontexts und des Verständnisses der Testziele und Risiken planen. Das kann die Auswahl von Testvorgehensweisen, die Schätzung der Testdauer, des Aufwands und der Kosten, die Beschaffung von Ressourcen, die Festlegung von Teststufen und Testzyklen und die Planung des Fehlermanagements beinhalten</li><li>Testkonzepte schreiben und aktualisieren</li><li>Testkonzepte mit den Projektmanagern, Product Ownern und weiteren Beteiligten abstimmen</li><li>Einbringen der Testperspektive in andere Projektaktivitäten, beispielsweise in die Integrationsplanung</li><li>Die Analyse, den Entwurf, die Realisierung und die Durchführung von Tests anstoßen, den Testfortschritt und die Testergebnisse überwachen und den Stand der Endekriterien (oder der Definition-of-Done) prüfen sowie die Testabschlussaktivitäten ermöglichen</li><li>Testfortschrittsberichte und Testabschlussberichte auf der Grundlage der gesammelten Informationen erstellen und verteilen</li><li>Die Planung auf der Grundlage von Testergebnissen und Fortschritt anpassen (manchmal dokumentiert in Testfortschrittsberichten und/oder Testabschlussberichten für andere Tests, die im Projekt bereits abgeschlossen sind) und notwendige Maßnahmen zur Teststeuerung in die Wege leiten</li><li>Das Aufsetzen des Fehlermanagementsystems und eines angemessenen Konfigurationsmanagements für Testmittel unterstützen</li><li>Geeignete Metriken für die Messung des Testfortschritts und die Bewertung der Qualität des Testens und des Produkts einführen</li><li>Unterstützung bei der Auswahl und dem Einsatz von Werkzeugen für den Testprozess, einschließlich der Empfehlung des Budgets für die Werkzeugauswahl (und möglicherweise Kauf und/oder Support), der Zuordnung von Zeit und Aufwand für Pilotprojekte und der Bereitstellung von kontinuierlicher Unterstützung bei der Nutzung der Werkzeuge</li><li>Über die Realisierung von Testumgebungen entscheiden</li><li>Die Tester, das Testteam und das Berufsbild Tester innerhalb des Unternehmens entwickeln und fördern</li><li>Die Fähigkeiten und Aufstiegsmöglichkeiten von Testern weiterentwickeln (beispielsweise durch Schulungspläne, Leistungsbeurteilungen, Coaching usw.)</li></ol>Die Art und Weise, in der die Rolle des Testmanagers umgesetzt wird, variiert in Abhängigkeit vom Softwareentwicklungslebenszyklus. In der agilen Entwicklung beispielsweise werden einige der oben genannten Aufgaben, insbesondere solche, die die täglichen Tests innerhalb des Teams betreffen, vom agilen Team übernommen – häufig von einem im Team integrierten Tester. Einige der Aufgaben, die mehrere Teams oder das ganze Unternehmen betreffen oder die mit Personalmanagement zu tun haben, können von Testmanagern außerhalb des Entwicklungsteams wahrgenommen werden, die manchmal Test Coaches genannt werden. Siehe Black 2009 für weitere Informationen zum Management des Testprozesses.<br>Typische Aufgaben eines Testers sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Testkonzepte prüfen und zu diesen beitragen</li><li>Anforderungen, User-Stories und Abnahmekriterien, Spezifikationen und Modelle (d.h. die Testbasis) auf Testbarkeit analysieren, prüfen und beurteilen</li><li>Die Testbedingungen identifizieren und dokumentieren und die Verfolgbarkeit zwischen Testfällen, Testbedingungen und der Testbasis erfassen</li><li>Die Testumgebung(en) entwerfen, einrichten und verifizieren, oft in Abstimmung mit der Systemadministration und dem Netzwerkmanagement</li><li>Testfälle und Testabläufe entwerfen und realisieren</li><li>Testdaten vorbereiten und beschaffen</li><li>Den detaillierten Testausführungsplan erstellen</li><li>Die Tests durchführen, die Ergebnisse bewerten und Abweichungen von den erwarteten Ergebnissen dokumentieren</li><li>Geeignete Werkzeuge zur Unterstützung des Testprozesses verwenden</li><li>Bei Bedarf Tests automatisieren (dies kann durch einen Entwickler oder Testautomatisierungsexperten unterstützt werden)</li><li>Die nicht-funktionalen Eigenschaften wie Performanz, Zuverlässigkeit, Gebrauchstauglichkeit, IT-Sicherheit, Kompatibilität und Übertragbarkeit bewerten</li><li>Tests prüfen, die von anderen entwickelt wurden</li></ol>Personen, die an der Testanalyse, dem Testentwurf, spezifischen Testarten oder der Testautomatisierung arbeiten, können Spezialisten in diesen Rollen sein. Abhängig von den Risiken des Produkts oder des Projekts und dem ausgewählten Softwareentwicklungslebenszyklus-Modell können unterschiedliche Personen die Rolle des Testers in unterschiedlichen Teststufen wahrnehmen. Zum Beispiel übernimmt in der Komponententeststufe und der Komponentenintegrationsteststufe häufig ein Entwickler die Rolle des Testers. In der Abnahmeteststufe wird die Rolle des Testers oft von Businessanalysten, Fachexperten und Benutzern eingenommen. In der Systemtest- und Systemintegrationsteststufe wird die Rolle des Testers meist von einem unabhängigen Testteam übernommen. In der betrieblichen Abnahmeteststufe wird die Rolle des Testers häufig vom Betrieb und/oder von Mitarbeitern der Systemadministration wahrgenommen.",
      "d": "FALSCH<br><br>Eine der typischen Aufgaben eines Testers gemäß CTFL Lehrplan 2018, Abschnitt 5.1.2.<br><br>5.1.2 Aufgaben eines Testmanagers und eines Testers<br>In diesem Lehrplan werden zwei Testrollen behandelt, und zwar Testmanager und Tester. Die Aktivitäten und Aufgaben dieser beiden Rollen hängen vom Projekt- und Produktkontext, von den Fähigkeiten der Menschen in diesen Rollen und dem Unternehmen ab.<br>Der Testmanager ist verantwortlich für den allgemeinen Testfortschritt und die erfolgreiche Leitung der Test-aktivitäten. Die Testmanagementrolle kann von einem professionellen Testmanager oder von einem Projektmanager, einem Entwicklungsmanager oder einem Qualitätssicherungsmanager eingenommen werden. In größeren Projekten oder Unternehmen können mehrere Testteams an einen Testmanager, Testcoach oder Testkoordinator berichten und jedes Team wird durch einen Testleiter oder den leitenden Tester geführt.<br>Typische Aufgaben eines Testmanagers sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Eine Testrichtlinie und Teststrategie für das Unternehmen entwickeln oder prüfen</li><li>Die Testaktivitäten unter Berücksichtigung des Kontexts und des Verständnisses der Testziele und Risiken planen. Das kann die Auswahl von Testvorgehensweisen, die Schätzung der Testdauer, des Aufwands und der Kosten, die Beschaffung von Ressourcen, die Festlegung von Teststufen und Testzyklen und die Planung des Fehlermanagements beinhalten</li><li>Testkonzepte schreiben und aktualisieren</li><li>Testkonzepte mit den Projektmanagern, Product Ownern und weiteren Beteiligten abstimmen</li><li>Einbringen der Testperspektive in andere Projektaktivitäten, beispielsweise in die Integrationsplanung</li><li>Die Analyse, den Entwurf, die Realisierung und die Durchführung von Tests anstoßen, den Testfortschritt und die Testergebnisse überwachen und den Stand der Endekriterien (oder der Definition-of-Done) prüfen sowie die Testabschlussaktivitäten ermöglichen</li><li>Testfortschrittsberichte und Testabschlussberichte auf der Grundlage der gesammelten Informationen erstellen und verteilen</li><li>Die Planung auf der Grundlage von Testergebnissen und Fortschritt anpassen (manchmal dokumentiert in Testfortschrittsberichten und/oder Testabschlussberichten für andere Tests, die im Projekt bereits abgeschlossen sind) und notwendige Maßnahmen zur Teststeuerung in die Wege leiten</li><li>Das Aufsetzen des Fehlermanagementsystems und eines angemessenen Konfigurationsmanagements für Testmittel unterstützen</li><li>Geeignete Metriken für die Messung des Testfortschritts und die Bewertung der Qualität des Testens und des Produkts einführen</li><li>Unterstützung bei der Auswahl und dem Einsatz von Werkzeugen für den Testprozess, einschließlich der Empfehlung des Budgets für die Werkzeugauswahl (und möglicherweise Kauf und/oder Support), der Zuordnung von Zeit und Aufwand für Pilotprojekte und der Bereitstellung von kontinuierlicher Unterstützung bei der Nutzung der Werkzeuge</li><li>Über die Realisierung von Testumgebungen entscheiden</li><li>Die Tester, das Testteam und das Berufsbild Tester innerhalb des Unternehmens entwickeln und fördern</li><li>Die Fähigkeiten und Aufstiegsmöglichkeiten von Testern weiterentwickeln (beispielsweise durch Schulungspläne, Leistungsbeurteilungen, Coaching usw.)</li></ol>Die Art und Weise, in der die Rolle des Testmanagers umgesetzt wird, variiert in Abhängigkeit vom Softwareentwicklungslebenszyklus. In der agilen Entwicklung beispielsweise werden einige der oben genannten Aufgaben, insbesondere solche, die die täglichen Tests innerhalb des Teams betreffen, vom agilen Team übernommen – häufig von einem im Team integrierten Tester. Einige der Aufgaben, die mehrere Teams oder das ganze Unternehmen betreffen oder die mit Personalmanagement zu tun haben, können von Testmanagern außerhalb des Entwicklungsteams wahrgenommen werden, die manchmal Test Coaches genannt werden. Siehe Black 2009 für weitere Informationen zum Management des Testprozesses.<br>Typische Aufgaben eines Testers sind u.a.:<br><ol style=\"list-style-type: circle;\"><li>Testkonzepte prüfen und zu diesen beitragen</li><li>Anforderungen, User-Stories und Abnahmekriterien, Spezifikationen und Modelle (d.h. die Testbasis) auf Testbarkeit analysieren, prüfen und beurteilen</li><li>Die Testbedingungen identifizieren und dokumentieren und die Verfolgbarkeit zwischen Testfällen, Testbedingungen und der Testbasis erfassen</li><li>Die Testumgebung(en) entwerfen, einrichten und verifizieren, oft in Abstimmung mit der Systemadministration und dem Netzwerkmanagement</li><li>Testfälle und Testabläufe entwerfen und realisieren</li><li>Testdaten vorbereiten und beschaffen</li><li>Den detaillierten Testausführungsplan erstellen</li><li>Die Tests durchführen, die Ergebnisse bewerten und Abweichungen von den erwarteten Ergebnissen dokumentieren</li><li>Geeignete Werkzeuge zur Unterstützung des Testprozesses verwenden</li><li>Bei Bedarf Tests automatisieren (dies kann durch einen Entwickler oder Testautomatisierungsexperten unterstützt werden)</li><li>Die nicht-funktionalen Eigenschaften wie Performanz, Zuverlässigkeit, Gebrauchstauglichkeit, IT-Sicherheit, Kompatibilität und Übertragbarkeit bewerten</li><li>Tests prüfen, die von anderen entwickelt wurden</li></ol>Personen, die an der Testanalyse, dem Testentwurf, spezifischen Testarten oder der Testautomatisierung arbeiten, können Spezialisten in diesen Rollen sein. Abhängig von den Risiken des Produkts oder des Projekts und dem ausgewählten Softwareentwicklungslebenszyklus-Modell können unterschiedliche Personen die Rolle des Testers in unterschiedlichen Teststufen wahrnehmen. Zum Beispiel übernimmt in der Komponententeststufe und der Komponentenintegrationsteststufe häufig ein Entwickler die Rolle des Testers. In der Abnahmeteststufe wird die Rolle des Testers oft von Businessanalysten, Fachexperten und Benutzern eingenommen. In der Systemtest- und Systemintegrationsteststufe wird die Rolle des Testers meist von einem unabhängigen Testteam übernommen. In der betrieblichen Abnahmeteststufe wird die Rolle des Testers häufig vom Betrieb und/oder von Mitarbeitern der Systemadministration wahrgenommen."
    }
  },
  {
    "frage": "Gegeben seien die folgenden Beispiele für Eingangs- und Endekriterien:<br><br><ol><li>Das ursprüngliche Testbudget von 30.000 US-Dollar wurde ausgegeben.</li><li>96% der geplanten Tests wurden ausgeführt.</li><li>Die Testumgebung für den Performanz-Test wurde entworfen, eingerichtet und verifiziert.</li><li>Derzeit gibt es keine kritischen Fehlerzustände und zwei Fehlerzustände mit hoher Priorität.</li><li>Die Designspezifikationen wurden einem Review unterzogen und nachgebessert.</li><li>Die Komponente für die Berechnung des Steuersatzes hat die Unit Tests bestanden.</li></ol>Welche der folgenden Kombinationen kategorisiert sie AM BESTEN als Eingangs- und Endekriterien?</br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Eingangskriterien – 5, 6; Endekriterien – 1, 2, 3, 4",
      "b": "Eingangskriterien – 2, 3, 6; Endekriterien – 1, 4, 5",
      "c": "Eingangskriterien – 1, 3; Endekriterien – 2, 4, 5, 6",
      "d": "Eingangskriterien – 3, 5, 6; Endekriterien – 1, 2, 4"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Zuordnung von Beispielen für Eingangs- und Endekriterien sind:<br><br> Eingangskriterien:<ol style=\"list-style-type: circle;\"><li>(3) Die Testumgebung für den Performanz-Test wurde entworfen, eingerichtet und verifiziert - ein Beispiel dafür, dass eine Testumgebung bereit sein muss, bevor mit dem Testen begonnen werden kann.</li><li>(5) Die Designspezifikationen für den Autopiloten wurden einem Review unterzogen und nachgebessert – ein Beispiel dafür, dass die Testbasis zur Verfügung stehen muss, bevor mit dem Testen begonnen werden kann.</li><li>(6) Die Komponente für die Berechnung des Steuersatzes hat die Unit-Tests bestanden ein Beispiel für die Notwendigkeit, dass ein Testobjekt die Endekriterien einer vorangegangenen Teststufe erfüllen muss, bevor mit dem Testen begonnen werden kann.</li></ol>Endekriterien:<br><ol style=\"list-style-type: circle;\"><li> (1) Das ursprüngliche Testbudget von 30.000 US-Dollar plus eine Sicherheitsreserve von 7.000 US-Dollar wurde ausgegeben – ein Beispiel dafür, dass ein vollständig ausgeschöpftes Testbudget ein Signal ist, das Testen zu beenden.</li><li>(2) 96% der geplanten Tests für das Zeichenpaket wurden ausgeführt und die verbleibenden Tests sind jetzt nicht mehr Bestandteil des Testumfangs - ein Beispiel dafür, dass die Durchführung aller geplanten Tests ein Signal ist, das Testen zu beenden (normalerweise zusammen mit den Endekriterien für ungelöste Fehlerzustände verwendet).</li><li>(4) Derzeit gibt es keine kritischen Fehlerzustände und zwei Fehlerzustände mit hoher Priorität. – ein Beispiel für die Anzahl ungelöster Fehlerzustände, die eine geplante Grenze erreichen, welche die Beendigung des Testens signalisiert (normalerweise zusammen mit den Endekriterien für geplante Tests verwendet).</li></ol>Somit ist Option d) korrekt.",
      "b": "Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Zuordnung von Beispielen für Eingangs- und Endekriterien sind:<br><br> Eingangskriterien:<ol style=\"list-style-type: circle;\"><li>(3) Die Testumgebung für den Performanz-Test wurde entworfen, eingerichtet und verifiziert - ein Beispiel dafür, dass eine Testumgebung bereit sein muss, bevor mit dem Testen begonnen werden kann.</li><li>(5) Die Designspezifikationen für den Autopiloten wurden einem Review unterzogen und nachgebessert – ein Beispiel dafür, dass die Testbasis zur Verfügung stehen muss, bevor mit dem Testen begonnen werden kann.</li><li>(6) Die Komponente für die Berechnung des Steuersatzes hat die Unit-Tests bestanden ein Beispiel für die Notwendigkeit, dass ein Testobjekt die Endekriterien einer vorangegangenen Teststufe erfüllen muss, bevor mit dem Testen begonnen werden kann.</li></ol>Endekriterien:<br><ol style=\"list-style-type: circle;\"><li> (1) Das ursprüngliche Testbudget von 30.000 US-Dollar plus eine Sicherheitsreserve von 7.000 US-Dollar wurde ausgegeben – ein Beispiel dafür, dass ein vollständig ausgeschöpftes Testbudget ein Signal ist, das Testen zu beenden.</li><li>(2) 96% der geplanten Tests für das Zeichenpaket wurden ausgeführt und die verbleibenden Tests sind jetzt nicht mehr Bestandteil des Testumfangs - ein Beispiel dafür, dass die Durchführung aller geplanten Tests ein Signal ist, das Testen zu beenden (normalerweise zusammen mit den Endekriterien für ungelöste Fehlerzustände verwendet).</li><li>(4) Derzeit gibt es keine kritischen Fehlerzustände und zwei Fehlerzustände mit hoher Priorität. – ein Beispiel für die Anzahl ungelöster Fehlerzustände, die eine geplante Grenze erreichen, welche die Beendigung des Testens signalisiert (normalerweise zusammen mit den Endekriterien für geplante Tests verwendet).</li></ol>Somit ist Option d) korrekt.",
      "c": "Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Zuordnung von Beispielen für Eingangs- und Endekriterien sind:<br><br> Eingangskriterien:<ol style=\"list-style-type: circle;\"><li>(3) Die Testumgebung für den Performanz-Test wurde entworfen, eingerichtet und verifiziert - ein Beispiel dafür, dass eine Testumgebung bereit sein muss, bevor mit dem Testen begonnen werden kann.</li><li>(5) Die Designspezifikationen für den Autopiloten wurden einem Review unterzogen und nachgebessert – ein Beispiel dafür, dass die Testbasis zur Verfügung stehen muss, bevor mit dem Testen begonnen werden kann.</li><li>(6) Die Komponente für die Berechnung des Steuersatzes hat die Unit-Tests bestanden ein Beispiel für die Notwendigkeit, dass ein Testobjekt die Endekriterien einer vorangegangenen Teststufe erfüllen muss, bevor mit dem Testen begonnen werden kann.</li></ol>Endekriterien:<br><ol style=\"list-style-type: circle;\"><li> (1) Das ursprüngliche Testbudget von 30.000 US-Dollar plus eine Sicherheitsreserve von 7.000 US-Dollar wurde ausgegeben – ein Beispiel dafür, dass ein vollständig ausgeschöpftes Testbudget ein Signal ist, das Testen zu beenden.</li><li>(2) 96% der geplanten Tests für das Zeichenpaket wurden ausgeführt und die verbleibenden Tests sind jetzt nicht mehr Bestandteil des Testumfangs - ein Beispiel dafür, dass die Durchführung aller geplanten Tests ein Signal ist, das Testen zu beenden (normalerweise zusammen mit den Endekriterien für ungelöste Fehlerzustände verwendet).</li><li>(4) Derzeit gibt es keine kritischen Fehlerzustände und zwei Fehlerzustände mit hoher Priorität. – ein Beispiel für die Anzahl ungelöster Fehlerzustände, die eine geplante Grenze erreichen, welche die Beendigung des Testens signalisiert (normalerweise zusammen mit den Endekriterien für geplante Tests verwendet).</li></ol>Somit ist Option d) korrekt.",
      "d": "Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Zuordnung von Beispielen für Eingangs- und Endekriterien sind:<br><br> Eingangskriterien:<ol style=\"list-style-type: circle;\"><li>(3) Die Testumgebung für den Performanz-Test wurde entworfen, eingerichtet und verifiziert - ein Beispiel dafür, dass eine Testumgebung bereit sein muss, bevor mit dem Testen begonnen werden kann.</li><li>(5) Die Designspezifikationen für den Autopiloten wurden einem Review unterzogen und nachgebessert – ein Beispiel dafür, dass die Testbasis zur Verfügung stehen muss, bevor mit dem Testen begonnen werden kann.</li><li>(6) Die Komponente für die Berechnung des Steuersatzes hat die Unit-Tests bestanden ein Beispiel für die Notwendigkeit, dass ein Testobjekt die Endekriterien einer vorangegangenen Teststufe erfüllen muss, bevor mit dem Testen begonnen werden kann.</li></ol>Endekriterien:<br><ol style=\"list-style-type: circle;\"><li> (1) Das ursprüngliche Testbudget von 30.000 US-Dollar plus eine Sicherheitsreserve von 7.000 US-Dollar wurde ausgegeben – ein Beispiel dafür, dass ein vollständig ausgeschöpftes Testbudget ein Signal ist, das Testen zu beenden.</li><li>(2) 96% der geplanten Tests für das Zeichenpaket wurden ausgeführt und die verbleibenden Tests sind jetzt nicht mehr Bestandteil des Testumfangs - ein Beispiel dafür, dass die Durchführung aller geplanten Tests ein Signal ist, das Testen zu beenden (normalerweise zusammen mit den Endekriterien für ungelöste Fehlerzustände verwendet).</li><li>(4) Derzeit gibt es keine kritischen Fehlerzustände und zwei Fehlerzustände mit hoher Priorität. – ein Beispiel für die Anzahl ungelöster Fehlerzustände, die eine geplante Grenze erreichen, welche die Beendigung des Testens signalisiert (normalerweise zusammen mit den Endekriterien für geplante Tests verwendet).</li></ol>Somit ist Option d) korrekt."
    }
  },
  {
    "frage": "Gegeben sind die folgenden Prioritäten und Abhängigkeiten von Testfällen:",
    "inhalte": [
      {
        "typ": "text",
        "inhalt": "Gegeben sind die folgenden Prioritäten und Abhängigkeiten von Testfällen:"
      },
      {
        "typ": "tabelle",
        "inhalt": {
          "kopf": [
            "Testfall",
            "Priorität",
            "Technische Abhängigkeit von:",
            "Logische Abhängigkeit von:"
          ],
          "koerper": [
            {
              "zeile": [
                "TF1",
                "Hoch",
                "TF4",
                ""
              ],
              "istKopfZeile": false
            },
            {
              "zeile": [
                "TF2",
                "Niedrig",
                "",
                ""
              ],
              "istKopfZeile": false
            },
            {
              "zeile": [
                "TF3",
                "Hoch",
                "",
                "TF4"
              ],
              "istKopfZeile": false
            },
            {
              "zeile": [
                "TF4",
                "Mittel",
                "",
                ""
              ],
              "istKopfZeile": false
            },
            {
              "zeile": [
                "TF5",
                "Niedrig",
                "",
                "TF2"
              ],
              "istKopfZeile": false
            },
            {
              "zeile": [
                "TF6",
                "Mittel",
                "TF5",
                ""
              ],
              "istKopfZeile": false
            }
          ]
        }
      },
      {
        "typ": "text",
        "inhalt": "Welcher der folgenden Testausführungspläne berücksichtigt AM BESTEN die Prioritäten sowie technische und logische Abhängigkeiten?<br><br>Wählen Sie genau EINE korrekte Option aus!"
      }
    ],
    "antworten": {
      "a": "TF1 – TF3 – TF4 – TF6 – TF2 – TF5",
      "b": "TF4 – TF3 – TF1 – TF2 – TF5 – TF6",
      "c": "TF4 – TF1 – TF3 – TF5 – TF6 – TF2",
      "d": "TF4 – TF2 – TF5 – TF1 – TF3 – TF6"
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die Testfälle sollten in der Reihenfolge der Priorität ausgeführt werden, aber der Ausführungsplan muss auch die Abhängigkeiten berücksichtigen.<br><br>Die zwei Testfälle mit der höchsten Priorität (TF1 und TF3) sind beide abhängig von TF4, daher sollten die ersten drei Testfälle entweder in der Reihenfolge TF4 – TF1 – TF3 oder in der Reihenfolge TF4 – TF3 –TF1 ausgeführt werden (Wir haben keine Möglichkeit, zwischen TF1 und TF3 zu unterscheiden).<br><br>Als nächstes müssen wir den verbleibenden Testfall mittlerer Priorität TF6 betrachten. TF6 ist abhängig von TF5, aber TF5 ist abhängig von TF2, daher müssen die nächsten drei Testfälle in folgender Reihenfolge ausgeführt werden: TF2 – TF5 – TF6.<br><br>Das bedeutet, es gibt zwei optimale Ausführungspläne:<ol style=\"list-style-type: circle;\"><li>TF4 – TF1 – TF3 – TF2 – TF5 – TF6</li><li>TF4 – TF3 – TF1 – TF2 – TF5 – TF6</li></ol>Somit ist Option b) korrekt.",
      "b": "KORREKT<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die Testfälle sollten in der Reihenfolge der Priorität ausgeführt werden, aber der Ausführungsplan muss auch die Abhängigkeiten berücksichtigen.<br><br>Die zwei Testfälle mit der höchsten Priorität (TF1 und TF3) sind beide abhängig von TF4, daher sollten die ersten drei Testfälle entweder in der Reihenfolge TF4 – TF1 – TF3 oder in der Reihenfolge TF4 – TF3 –TF1 ausgeführt werden (Wir haben keine Möglichkeit, zwischen TF1 und TF3 zu unterscheiden).<br><br>Als nächstes müssen wir den verbleibenden Testfall mittlerer Priorität TF6 betrachten. TF6 ist abhängig von TF5, aber TF5 ist abhängig von TF2, daher müssen die nächsten drei Testfälle in folgender Reihenfolge ausgeführt werden: TF2 – TF5 – TF6.<br><br>Das bedeutet, es gibt zwei optimale Ausführungspläne:<ol style=\"list-style-type: circle;\"><li>TF4 – TF1 – TF3 – TF2 – TF5 – TF6</li><li>TF4 – TF3 – TF1 – TF2 – TF5 – TF6</li></ol>Somit ist Option b) korrekt.",
      "c": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die Testfälle sollten in der Reihenfolge der Priorität ausgeführt werden, aber der Ausführungsplan muss auch die Abhängigkeiten berücksichtigen.<br><br>Die zwei Testfälle mit der höchsten Priorität (TF1 und TF3) sind beide abhängig von TF4, daher sollten die ersten drei Testfälle entweder in der Reihenfolge TF4 – TF1 – TF3 oder in der Reihenfolge TF4 – TF3 –TF1 ausgeführt werden (Wir haben keine Möglichkeit, zwischen TF1 und TF3 zu unterscheiden).<br><br>Als nächstes müssen wir den verbleibenden Testfall mittlerer Priorität TF6 betrachten. TF6 ist abhängig von TF5, aber TF5 ist abhängig von TF2, daher müssen die nächsten drei Testfälle in folgender Reihenfolge ausgeführt werden: TF2 – TF5 – TF6.<br><br>Das bedeutet, es gibt zwei optimale Ausführungspläne:<ol style=\"list-style-type: circle;\"><li>TF4 – TF1 – TF3 – TF2 – TF5 – TF6</li><li>TF4 – TF3 – TF1 – TF2 – TF5 – TF6</li></ol>Somit ist Option b) korrekt.",
      "d": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die Testfälle sollten in der Reihenfolge der Priorität ausgeführt werden, aber der Ausführungsplan muss auch die Abhängigkeiten berücksichtigen.<br><br>Die zwei Testfälle mit der höchsten Priorität (TF1 und TF3) sind beide abhängig von TF4, daher sollten die ersten drei Testfälle entweder in der Reihenfolge TF4 – TF1 – TF3 oder in der Reihenfolge TF4 – TF3 –TF1 ausgeführt werden (Wir haben keine Möglichkeit, zwischen TF1 und TF3 zu unterscheiden).<br><br>Als nächstes müssen wir den verbleibenden Testfall mittlerer Priorität TF6 betrachten. TF6 ist abhängig von TF5, aber TF5 ist abhängig von TF2, daher müssen die nächsten drei Testfälle in folgender Reihenfolge ausgeführt werden: TF2 – TF5 – TF6.<br><br>Das bedeutet, es gibt zwei optimale Ausführungspläne:<ol style=\"list-style-type: circle;\"><li>TF4 – TF1 – TF3 – TF2 – TF5 – TF6</li><li>TF4 – TF3 – TF1 – TF2 – TF5 – TF6</li></ol>Somit ist Option b) korrekt."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen über Testschätzverfahren ist korrekt?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Beim metrikbasierten Verfahren basiert die Schätzung auf Testmaßnahmen aus dem Projekt, so dass diese Schätzung erst nach Beginn des Tests verfügbar ist.",
      "b": "Beim expertenbasierten Verfahren empfiehlt eine vom Kunden identifizierte Gruppe von Experten das erforderliche Testbudget.",
      "c": "Beim expertenbasierten Verfahren schätzen die für die verschiedenen Testaktivitäten verantwortlichen Testmanager den erwarteten Testaufwand.",
      "d": "Beim metrikbasierten Ansatz wird ein Durchschnitt der Testkosten, die aus mehreren vergangenen Projekten ermittelt wurden, als Testbudget verwendet."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Die Schätzungen werden möglicherweise aktualisiert, sobald weitere Informationen verfügbar sind. Es sind jedoch Schätzungen erforderlich, um die Planung vor Beginn der Tests zu unterstützen.",
      "b": "FALSCH<br><br>Die Experten beim expertenbasierten Verfahren müssen Experten für das Testen sein und nicht für das Testobjekt.",
      "c": "KORREKT<br><br>Beim expertenbasierten Ansatz werden die für die verschiedenen Testaktivitäten verantwortlichen Testmanager als Experten für ihr jeweiliges Gebiet betrachtet. Daher sind sie in der Lage, den erwarteten Testaufwand zu schätzen.",
      "d": "FALSCH<br><br>Es ist zwar nützlich, die Testkosten aus früheren Projekten zu kennen, jedoch ist ein anspruchsvollerer Ansatz erforderlich, als nur den Durchschnitt vergangener Projekte zu ermitteln. (Das neue Projekt kann möglicherweise nicht mit den vergangenen Projekten vergleichbar sein, z. B. kann es viel größer oder viel kleiner sein als die vergangenen Projekte)."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen definiert AM BESTEN die Risikostufe<br>(Höhe des Risikos)?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die Risikostufe wird berechnet, indem die Wahrscheinlichkeiten aller Problemsituationen und der daraus resultierende finanzielle Schaden addiert werden.",
      "b": "Die Risikostufe wird geschätzt, indem die Wahrscheinlichkeit einer Bedrohung des Systems multipliziert wird mit der Wahrscheinlichkeit, dass die Bedrohung auftritt und finanzielle Schäden verursacht.",
      "c": "Die Risikostufe wird bestimmt durch eine Kombination der Wahrscheinlichkeit eines unerwünschten Ereignisses und der erwarteten Auswirkung dieses Ereignisses.",
      "d": "Die Risikostufe ist die Summe aller potenziellen Gefahren für ein System multipliziert mit der Summe aller potenziellen Verluste aus diesem System."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Die Risikostufe wird bestimmt, indem eine Kombination aus der Wahrscheinlichkeit von Problemsituationen und dem daraus resultierenden Schaden betrachtet wird; die Risikostufe kann jedoch nicht durch Addition dieser Faktoren berechnet werden (die Wahrscheinlichkeit würde im Bereich von 0 bis 1 liegen und der Schaden könnte in Euro beziffert sein).",
      "b": "FALSCH<br><br>Das Risiko wird bestimmt, indem eine Kombination aus Wahrscheinlichkeit und Auswirkung berücksichtigt wird. Diese Definition berücksichtigt nur Wahrscheinlichkeit und Zufall ohne Berücksichtigung der Auswirkungen (oder des Schadens).",
      "c": "KORREKT<br><br>Wie beschrieben im CTFL Lehrplan 2018, Abschnitt 5.5.1<br><br>5.5.1 Definition des Risikos<br>Ein Risiko ist ein möglicherweise vorkommendes Ereignis in der Zukunft, das negative Auswirkungen hat. Die Höhe des Risikos wird durch die Eintrittswahrscheinlichkeit des Ereignisses und dessen Wirkung (der Schadenhöhe) bestimmt.",
      "d": "FALSCH<br><br>Das Risiko wird bestimmt, indem eine Kombination aus Wahrscheinlichkeit und Auswirkung berücksichtigt wird. Diese Definition berücksichtigt nur Gefahren und Verluste (eine Gefahr ist ein schlechtes Ereignis wie ein Risiko, während ein Verlust eine Form der Auswirkung ist), ohne die Wahrscheinlichkeit zu berücksichtigen."
    }
  },
  {
    "frage": "Welcher der folgenden Aussagen ist AM EHESTEN ein Beispiel für ein Produktrisiko?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die erwarteten IT-Sicherheitsmerkmale werden von der Systemarchitektur möglicherweise nicht unterstützt.",
      "b": "Die Entwickler haben möglicherweise nicht die Zeit, alle vom Testteam gefundenen Fehler zu beheben.",
      "c": "Die Testfälle decken die spezifizierten Anforderungen möglicherweise nicht vollständig ab.",
      "d": "Die Umgebung für den Performanztest ist möglicherweise nicht einsatzbereit, bevor das System zur Auslieferung ansteht."
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Werden die erwarteten IT-Sicherheitsmerkmale von der Systemarchitektur nicht unterstützt, kann das System schwerwiegende Fehler aufweisen. Da hier das zu produzierende System das Problem ist, handelt es sich um ein Produktrisiko.",
      "b": "FALSCH<br><br>Wenn die Entwickler das Budget überschreiten oder die Zeit knapp wird, ist das ein Problem mit dem Projektablauf - es ist ein Projektrisiko.",
      "c": "FALSCH<br><br>Wenn die Testfälle die Anforderungen nicht vollständig überdecken, bedeutet dies, dass die Prüfung möglicherweise nicht die Anforderungen des Testkonzepts erfüllt - es ist ein Projektrisiko.",
      "d": "FALSCH<br><br>Wenn die Testumgebung nicht einsatzbereit ist, bedeutet dies, dass der Test möglicherweise nicht durchgeführt werden kann, oder dass er auf einer anderen Umgebung durchgeführt werden muss, und dass er sich auf die Durchführung des Projekts auswirkt - es ist ein Projektrisiko."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen zum Zusammenhang von Produktrisiko und Testmanagement ist am wenigsten sinnvoll?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "Die potenziellen Auswirkungen von IT-Sicherheitsmängeln wurden als besonders hoch eingestuft, so dass IT-Sicherheitstests vor einigen anderen Testaktivitäten priorisiert wurden.",
      "b": "Die Tests haben ergeben, dass die Qualität des Netzwerkmoduls besser ist als erwartet, so dass nun zusätzliche Tests in diesem Bereich durchgeführt werden.",
      "c": "Die Benutzer hatten Probleme mit der Benutzeroberfläche des bisherigen Systems, so dass zusätzliche Usability-Tests für das Ersatzsystem geplant sind.",
      "d": "Die Zeit, die zum Laden von Webseiten benötigt wird, ist entscheidend für den Erfolg der neuen Website, weshalb für dieses Projekt ein Experte für Leistungstests eingesetzt wurde."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Da uns gesagt wird, dass Sicherheitsmängel eine besonders hohe Auswirkung haben, wird ihr Risiko höher sein. Deshalb wurde der Sicherheitstest vor einigen anderen Tests priorisiert. Der Einfluss der Produktrisikoanalyse auf den Test wurde somit KORREKT eingeschätzt.",
      "b": "KORREKT<br><br>Da im Netzwerkmodul weniger Fehler als erwartet festgestellt wurden, sollte das wahrgenommene Risiko in diesem Bereich geringer sein, und daher sollten sich WENIGER Tests auf diesen Bereich konzentrieren und NICHT zusätzliche Tests. Daher hat die Produktrisikoanalyse den Test in dieser Situation NICHT KORREKT beeinflusst.",
      "c": "FALSCH<br><br>Da die Anwender Probleme mit der Benutzeroberfläche des bisherigen Systems hatten, ist das Risiko der Benutzeroberfläche inzwischen sehr hoch, was dazu geführt hat, dass weitere Usability-Tests geplant sind. Der Einfluss der Produktrisikoanalyse auf den Test wurde somit KORREKT eingeschätzt. Daher hat die Produktrisikoanalyse den Umfang der Tests RICHTIG beeinflusst.",
      "d": "FALSCH<br><br>Da die Zeit, die zum Laden von Webseiten benötigt wird, als entscheidend für den Erfolg der neuen Website eingestuft wurde, sollte die Leistung der Website als Risiko angesehen werden, und die Beschäftigung eines Experten für Leistungstests hilft, dieses Risiko zu minimieren. Somit hat die Produktrisikoanalyse den Test RICHTIG beeinflusst."
    }
  },
  {
    "frage": "Sie führen Systemtests für ein Zugbuchungssystem durch. Basierend auf den durchgeführten Testfällen haben Sie festgestellt, dass das System gelegentlich meldet, dass keine Züge verfügbar sind, obwohl dies eigentlich der Fall sein sollte. Sie haben den Entwicklern eine Zusammenfassung des Fehlers und der Version des getesteten Systems zur Verfügung gestellt. Diese erkennen die Dringlichkeit des Fehlers und warten nun darauf, dass Sie weitere Details angeben.<br><br>Abgesehen von den bereits aufgeführten Informationen sind folgende weitere Informationen gegeben:<ol><li>Grad der Auswirkung (Schwere) des Fehlers.</li><li>Identifikation des Testelements.</li><li>Details der Testumgebung.</li><li>Dringlichkeit/Priorität für die Behebung.</li><li>Istergebnisse.</li><li>Referenz auf die Testfallspezifikation.</li></ol>",
    "inhalte": [
      {
        "typ": "text",
        "inhalt": "Welche dieser Informationen sind AM SINNVOLLSTEN, um sie in den Fehlerbericht mit aufzunehmen?<br><br>Wählen Sie genau EINE korrekte Option aus!"
      }
    ],
    "antworten": {
      "a": "1, 2, 6",
      "b": "1, 4, 5, 6",
      "c": "2, 3, 4, 5",
      "d": "3, 5, 6"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3) <ol><li>Grad der Auswirkung (Schwere) des Fehlerzustands - die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.</li><li>Identifizierung des Testelements - da die Entwickler das Problem bereits kennen und Sie Systemtests durchführen und Sie bereits die Version des zu testenden Systems zur Verfügung gestellt haben, können Sie davon ausgehen, dass die Entwickler das zu testende Element kennen, daher ist dies eine weniger wichtige Information.</li><li>Details der Testumgebung - der Aufbau der Testumgebung kann einen spürbaren Einfluss auf die Testergebnisse haben, und es sollten detaillierte Informationen dazu bereitgestellt werden, daher ist dies eine wichtige Information.</li><li>Dringlichkeit/Priorität für die Behebung- die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.</li><li>Istergebnisse - die Istergebnisse können den Entwicklern gut helfen, festzustellen, was mit dem System schiefläuft, daher ist dies eine wichtige Information.</li><li>Referenz auf die Testfallspezifikation - dies zeigt den Entwicklern die von Ihnen ausgeführten Tests, einschließlich der Testeingaben, die zum Ausfall des Systems führten (und der erwarteten Ergebnisse), so dass dies eine wichtige Information ist.</li></ol> Option d) ist korrekt.",
      "b": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3) <ol><li>Grad der Auswirkung (Schwere) des Fehlerzustands - die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.</li><li>Identifizierung des Testelements - da die Entwickler das Problem bereits kennen und Sie Systemtests durchführen und Sie bereits die Version des zu testenden Systems zur Verfügung gestellt haben, können Sie davon ausgehen, dass die Entwickler das zu testende Element kennen, daher ist dies eine weniger wichtige Information.</li><li>Details der Testumgebung - der Aufbau der Testumgebung kann einen spürbaren Einfluss auf die Testergebnisse haben, und es sollten detaillierte Informationen dazu bereitgestellt werden, daher ist dies eine wichtige Information.</li><li>Dringlichkeit/Priorität für die Behebung- die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.</li><li>Istergebnisse - die Istergebnisse können den Entwicklern gut helfen, festzustellen, was mit dem System schiefläuft, daher ist dies eine wichtige Information.</li><li>Referenz auf die Testfallspezifikation - dies zeigt den Entwicklern die von Ihnen ausgeführten Tests, einschließlich der Testeingaben, die zum Ausfall des Systems führten (und der erwarteten Ergebnisse), so dass dies eine wichtige Information ist.</li></ol> Option d) ist korrekt.",
      "c": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3) <ol><li>Grad der Auswirkung (Schwere) des Fehlerzustands - die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.</li><li>Identifizierung des Testelements - da die Entwickler das Problem bereits kennen und Sie Systemtests durchführen und Sie bereits die Version des zu testenden Systems zur Verfügung gestellt haben, können Sie davon ausgehen, dass die Entwickler das zu testende Element kennen, daher ist dies eine weniger wichtige Information.</li><li>Details der Testumgebung - der Aufbau der Testumgebung kann einen spürbaren Einfluss auf die Testergebnisse haben, und es sollten detaillierte Informationen dazu bereitgestellt werden, daher ist dies eine wichtige Information.</li><li>Dringlichkeit/Priorität für die Behebung- die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.</li><li>Istergebnisse - die Istergebnisse können den Entwicklern gut helfen, festzustellen, was mit dem System schiefläuft, daher ist dies eine wichtige Information.</li><li>Referenz auf die Testfallspezifikation - dies zeigt den Entwicklern die von Ihnen ausgeführten Tests, einschließlich der Testeingaben, die zum Ausfall des Systems führten (und der erwarteten Ergebnisse), so dass dies eine wichtige Information ist.</li></ol> Option d) ist korrekt.",
      "d": "KORREKT<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3) <ol><li>Grad der Auswirkung (Schwere) des Fehlerzustands - die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.</li><li>Identifizierung des Testelements - da die Entwickler das Problem bereits kennen und Sie Systemtests durchführen und Sie bereits die Version des zu testenden Systems zur Verfügung gestellt haben, können Sie davon ausgehen, dass die Entwickler das zu testende Element kennen, daher ist dies eine weniger wichtige Information.</li><li>Details der Testumgebung - der Aufbau der Testumgebung kann einen spürbaren Einfluss auf die Testergebnisse haben, und es sollten detaillierte Informationen dazu bereitgestellt werden, daher ist dies eine wichtige Information.</li><li>Dringlichkeit/Priorität für die Behebung- die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.</li><li>Istergebnisse - die Istergebnisse können den Entwicklern gut helfen, festzustellen, was mit dem System schiefläuft, daher ist dies eine wichtige Information.</li><li>Referenz auf die Testfallspezifikation - dies zeigt den Entwicklern die von Ihnen ausgeführten Tests, einschließlich der Testeingaben, die zum Ausfall des Systems führten (und der erwarteten Ergebnisse), so dass dies eine wichtige Information ist.</li></ol> Option d) ist korrekt."
    }
  },
  {
    "frage": "Gegeben seien folgende Testaktivitäten und Testwerkzeuge:<br><br><ol><li>Performanzmessung und dynamische Analyse.</li><li>Testdurchführung und Protokollierung.</li><li>Management des Testens und Testmittel.</li><li>Testentwurf.</li></ol><ol style=\"list-style-type: upper-alpha;\"><li>Werkzeuge für Anforderungsüberdeckung.</li><li>Dynamische Analysewerkzeuge.</li><li>Werkzeuge zur Vorbereitung von Testdaten.</li><li>Fehlermanagementwerkzeuge.</li></ol>Welcher der folgenden Kombinationen passt am besten zu den Aktivitäten und Tools?<br><br>Wählen Sie genau EINE korrekte Option aus!",
    "inhalte": [],
    "antworten": {
      "a": "1 – B, 2 – C, 3 – D, 4 – A",
      "b": "1 – B, 2 – A, 3 – C, 4 – D",
      "c": "1 – B, 2 – A, 3 – D, 4 – C",
      "d": "1 – A, 2 – B, 3 – D, 4 – C"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Zuordnung von Testaktivitäten und Testwerkzeugen ist laut Lehrplan 6.1.1:<br><br>a) 1. Performanzmessung und dynamische Analyse - (B) Dynamische Analysewerkzeuge<br>b) 2. Testausführung und Protokollierung - (A) Tools zur Anforderungsüberdeckung<br>c) 3. Management von Tests und Testmitteln - (D) Fehlerverwaltungswerkzeuge<br>d) 4. Testentwurf - (C) Werkzeuge zur Vorbereitung von Testdaten<br><br>Somit ist Option c) korrekt.<br><br>6.1.1 Klassifizierung von Testwerkzeugen<br><br>Testwerkzeuge können, abhängig vom Kontext, einen oder mehrere der folgenden Zwecke erfüllen:<ol style=\"list-style-type: circle;\"><li>Die Effizienz der Testaktivitäten durch die Automatisierung sich wiederholender Aufgaben verbessern oder von Aufgaben, die erhebliche Ressourcen verbrauchen, wenn sie manuell durchgeführt werden (z.B. Testdurchführung, Regressionstests).</li><li>Die Effizienz von Testaktivitäten durch die Unterstützung von manuellen Testaktivitäten während des Testprozesses verbessern (siehe Abschnitt 1.4 Testprozess).</li><li>Verbesserung der Qualität der Testaktivitäten durch konsistenteres Testen und eine höhere Fehlerreproduzierbarkeit.</li><li>Aktivitäten automatisieren, die nicht manuell ausgeführt werden können (z.B. groß angelegte Performanztests).</li><li>Die Zuverlässigkeit des Testens erhöhen (z.B. durch automatisierten Vergleich großer Datenmengen oder die Simulation von Verhaltensweisen).</li></ol>Werkzeuge können auf Basis verschiedener Kriterien wie Zweck, Preis, Lizenzmodell (z.B. kommerzielle Standardsoftware oder Open Source) und genutzter Technologie klassifiziert werden. In diesem Lehrplan sind Werkzeuge in Bezug auf Testaktivitäten klassifiziert, die sie unterstützen.<br><br>Einige Werkzeuge unterstützen nur oder hauptsächlich eine Aktivität, andere können mehr als eine Aktivität unterstützen, aber sie sind unter der Aktivität klassifiziert, mit der sie am wahrscheinlichsten in Verbindung gebracht werden. Werkzeuge eines einzigen Anbieters, insbesondere diejenigen, die entworfen wurden, um zusammenzuarbeiten, können als eine integrierte Suite zur Verfügung gestellt werden.<br><br>Einige Arten von Testwerkzeugen können intrusiv sein, d.h., sie können das tatsächliche Ergebnis des Tests beeinflussen. Beispielsweise können die tatsächlichen Antwortzeiten einer Anwendung aufgrund der zusätzlichen Anweisungen, die von einem Performanztestwerkzeug ausgeführt werden, differieren oder die erreichte Codeüberdeckung kann durch die Verwendung eines Überdeckungswerkzeugs verzerrt sein. Die Folge des Einsatzes von intrusiven Werkzeugen wird Untersuchungseffekt genannt.<br><br>Einige Werkzeuge sind als Unterstützung insbesondere für Entwickler geeignet (z.B. Werkzeuge, die während Komponenten- und Integrationstests genutzt werden). Derartige Werkzeuge sind in den folgenden Abschnitten mit „(E)“ markiert.<br><br>Werkzeugunterstützung für das Management des Testens und für Testmittel<br>Managementwerkzeuge können auf jede Testaktivität über den gesamten Softwareentwicklungslebenszyklus angewendet werden. Beispiele für Werkzeuge, die das Management des Testens und Testmittel unterstützen, sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testmanagementwerkzeuge und Application-Lifecycle-Management-Werkzeuge (ALM).</li><li>Anforderungsmanagementwerkzeuge (z.B. Verfolgbarkeit zu Testobjekten).</li><li>Fehlermanagementwerkzeuge.</li><li>Konfigurationsmanagementwerkzeuge.</li><li>Werkzeuge zur kontinuierlichen Integration (E).</li></ol>Werkzeugunterstützung für statische Tests<br>Statische Testwerkzeuge stehen in Verbindung mit den Aktivitäten und Nutzen, die in Kapitel 3 beschrieben wurden. Beispiele für ein solches Werkzeug sind u.a.:<ol style=\"list-style-type: circle;\"><li>Statische Analysewerkzeuge (E).</li></ol>Werkzeugunterstützung für Testentwurf und -realisierung<br>Testentwurfswerkzeuge helfen beim Erstellen von wartbaren Arbeitsergebnissen im Testentwurf und der Testrealisierung, u.a. beim Erstellen von Testfällen, Testabläufen und Testdaten. Beispiele für solche Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testwerkzeuge für das modellbasierte Testen.</li><li>Testdateneditoren und -generatoren.</li></ol>In einigen Fällen können Werkzeuge, die Testentwurf und -realisierung unterstützen, auch die Testdurchführung und -aufzeichnung unterstützen oder ihre Ausgaben direkt an andere Werkzeuge übertragen, die bei der Testdurchführung und -aufzeichnung helfen.<br><br>Werkzeugunterstützung für Testdurchführung und -protokollierung<br>Viele Werkzeuge existieren, um die Testdurchführung und -protokollierung zu unterstützen und zu verbessern. Beispiele für diese Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testausführungswerkzeuge (z.B. um Regressionstests durchzuführen).</li><li>Überdeckungswerkzeuge (z.B. Anforderungsüberdeckung, Codeüberdeckung (E)).</li><li>Testrahmen (E).</li></ol>Werkzeugunterstützung zur Performanzmessung und dynamischen Analyse<br>Werkzeuge zur Performanzmessung und dynamischen Analyse sind wesentlich für die Unterstützung von Performanz- und Lasttestaktivitäten, da diese Aktivitäten nicht effektiv manuell durchführbar sind. Beispiele für solche Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Performanztestwerkzeuge.</li><li>Dynamische Analysewerkzeuge (E).</li></ol>Werkzeugunterstützung für spezielle Testbedürfnisse<br>Zusätzlich zu Werkzeugen, die den allgemeinen Testprozess unterstützen, gibt es viele andere Werkzeuge, die spezifische Aspekte des Testens nichtfunktionaler Merkmale unterstützen.",
      "b": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Zuordnung von Testaktivitäten und Testwerkzeugen ist laut Lehrplan 6.1.1:<br><br>a) 1. Performanzmessung und dynamische Analyse - (B) Dynamische Analysewerkzeuge<br>b) 2. Testausführung und Protokollierung - (A) Tools zur Anforderungsüberdeckung<br>c) 3. Management von Tests und Testmitteln - (D) Fehlerverwaltungswerkzeuge<br>d) 4. Testentwurf - (C) Werkzeuge zur Vorbereitung von Testdaten<br><br>Somit ist Option c) korrekt.<br><br>6.1.1 Klassifizierung von Testwerkzeugen<br><br>Testwerkzeuge können, abhängig vom Kontext, einen oder mehrere der folgenden Zwecke erfüllen:<ol style=\"list-style-type: circle;\"><li>Die Effizienz der Testaktivitäten durch die Automatisierung sich wiederholender Aufgaben verbessern oder von Aufgaben, die erhebliche Ressourcen verbrauchen, wenn sie manuell durchgeführt werden (z.B. Testdurchführung, Regressionstests).</li><li>Die Effizienz von Testaktivitäten durch die Unterstützung von manuellen Testaktivitäten während des Testprozesses verbessern (siehe Abschnitt 1.4 Testprozess).</li><li>Verbesserung der Qualität der Testaktivitäten durch konsistenteres Testen und eine höhere Fehlerreproduzierbarkeit.</li><li>Aktivitäten automatisieren, die nicht manuell ausgeführt werden können (z.B. groß angelegte Performanztests).</li><li>Die Zuverlässigkeit des Testens erhöhen (z.B. durch automatisierten Vergleich großer Datenmengen oder die Simulation von Verhaltensweisen).</li></ol>Werkzeuge können auf Basis verschiedener Kriterien wie Zweck, Preis, Lizenzmodell (z.B. kommerzielle Standardsoftware oder Open Source) und genutzter Technologie klassifiziert werden. In diesem Lehrplan sind Werkzeuge in Bezug auf Testaktivitäten klassifiziert, die sie unterstützen.<br><br>Einige Werkzeuge unterstützen nur oder hauptsächlich eine Aktivität, andere können mehr als eine Aktivität unterstützen, aber sie sind unter der Aktivität klassifiziert, mit der sie am wahrscheinlichsten in Verbindung gebracht werden. Werkzeuge eines einzigen Anbieters, insbesondere diejenigen, die entworfen wurden, um zusammenzuarbeiten, können als eine integrierte Suite zur Verfügung gestellt werden.<br><br>Einige Arten von Testwerkzeugen können intrusiv sein, d.h., sie können das tatsächliche Ergebnis des Tests beeinflussen. Beispielsweise können die tatsächlichen Antwortzeiten einer Anwendung aufgrund der zusätzlichen Anweisungen, die von einem Performanztestwerkzeug ausgeführt werden, differieren oder die erreichte Codeüberdeckung kann durch die Verwendung eines Überdeckungswerkzeugs verzerrt sein. Die Folge des Einsatzes von intrusiven Werkzeugen wird Untersuchungseffekt genannt.<br><br>Einige Werkzeuge sind als Unterstützung insbesondere für Entwickler geeignet (z.B. Werkzeuge, die während Komponenten- und Integrationstests genutzt werden). Derartige Werkzeuge sind in den folgenden Abschnitten mit „(E)“ markiert.<br><br>Werkzeugunterstützung für das Management des Testens und für Testmittel<br>Managementwerkzeuge können auf jede Testaktivität über den gesamten Softwareentwicklungslebenszyklus angewendet werden. Beispiele für Werkzeuge, die das Management des Testens und Testmittel unterstützen, sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testmanagementwerkzeuge und Application-Lifecycle-Management-Werkzeuge (ALM).</li><li>Anforderungsmanagementwerkzeuge (z.B. Verfolgbarkeit zu Testobjekten).</li><li>Fehlermanagementwerkzeuge.</li><li>Konfigurationsmanagementwerkzeuge.</li><li>Werkzeuge zur kontinuierlichen Integration (E).</li></ol>Werkzeugunterstützung für statische Tests<br>Statische Testwerkzeuge stehen in Verbindung mit den Aktivitäten und Nutzen, die in Kapitel 3 beschrieben wurden. Beispiele für ein solches Werkzeug sind u.a.:<ol style=\"list-style-type: circle;\"><li>Statische Analysewerkzeuge (E).</li></ol>Werkzeugunterstützung für Testentwurf und -realisierung<br>Testentwurfswerkzeuge helfen beim Erstellen von wartbaren Arbeitsergebnissen im Testentwurf und der Testrealisierung, u.a. beim Erstellen von Testfällen, Testabläufen und Testdaten. Beispiele für solche Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testwerkzeuge für das modellbasierte Testen.</li><li>Testdateneditoren und -generatoren.</li></ol>In einigen Fällen können Werkzeuge, die Testentwurf und -realisierung unterstützen, auch die Testdurchführung und -aufzeichnung unterstützen oder ihre Ausgaben direkt an andere Werkzeuge übertragen, die bei der Testdurchführung und -aufzeichnung helfen.<br><br>Werkzeugunterstützung für Testdurchführung und -protokollierung<br>Viele Werkzeuge existieren, um die Testdurchführung und -protokollierung zu unterstützen und zu verbessern. Beispiele für diese Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testausführungswerkzeuge (z.B. um Regressionstests durchzuführen).</li><li>Überdeckungswerkzeuge (z.B. Anforderungsüberdeckung, Codeüberdeckung (E)).</li><li>Testrahmen (E).</li></ol>Werkzeugunterstützung zur Performanzmessung und dynamischen Analyse<br>Werkzeuge zur Performanzmessung und dynamischen Analyse sind wesentlich für die Unterstützung von Performanz- und Lasttestaktivitäten, da diese Aktivitäten nicht effektiv manuell durchführbar sind. Beispiele für solche Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Performanztestwerkzeuge.</li><li>Dynamische Analysewerkzeuge (E).</li></ol>Werkzeugunterstützung für spezielle Testbedürfnisse<br>Zusätzlich zu Werkzeugen, die den allgemeinen Testprozess unterstützen, gibt es viele andere Werkzeuge, die spezifische Aspekte des Testens nichtfunktionaler Merkmale unterstützen.",
      "c": "KORREKT<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Zuordnung von Testaktivitäten und Testwerkzeugen ist laut Lehrplan 6.1.1:<br><br>a) 1. Performanzmessung und dynamische Analyse - (B) Dynamische Analysewerkzeuge<br>b) 2. Testausführung und Protokollierung - (A) Tools zur Anforderungsüberdeckung<br>c) 3. Management von Tests und Testmitteln - (D) Fehlerverwaltungswerkzeuge<br>d) 4. Testentwurf - (C) Werkzeuge zur Vorbereitung von Testdaten<br><br>Somit ist Option c) korrekt.<br><br>6.1.1 Klassifizierung von Testwerkzeugen<br><br>Testwerkzeuge können, abhängig vom Kontext, einen oder mehrere der folgenden Zwecke erfüllen:<ol style=\"list-style-type: circle;\"><li>Die Effizienz der Testaktivitäten durch die Automatisierung sich wiederholender Aufgaben verbessern oder von Aufgaben, die erhebliche Ressourcen verbrauchen, wenn sie manuell durchgeführt werden (z.B. Testdurchführung, Regressionstests).</li><li>Die Effizienz von Testaktivitäten durch die Unterstützung von manuellen Testaktivitäten während des Testprozesses verbessern (siehe Abschnitt 1.4 Testprozess).</li><li>Verbesserung der Qualität der Testaktivitäten durch konsistenteres Testen und eine höhere Fehlerreproduzierbarkeit.</li><li>Aktivitäten automatisieren, die nicht manuell ausgeführt werden können (z.B. groß angelegte Performanztests).</li><li>Die Zuverlässigkeit des Testens erhöhen (z.B. durch automatisierten Vergleich großer Datenmengen oder die Simulation von Verhaltensweisen).</li></ol>Werkzeuge können auf Basis verschiedener Kriterien wie Zweck, Preis, Lizenzmodell (z.B. kommerzielle Standardsoftware oder Open Source) und genutzter Technologie klassifiziert werden. In diesem Lehrplan sind Werkzeuge in Bezug auf Testaktivitäten klassifiziert, die sie unterstützen.<br><br>Einige Werkzeuge unterstützen nur oder hauptsächlich eine Aktivität, andere können mehr als eine Aktivität unterstützen, aber sie sind unter der Aktivität klassifiziert, mit der sie am wahrscheinlichsten in Verbindung gebracht werden. Werkzeuge eines einzigen Anbieters, insbesondere diejenigen, die entworfen wurden, um zusammenzuarbeiten, können als eine integrierte Suite zur Verfügung gestellt werden.<br><br>Einige Arten von Testwerkzeugen können intrusiv sein, d.h., sie können das tatsächliche Ergebnis des Tests beeinflussen. Beispielsweise können die tatsächlichen Antwortzeiten einer Anwendung aufgrund der zusätzlichen Anweisungen, die von einem Performanztestwerkzeug ausgeführt werden, differieren oder die erreichte Codeüberdeckung kann durch die Verwendung eines Überdeckungswerkzeugs verzerrt sein. Die Folge des Einsatzes von intrusiven Werkzeugen wird Untersuchungseffekt genannt.<br><br>Einige Werkzeuge sind als Unterstützung insbesondere für Entwickler geeignet (z.B. Werkzeuge, die während Komponenten- und Integrationstests genutzt werden). Derartige Werkzeuge sind in den folgenden Abschnitten mit „(E)“ markiert.<br><br>Werkzeugunterstützung für das Management des Testens und für Testmittel<br>Managementwerkzeuge können auf jede Testaktivität über den gesamten Softwareentwicklungslebenszyklus angewendet werden. Beispiele für Werkzeuge, die das Management des Testens und Testmittel unterstützen, sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testmanagementwerkzeuge und Application-Lifecycle-Management-Werkzeuge (ALM).</li><li>Anforderungsmanagementwerkzeuge (z.B. Verfolgbarkeit zu Testobjekten).</li><li>Fehlermanagementwerkzeuge.</li><li>Konfigurationsmanagementwerkzeuge.</li><li>Werkzeuge zur kontinuierlichen Integration (E).</li></ol>Werkzeugunterstützung für statische Tests<br>Statische Testwerkzeuge stehen in Verbindung mit den Aktivitäten und Nutzen, die in Kapitel 3 beschrieben wurden. Beispiele für ein solches Werkzeug sind u.a.:<ol style=\"list-style-type: circle;\"><li>Statische Analysewerkzeuge (E).</li></ol>Werkzeugunterstützung für Testentwurf und -realisierung<br>Testentwurfswerkzeuge helfen beim Erstellen von wartbaren Arbeitsergebnissen im Testentwurf und der Testrealisierung, u.a. beim Erstellen von Testfällen, Testabläufen und Testdaten. Beispiele für solche Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testwerkzeuge für das modellbasierte Testen.</li><li>Testdateneditoren und -generatoren.</li></ol>In einigen Fällen können Werkzeuge, die Testentwurf und -realisierung unterstützen, auch die Testdurchführung und -aufzeichnung unterstützen oder ihre Ausgaben direkt an andere Werkzeuge übertragen, die bei der Testdurchführung und -aufzeichnung helfen.<br><br>Werkzeugunterstützung für Testdurchführung und -protokollierung<br>Viele Werkzeuge existieren, um die Testdurchführung und -protokollierung zu unterstützen und zu verbessern. Beispiele für diese Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testausführungswerkzeuge (z.B. um Regressionstests durchzuführen).</li><li>Überdeckungswerkzeuge (z.B. Anforderungsüberdeckung, Codeüberdeckung (E)).</li><li>Testrahmen (E).</li></ol>Werkzeugunterstützung zur Performanzmessung und dynamischen Analyse<br>Werkzeuge zur Performanzmessung und dynamischen Analyse sind wesentlich für die Unterstützung von Performanz- und Lasttestaktivitäten, da diese Aktivitäten nicht effektiv manuell durchführbar sind. Beispiele für solche Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Performanztestwerkzeuge.</li><li>Dynamische Analysewerkzeuge (E).</li></ol>Werkzeugunterstützung für spezielle Testbedürfnisse<br>Zusätzlich zu Werkzeugen, die den allgemeinen Testprozess unterstützen, gibt es viele andere Werkzeuge, die spezifische Aspekte des Testens nichtfunktionaler Merkmale unterstützen.",
      "d": "FALSCH<br><br>Begründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)<br><br>Die korrekte Zuordnung von Testaktivitäten und Testwerkzeugen ist laut Lehrplan 6.1.1:<br><br>a) 1. Performanzmessung und dynamische Analyse - (B) Dynamische Analysewerkzeuge<br>b) 2. Testausführung und Protokollierung - (A) Tools zur Anforderungsüberdeckung<br>c) 3. Management von Tests und Testmitteln - (D) Fehlerverwaltungswerkzeuge<br>d) 4. Testentwurf - (C) Werkzeuge zur Vorbereitung von Testdaten<br><br>Somit ist Option c) korrekt.<br><br>6.1.1 Klassifizierung von Testwerkzeugen<br><br>Testwerkzeuge können, abhängig vom Kontext, einen oder mehrere der folgenden Zwecke erfüllen:<ol style=\"list-style-type: circle;\"><li>Die Effizienz der Testaktivitäten durch die Automatisierung sich wiederholender Aufgaben verbessern oder von Aufgaben, die erhebliche Ressourcen verbrauchen, wenn sie manuell durchgeführt werden (z.B. Testdurchführung, Regressionstests).</li><li>Die Effizienz von Testaktivitäten durch die Unterstützung von manuellen Testaktivitäten während des Testprozesses verbessern (siehe Abschnitt 1.4 Testprozess).</li><li>Verbesserung der Qualität der Testaktivitäten durch konsistenteres Testen und eine höhere Fehlerreproduzierbarkeit.</li><li>Aktivitäten automatisieren, die nicht manuell ausgeführt werden können (z.B. groß angelegte Performanztests).</li><li>Die Zuverlässigkeit des Testens erhöhen (z.B. durch automatisierten Vergleich großer Datenmengen oder die Simulation von Verhaltensweisen).</li></ol>Werkzeuge können auf Basis verschiedener Kriterien wie Zweck, Preis, Lizenzmodell (z.B. kommerzielle Standardsoftware oder Open Source) und genutzter Technologie klassifiziert werden. In diesem Lehrplan sind Werkzeuge in Bezug auf Testaktivitäten klassifiziert, die sie unterstützen.<br><br>Einige Werkzeuge unterstützen nur oder hauptsächlich eine Aktivität, andere können mehr als eine Aktivität unterstützen, aber sie sind unter der Aktivität klassifiziert, mit der sie am wahrscheinlichsten in Verbindung gebracht werden. Werkzeuge eines einzigen Anbieters, insbesondere diejenigen, die entworfen wurden, um zusammenzuarbeiten, können als eine integrierte Suite zur Verfügung gestellt werden.<br><br>Einige Arten von Testwerkzeugen können intrusiv sein, d.h., sie können das tatsächliche Ergebnis des Tests beeinflussen. Beispielsweise können die tatsächlichen Antwortzeiten einer Anwendung aufgrund der zusätzlichen Anweisungen, die von einem Performanztestwerkzeug ausgeführt werden, differieren oder die erreichte Codeüberdeckung kann durch die Verwendung eines Überdeckungswerkzeugs verzerrt sein. Die Folge des Einsatzes von intrusiven Werkzeugen wird Untersuchungseffekt genannt.<br><br>Einige Werkzeuge sind als Unterstützung insbesondere für Entwickler geeignet (z.B. Werkzeuge, die während Komponenten- und Integrationstests genutzt werden). Derartige Werkzeuge sind in den folgenden Abschnitten mit „(E)“ markiert.<br><br>Werkzeugunterstützung für das Management des Testens und für Testmittel<br>Managementwerkzeuge können auf jede Testaktivität über den gesamten Softwareentwicklungslebenszyklus angewendet werden. Beispiele für Werkzeuge, die das Management des Testens und Testmittel unterstützen, sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testmanagementwerkzeuge und Application-Lifecycle-Management-Werkzeuge (ALM).</li><li>Anforderungsmanagementwerkzeuge (z.B. Verfolgbarkeit zu Testobjekten).</li><li>Fehlermanagementwerkzeuge.</li><li>Konfigurationsmanagementwerkzeuge.</li><li>Werkzeuge zur kontinuierlichen Integration (E).</li></ol>Werkzeugunterstützung für statische Tests<br>Statische Testwerkzeuge stehen in Verbindung mit den Aktivitäten und Nutzen, die in Kapitel 3 beschrieben wurden. Beispiele für ein solches Werkzeug sind u.a.:<ol style=\"list-style-type: circle;\"><li>Statische Analysewerkzeuge (E).</li></ol>Werkzeugunterstützung für Testentwurf und -realisierung<br>Testentwurfswerkzeuge helfen beim Erstellen von wartbaren Arbeitsergebnissen im Testentwurf und der Testrealisierung, u.a. beim Erstellen von Testfällen, Testabläufen und Testdaten. Beispiele für solche Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testwerkzeuge für das modellbasierte Testen.</li><li>Testdateneditoren und -generatoren.</li></ol>In einigen Fällen können Werkzeuge, die Testentwurf und -realisierung unterstützen, auch die Testdurchführung und -aufzeichnung unterstützen oder ihre Ausgaben direkt an andere Werkzeuge übertragen, die bei der Testdurchführung und -aufzeichnung helfen.<br><br>Werkzeugunterstützung für Testdurchführung und -protokollierung<br>Viele Werkzeuge existieren, um die Testdurchführung und -protokollierung zu unterstützen und zu verbessern. Beispiele für diese Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Testausführungswerkzeuge (z.B. um Regressionstests durchzuführen).</li><li>Überdeckungswerkzeuge (z.B. Anforderungsüberdeckung, Codeüberdeckung (E)).</li><li>Testrahmen (E).</li></ol>Werkzeugunterstützung zur Performanzmessung und dynamischen Analyse<br>Werkzeuge zur Performanzmessung und dynamischen Analyse sind wesentlich für die Unterstützung von Performanz- und Lasttestaktivitäten, da diese Aktivitäten nicht effektiv manuell durchführbar sind. Beispiele für solche Werkzeuge sind u.a.:<ol style=\"list-style-type: circle;\"><li>Performanztestwerkzeuge.</li><li>Dynamische Analysewerkzeuge (E).</li></ol>Werkzeugunterstützung für spezielle Testbedürfnisse<br>Zusätzlich zu Werkzeugen, die den allgemeinen Testprozess unterstützen, gibt es viele andere Werkzeuge, die spezifische Aspekte des Testens nichtfunktionaler Merkmale unterstützen."
    }
  },
  {
    "frage": "Welcher der folgenden Punkte wird AM WAHRSCHEINLICHSTEN als Grund für die Verwendung eines Pilotprojekts zur Einführung eines Werkzeugs in einem Unternehmen verwendet?",
    "inhalte": [],
    "antworten": {
      "a": "Die Notwendigkeit zu bewerten, wie das Werkzeug zu bestehenden Prozessen und Vorgehensweisen passt und zu bestimmen, was geändert werden muss.",
      "b": "Die Notwendigkeit, die Fähigkeiten zur Testautomatisierung sowie die Trainings-, Mentoring- und Coaching-Bedürfnisse der Tester zu bewerten, die das Werkzeug nutzen werden.",
      "c": "Die Notwendigkeit zu bewerten, ob das Werkzeug die erforderliche Funktionalität bietet und bestehende Testwerkzeuge nicht dupliziert.",
      "d": "Die Notwendigkeit, den Werkzeughersteller zu bewerten in Bezug auf die Schulung und andere Unterstützung, die er anbietet."
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Gemäß Lehrplan (6.2.2).<br><br>6.2.2 Pilotprojekte für die Einführung eines Werkzeugs in einem Unternehmen<br><br>Nach Abschluss der Auswahl eines Werkzeugs und der erfolgreichen Machbarkeitsstudie beginnt dessen Einführung in einem Unternehmen in der Regel mit einem Pilotprojekt, das die folgenden Ziele hat:<ol style=\"list-style-type: circle;\"><li>Tiefgehende Kenntnis über das Werkzeug und Verständnis seiner Stärken und Schwächen erzielen.</li><li>Evaluierung, wie das Werkzeug in bestehende Prozesse und Methoden passt, und bestimmen, was ggf. geändert werden müsste.</li><li>Über die Standardisierung des Werkzeugeinsatzes hinsichtlich Nutzung, Verwaltung, Speicherung und Wartung des Werkzeugs und der Testarbeitsergebnisse (z.B. Entscheidung über Namenskonventionen für Dateien und Tests, Auswahl von Programmierrichtlinien, Neuanlage von Bibliotheken und die Festlegung von modularen Testsuiten) entscheiden.</li><li>Beurteilen, ob der Nutzen mit vertretbaren Kosten erreicht werden kann.</li><li>Die Metriken, die das Werkzeug sammeln und aufzeichnen soll, verstehen und das Werkzeug konfigurieren, um sicherzustellen, dass diese Metriken erfasst und aufgezeichnet werden können.</li></ol>",
      "b": "FALSCH<br><br>Die Bewertung der Fähigkeiten zur Testautomatisierung und der Trainings-, Mentoring- und Coaching-Bedürfnisse der Tester, die das Tool verwenden werden, hätte im Rahmen der Werkzeugauswahl gemäß Lehrplan (6.2.1) durchgeführt werden sollen.<br><br>6.2.1 Hauptgrundsätze für die Auswahl von Werkzeugen<br><br>Grundsätzliche Überlegungen bei der Auswahl eines Werkzeugs für ein Unternehmen sind u.a.:<ol style=\"list-style-type: circle;\"><li>Bewertung der Reife des eigenen Unternehmens, Analyse der Stärken und Schwächen.</li><li>Identifizierung von Möglichkeiten für die Verbesserung des Testprozesses, unterstützt durch Werkzeuge.</li><li>Verständnis der Technologien, die von den Testobjekten genutzt werden, um ein Werkzeug auszuwählen, das mit dieser Technologie kompatibel ist.</li><li>Verständnis der Werkzeuge für Build und kontinuierliche Integration, die im Unternehmen bereits im Einsatz sind, um Werkzeugkompatibilität und Integration zu gewährleisten.</li><li>Bewertung des Werkzeugs gegen klar spezifizierte Anforderungen und objektive Kriterien (für Nutzen und Anwendung).</li><li>Überlegung, ob das Werkzeug für eine kostenfreie Testperiode verfügbar ist (und wie lange).</li><li>Bewertung des Anbieters (einschließlich Trainings-, Unterstützungs- und kommerzieller Aspekte) oder der Unterstützung für nichtkommerzielle Werkzeuge (z.B. Open Source).</li><li>Identifizierung interner Anforderungen für Coaching und Anleitung zur Nutzung des Werkzeugs.</li><li>Bewertung des Schulungsbedarfs unter Berücksichtigung der Test- (und Testautomatisierungs-) Kenntnisse derjenigen, die direkt mit dem Werkzeug arbeiten werden.</li><li>Überlegung zu Vor- und Nachteilen verschiedener Lizenzmodelle (z.B. kommerzieller Standardsoftware oder Open Source).</li><li>Schätzung des Kosten-Nutzen-Verhältnisses auf Basis eines konkreten Business Case (falls benötigt).</li></ol>Als letzter Schritt sollte eine Machbarkeitsstudie (Proof-of-Concept) durchgeführt werden, um zu beurteilen, ob das Werkzeug effektiv mit der zu testenden Software und innerhalb der aktuellen Infrastruktur arbeitet oder wenn nötig, um Änderungen zu identifizieren, die für diese Infrastruktur notwendig sind, um das Werkzeug effektiv nutzen zu können.",
      "c": "FALSCH<br><br>Die Entscheidung, ob das Werkzeug die erforderliche Funktionalität bietet und bestehende Werkzeuge nicht dupliziert, hätte im Rahmen der Werkzeugauswahl gemäß Lehrplan (6.2.1) getroffen werden sollen.<br><br>6.2.1 Hauptgrundsätze für die Auswahl von Werkzeugen<br><br>Grundsätzliche Überlegungen bei der Auswahl eines Werkzeugs für ein Unternehmen sind u.a.:<ol style=\"list-style-type: circle;\"><li>Bewertung der Reife des eigenen Unternehmens, Analyse der Stärken und Schwächen.</li><li>Identifizierung von Möglichkeiten für die Verbesserung des Testprozesses, unterstützt durch Werkzeuge.</li><li>Verständnis der Technologien, die von den Testobjekten genutzt werden, um ein Werkzeug auszuwählen, das mit dieser Technologie kompatibel ist.</li><li>Verständnis der Werkzeuge für Build und kontinuierliche Integration, die im Unternehmen bereits im Einsatz sind, um Werkzeugkompatibilität und Integration zu gewährleisten.</li><li>Bewertung des Werkzeugs gegen klar spezifizierte Anforderungen und objektive Kriterien (für Nutzen und Anwendung).</li><li>Überlegung, ob das Werkzeug für eine kostenfreie Testperiode verfügbar ist (und wie lange).</li><li>Bewertung des Anbieters (einschließlich Trainings-, Unterstützungs- und kommerzieller Aspekte) oder der Unterstützung für nichtkommerzielle Werkzeuge (z.B. Open Source).</li><li>Identifizierung interner Anforderungen für Coaching und Anleitung zur Nutzung des Werkzeugs.</li><li>Bewertung des Schulungsbedarfs unter Berücksichtigung der Test- (und Testautomatisierungs-) Kenntnisse derjenigen, die direkt mit dem Werkzeug arbeiten werden.</li><li>Überlegung zu Vor- und Nachteilen verschiedener Lizenzmodelle (z.B. kommerzieller Standardsoftware oder Open Source).</li><li>Schätzung des Kosten-Nutzen-Verhältnisses auf Basis eines konkreten Business Case (falls benötigt).</li></ol>Als letzter Schritt sollte eine Machbarkeitsstudie (Proof-of-Concept) durchgeführt werden, um zu beurteilen, ob das Werkzeug effektiv mit der zu testenden Software und innerhalb der aktuellen Infrastruktur arbeitet oder wenn nötig, um Änderungen zu identifizieren, die für diese Infrastruktur notwendig sind, um das Werkzeug effektiv nutzen zu können.",
      "d": "FALSCH<br><br>Die Bewertung des Werkzeugherstellers im Hinblick auf die Schulung und andere Unterstützung, die er anbietet, hätte im Rahmen der Werkzeugauswahl gemäß Lehrplan (6.2.1) durchgeführt werden sollen.<br><br>6.2.1 Hauptgrundsätze für die Auswahl von Werkzeugen<br><br>Grundsätzliche Überlegungen bei der Auswahl eines Werkzeugs für ein Unternehmen sind u.a.:<ol style=\"list-style-type: circle;\"><li>Bewertung der Reife des eigenen Unternehmens, Analyse der Stärken und Schwächen.</li><li>Identifizierung von Möglichkeiten für die Verbesserung des Testprozesses, unterstützt durch Werkzeuge.</li><li>Verständnis der Technologien, die von den Testobjekten genutzt werden, um ein Werkzeug auszuwählen, das mit dieser Technologie kompatibel ist.</li><li>Verständnis der Werkzeuge für Build und kontinuierliche Integration, die im Unternehmen bereits im Einsatz sind, um Werkzeugkompatibilität und Integration zu gewährleisten.</li><li>Bewertung des Werkzeugs gegen klar spezifizierte Anforderungen und objektive Kriterien (für Nutzen und Anwendung).</li><li>Überlegung, ob das Werkzeug für eine kostenfreie Testperiode verfügbar ist (und wie lange).</li><li>Bewertung des Anbieters (einschließlich Trainings-, Unterstützungs- und kommerzieller Aspekte) oder der Unterstützung für nichtkommerzielle Werkzeuge (z.B. Open Source).</li><li>Identifizierung interner Anforderungen für Coaching und Anleitung zur Nutzung des Werkzeugs.</li><li>Bewertung des Schulungsbedarfs unter Berücksichtigung der Test- (und Testautomatisierungs-) Kenntnisse derjenigen, die direkt mit dem Werkzeug arbeiten werden.</li><li>Überlegung zu Vor- und Nachteilen verschiedener Lizenzmodelle (z.B. kommerzieller Standardsoftware oder Open Source).</li><li>Schätzung des Kosten-Nutzen-Verhältnisses auf Basis eines konkreten Business Case (falls benötigt).</li></ol>Als letzter Schritt sollte eine Machbarkeitsstudie (Proof-of-Concept) durchgeführt werden, um zu beurteilen, ob das Werkzeug effektiv mit der zu testenden Software und innerhalb der aktuellen Infrastruktur arbeitet oder wenn nötig, um Änderungen zu identifizieren, die für diese Infrastruktur notwendig sind, um das Werkzeug effektiv nutzen zu können."
    }
  },
  {
    "frage": "Welche der folgenden Definition entspricht dem Begriff „Testbedingung“ gemäß Glossar? Wählen Sie genau eine korrekte Option.",
    "inhalte": [],
    "antworten": {
      "a": "Ein kennzeichnendes Merkmal einer Komponente oder eines Systems.",
      "b": "Ein testbarer Aspekt einer Komponente oder eines Systems, der als Grundlage für das Testen identifiziert wurde.",
      "c": "Der Grad, zu dem eine Komponente oder ein System Funktionen zur Verfügung stellt, welche unter festgelegten Bedingungen explizit genannte und implizite Bedürfnisse erfüllen.",
      "d": "Testfälle entworfen im Hinblick auf die Ausführung von Kombinationen von Bedingungen und aus ihnen resultierender Aktionen."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Definition von Feature gemäß Glossar.",
      "b": "KORREKT<br><br>Gemäß Glossar V.3.3.",
      "c": "FALSCH<br><br>Definition von funktionale(r) Eignung gemäß Glossar V.3.3.",
      "d": "FALSCH<br><br>In Anlehnung an die Definition von Entscheidungstabellentest gemäß Glossar V.3.3."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen beschreibt ein gültiges Ziel des Testens? Wählen Sie genau eine korrekte Option.",
    "inhalte": [],
    "antworten": {
      "a": "Der Test soll möglichst spät starten, damit die Entwicklung genug Zeit hatte, ein gutes Produkt zu erstellen.",
      "b": "Es soll validiert werden, ob das Testobjekt so funktioniert, wie es die Benutzer und andere Stakeholder erwarten.",
      "c": "Es soll nachgewiesen werden, dass alle möglichen Fehlerzustände identifiziert wurden.",
      "d": "Es soll nachgewiesen werden, dass alle verbleibenden Fehlerzustände keine Fehlerwirkungen verursachen werden."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Widerspruch zu Grundsatz 3: „Frühes Testen spart Zeit und Geld.“<br><br>(siehe CTFL CORE Lehrplan 2018; Abschnitt 1.3).<br><br>1.3 Sieben Grundsätze des Testens<ol style=\"list-style-type: decimal;\"><li>Testen zeigt die Anwesenheit von Fehlerzuständen, nicht deren Abwesenheit: Testen kann zeigen, dass Fehlerzustände vorliegen, aber es kann nicht beweisen, dass es keine Fehlerzustände gibt. Testen reduziert die Wahrscheinlichkeit, dass noch unentdeckte Fehlerzustände in der Software vorhanden sind, aber auch wenn keine Fehlerzustände gefunden werden, ist Testen kein Beweis für Korrektheit.</li><li>Vollständiges Testen ist nicht möglich: Ein vollständiger Test, bei dem alle möglichen Eingabewerte und deren Kombinationen unter Berücksichtigung aller unterschiedlichen Vorbedingungen ausgeführt werden, ist nicht durchführbar, mit Ausnahme von sehr trivialen Testobjekten. Anstatt zu versuchen, vollständig zu testen, sollten Risikoanalyse, Testverfahren und Prioritäten genutzt werden, um den Testaufwand zu konzentrieren.</li><li>Frühes Testen spart Zeit und Geld: Um Fehlerzustände früh zu finden, sollten sowohl statische als auch dynamische Testaktivitäten so früh wie möglich im Softwareentwicklungslebenszyklus gestartet werden. Frühes Testen wird oft als Shift left bezeichnet. Frühes Testen im Softwareentwicklungslebenszyklus hilft dabei, kostenintensive Änderungen zu reduzieren oder vollständig zu vermeiden.</li><li>Häufung von Fehlerzuständen: Eine kleine Anzahl von Modulen enthält in der Regel die meisten Fehlerzustände, die während des Testens in der Phase vor Inbetriebnahme entdeckt werden, oder ist verantwortlich für die meisten der betrieblichen Fehlerwirkungen. Vorausgesagte Anhäufungen von Fehlerzuständen und die tatsächlich beobachteten Anhäufungen von Fehlerzuständen im Test oder im Betrieb sind ein wichtiger Beitrag zur Risikoanalyse, die genutzt wird, um den Testaufwand zu konzentrieren.</li><li>Vorsicht vor dem Pestizid-Paradoxon: Wenn die gleichen Tests immer wieder wiederholt werden, finden diese Tests irgendwann keine neuen Fehlerzustände mehr. Um neue Fehlerzustände zu finden, müssen bestehende Tests und Testdaten möglicherweise verändert werden und neue Tests geschrieben werden.</li><li>Testen ist kontextabhängig: Je nach Einsatzgebiet und Kontext ist das Testen anzupassen. Zum Beispiel wird sicherheitskritische industrielle Steuerungssoftware anders getestet als eine mobile E-Commerce-Applikation.</li><li>Trugschluss: „Keine Fehler“ bedeutet ein brauchbares System: Einige Unternehmen erwarten, dass Tester alle denkbaren Tests durchführen und alle denkbaren Fehlerzustände finden können, aber die Grundsätze 2 und 1 lehren uns, dass dies unmöglich ist.</li></ol>Siehe Myers 2011, Kaner 2002, Weinberg 2008 und Beizer 1990 für Beispiele dieser und anderer Grundsätze des Testens.",
      "b": "KORREKT<br><br>Dies ist eines der Ziele des Testens<br><br>(vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.1.1).<br><br>1.1.1 Typische Ziele des Testens<ol style=\"list-style-type: circle;\"><li>Arbeitsergebnisse wie Anforderungen, User-Stories, Architekturdesign und Code bewerten, um Fehler zu identifizieren und in Folgearbeitsergebnissen zu vermeiden.</li><li>Verifizieren, ob alle spezifischen Anforderungen erfüllt sind.</li><li>Prüfen, ob das Testobjekt vollständig ist und validieren, ob das Testobjekt so funktioniert, wie es die Benutzer und andere Stakeholder erwarten.</li><li>Vertrauen in das Qualitätsniveau des Testobjekts schaffen.</li><li>Fehlerwirkungen und Fehlerzustände aufdecken, wodurch man Risiken aufgrund einer unzureichenden Softwarequalität reduziert.</li><li>Stakeholdern ausreichende Informationen zur Verfügung stellen, damit diese fundierte Entscheidungen treffen können, insbesondere bezüglich des Qualitätsniveaus des Testobjekts.</li><li>Konform mit vertraglichen, rechtlichen oder regulatorischen Anforderungen oder Standards zu sein und/oder um die Konformität (compliance) des Testobjekts mit diesen Anforderungen oder Standards zu verifizieren.</li></ol>Die Ziele des Testens können abhängig vom Kontext der zu testenden Komponente oder des Systems, das getestet wird, von der Teststufe und dem Softwareentwicklungslebenszyklus-Modell variieren. Diese Unterschiede können zum Beispiel Folgendes beinhalten:<ol style=\"list-style-type: circle;\"><li>Während des Komponententests kann es ein Ziel sein, so viele Fehlerwirkungen wie möglich zu finden, damit die zugrunde liegenden Fehlerzustände frühzeitig identifiziert und behoben werden. Ein weiteres Ziel kann es sein, die Codeüberdeckung durch Komponententests zu erhöhen.</li><li>Während des Abnahmetests kann es ein Ziel sein, zu bestätigen, dass das System so funktioniert wie erwartet und die Anforderungen erfüllt wurden. Ein weiteres Ziel dieses Tests kann darin bestehen, Stakeholdern Informationen über das Risiko einer Systemfreigabe zu einem festgelegten Zeitpunkt zu geben.</li></ol>",
      "c": "FALSCH<br><br>Grundsatz 2 besagt, dass vollständiges Testen unmöglich ist, und es kann nicht bewiesen werden, dass alle Fehlerzustände identifiziert wurden<br><br>(siehe CTFL CORE Lehrplan 2018; Abschnitt 1.3).<br><br>1.3 Sieben Grundsätze des Testens<ol style=\"list-style-type: decimal;\"><li>Testen zeigt die Anwesenheit von Fehlerzuständen, nicht deren Abwesenheit: Testen kann zeigen, dass Fehlerzustände vorliegen, aber es kann nicht beweisen, dass es keine Fehlerzustände gibt. Testen reduziert die Wahrscheinlichkeit, dass noch unentdeckte Fehlerzustände in der Software vorhanden sind, aber auch wenn keine Fehlerzustände gefunden werden, ist Testen kein Beweis für Korrektheit.</li><li>Vollständiges Testen ist nicht möglich: Ein vollständiger Test, bei dem alle möglichen Eingabewerte und deren Kombinationen unter Berücksichtigung aller unterschiedlichen Vorbedingungen ausgeführt werden, ist nicht durchführbar, mit Ausnahme von sehr trivialen Testobjekten. Anstatt zu versuchen, vollständig zu testen, sollten Risikoanalyse, Testverfahren und Prioritäten genutzt werden, um den Testaufwand zu konzentrieren.</li><li>Frühes Testen spart Zeit und Geld: Um Fehlerzustände früh zu finden, sollten sowohl statische als auch dynamische Testaktivitäten so früh wie möglich im Softwareentwicklungslebenszyklus gestartet werden. Frühes Testen wird oft als Shift left bezeichnet. Frühes Testen im Softwareentwicklungslebenszyklus hilft dabei, kostenintensive Änderungen zu reduzieren oder vollständig zu vermeiden.</li><li>Häufung von Fehlerzuständen: Eine kleine Anzahl von Modulen enthält in der Regel die meisten Fehlerzustände, die während des Testens in der Phase vor Inbetriebnahme entdeckt werden, oder ist verantwortlich für die meisten der betrieblichen Fehlerwirkungen. Vorausgesagte Anhäufungen von Fehlerzuständen und die tatsächlich beobachteten Anhäufungen von Fehlerzuständen im Test oder im Betrieb sind ein wichtiger Beitrag zur Risikoanalyse, die genutzt wird, um den Testaufwand zu konzentrieren.</li><li>Vorsicht vor dem Pestizid-Paradoxon: Wenn die gleichen Tests immer wieder wiederholt werden, finden diese Tests irgendwann keine neuen Fehlerzustände mehr. Um neue Fehlerzustände zu finden, müssen bestehende Tests und Testdaten möglicherweise verändert werden und neue Tests geschrieben werden.</li><li>Testen ist kontextabhängig: Je nach Einsatzgebiet und Kontext ist das Testen anzupassen. Zum Beispiel wird sicherheitskritische industrielle Steuerungssoftware anders getestet als eine mobile E-Commerce-Applikation.</li><li>Trugschluss: „Keine Fehler“ bedeutet ein brauchbares System: Einige Unternehmen erwarten, dass Tester alle denkbaren Tests durchführen und alle denkbaren Fehlerzustände finden können, aber die Grundsätze 2 und 1 lehren uns, dass dies unmöglich ist.</li></ol>Siehe Myers 2011, Kaner 2002, Weinberg 2008 und Beizer 1990 für Beispiele dieser und anderer Grundsätze des Testens.",
      "d": "FALSCH<br><br>Um eine Einschätzung treffen zu können, ob ein Defekt einen Fehler verursacht oder nicht, muss man den Fehlerzustand zunächst erkennen. Zu sagen, dass verbleibende Fehlerzustände keine Fehlerwirkungen verursachen, bedeutet implizit, dass alle Fehlerzustände gefunden wurden. Dies widerspricht erneut Grundsatz 2<br><br>(siehe CTFL CORE Lehrplan 2018; Abschnitt 1.3).<br><br>1.3 Sieben Grundsätze des Testens<ol style=\"list-style-type: decimal;\"><li>Testen zeigt die Anwesenheit von Fehlerzuständen, nicht deren Abwesenheit: Testen kann zeigen, dass Fehlerzustände vorliegen, aber es kann nicht beweisen, dass es keine Fehlerzustände gibt. Testen reduziert die Wahrscheinlichkeit, dass noch unentdeckte Fehlerzustände in der Software vorhanden sind, aber auch wenn keine Fehlerzustände gefunden werden, ist Testen kein Beweis für Korrektheit.</li><li>Vollständiges Testen ist nicht möglich: Ein vollständiger Test, bei dem alle möglichen Eingabewerte und deren Kombinationen unter Berücksichtigung aller unterschiedlichen Vorbedingungen ausgeführt werden, ist nicht durchführbar, mit Ausnahme von sehr trivialen Testobjekten. Anstatt zu versuchen, vollständig zu testen, sollten Risikoanalyse, Testverfahren und Prioritäten genutzt werden, um den Testaufwand zu konzentrieren.</li><li>Frühes Testen spart Zeit und Geld: Um Fehlerzustände früh zu finden, sollten sowohl statische als auch dynamische Testaktivitäten so früh wie möglich im Softwareentwicklungslebenszyklus gestartet werden. Frühes Testen wird oft als Shift left bezeichnet. Frühes Testen im Softwareentwicklungslebenszyklus hilft dabei, kostenintensive Änderungen zu reduzieren oder vollständig zu vermeiden.</li><li>Häufung von Fehlerzuständen: Eine kleine Anzahl von Modulen enthält in der Regel die meisten Fehlerzustände, die während des Testens in der Phase vor Inbetriebnahme entdeckt werden, oder ist verantwortlich für die meisten der betrieblichen Fehlerwirkungen. Vorausgesagte Anhäufungen von Fehlerzuständen und die tatsächlich beobachteten Anhäufungen von Fehlerzuständen im Test oder im Betrieb sind ein wichtiger Beitrag zur Risikoanalyse, die genutzt wird, um den Testaufwand zu konzentrieren.</li><li>Vorsicht vor dem Pestizid-Paradoxon: Wenn die gleichen Tests immer wieder wiederholt werden, finden diese Tests irgendwann keine neuen Fehlerzustände mehr. Um neue Fehlerzustände zu finden, müssen bestehende Tests und Testdaten möglicherweise verändert werden und neue Tests geschrieben werden.</li><li>Testen ist kontextabhängig: Je nach Einsatzgebiet und Kontext ist das Testen anzupassen. Zum Beispiel wird sicherheitskritische industrielle Steuerungssoftware anders getestet als eine mobile E-Commerce-Applikation.</li><li>Trugschluss: „Keine Fehler“ bedeutet ein brauchbares System: Einige Unternehmen erwarten, dass Tester alle denkbaren Tests durchführen und alle denkbaren Fehlerzustände finden können, aber die Grundsätze 2 und 1 lehren uns, dass dies unmöglich ist.</li></ol>Siehe Myers 2011, Kaner 2002, Weinberg 2008 und Beizer 1990 für Beispiele dieser und anderer Grundsätze des Testens."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen beschreibt den Unterschied zwischen Testen und Debugging zutreffend?<br><br>Wählen Sie genau eine korrekte Option.",
    "inhalte": [],
    "antworten": {
      "a": "Testen identifiziert die Ursache von Fehlerzuständen. Debugging analysiert die Fehlerzustände und schlägt Präventionsmaßnahmen vor.",
      "b": "Dynamische Tests zeigen Fehlerwirkungen auf, die durch Fehlerzustände verursacht wurden. Debugging ist eine Entwicklungsaktivität, die Fehlerzustände beseitigt, die die Ursache von Fehlerwirkungen sind.",
      "c": "Testen entfernt Fehlerwirkungen; Debugging entfernt dagegen Fehlerzustände, die Fehlerwirkungen verursachen.",
      "d": "Dynamische Tests verhindern die Ursache von Fehlerwirkungen. Debugging entfernt die Fehlerwirkungen."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Durch Testen können nicht die Ursachen von Fehlerwirkungen identifiziert werden, sondern nur durch Debugging (siehe CTFL CORE Lehrplan 2018, Abschnitt 1.1.2).<br><br>1.1.2 Testen und Debugging<ol style=\"list-style-type: decimal;\"><li>Testen und Debugging sind unterschiedliche Dinge. Die Durchführung von Tests kann Fehlerwirkungen aufzeigen, die durch Fehlerzustände in der Software hervorgerufen werden. Debugging ist im Gegensatz dazu die Entwicklungsaktivität, die solche Fehlerzustände findet, analysiert und behebt.</li><li>Die nachfolgenden Fehlernachtests prüfen, ob die Debugging-Maßnahmen die ursprünglichen Fehlerzustände behoben haben. In manchen Fällen sind Tester für die ursprünglichen Tests und die abschließenden Fehlernachtests verantwortlich, während Entwickler das Debugging, die zugehörigen Komponenten- und Komponentenintegrationstests (kontinuierliche Integration) durchführen.</li><li>Dennoch können in der agilen Softwareentwicklung und in einigen anderen Softwareentwicklungslebenszyklusmodellen Tester auch am Debugging und im Komponententest involviert sein.</li><li>Die ISO-Norm (ISO/IEC/IEEE 29119-1) beinhaltet weitere Informationen über Konzepte des Softwaretestens.</li></ol>",
      "b": "KORREKT<br><br>Dynamisches Testen zeigt Fehlerwirkungen auf, die durch Fehlerzustände verursacht wurden. Durch Debugging können die Ursachen von Fehlerwirkungen analysiert und beseitigt werden (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.1.2).<br><br>1.1.2 Testen und Debugging<ol style=\"list-style-type: decimal;\"><li>Testen und Debugging sind unterschiedliche Dinge. Die Durchführung von Tests kann Fehlerwirkungen aufzeigen, die durch Fehlerzustände in der Software hervorgerufen werden. Debugging ist im Gegensatz dazu die Entwicklungsaktivität, die solche Fehlerzustände findet, analysiert und behebt.</li><li>Die nachfolgenden Fehlernachtests prüfen, ob die Debugging-Maßnahmen die ursprünglichen Fehlerzustände behoben haben. In manchen Fällen sind Tester für die ursprünglichen Tests und die abschließenden Fehlernachtests verantwortlich, während Entwickler das Debugging, die zugehörigen Komponenten- und Komponentenintegrationstests (kontinuierliche Integration) durchführen.</li><li>Dennoch können in der agilen Softwareentwicklung und in einigen anderen Softwareentwicklungslebenszyklusmodellen Tester auch am Debugging und im Komponententest involviert sein.</li><li>Die ISO-Norm (ISO/IEC/IEEE 29119-1) beinhaltet weitere Informationen über Konzepte des Softwaretestens.</li></ol>",
      "c": "FALSCH<br><br>Durch Testen werden keine Fehlerzustände und daraus folgende Fehlerwirkungen entfernt, sondern nur durch Debugging (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.1.2).<br><br>1.1.2 Testen und Debugging<ol style=\"list-style-type: decimal;\"><li>Testen und Debugging sind unterschiedliche Dinge. Die Durchführung von Tests kann Fehlerwirkungen aufzeigen, die durch Fehlerzustände in der Software hervorgerufen werden. Debugging ist im Gegensatz dazu die Entwicklungsaktivität, die solche Fehlerzustände findet, analysiert und behebt.</li><li>Die nachfolgenden Fehlernachtests prüfen, ob die Debugging-Maßnahmen die ursprünglichen Fehlerzustände behoben haben. In manchen Fällen sind Tester für die ursprünglichen Tests und die abschließenden Fehlernachtests verantwortlich, während Entwickler das Debugging, die zugehörigen Komponenten- und Komponentenintegrationstests (kontinuierliche Integration) durchführen.</li><li>Dennoch können in der agilen Softwareentwicklung und in einigen anderen Softwareentwicklungslebenszyklusmodellen Tester auch am Debugging und im Komponententest involviert sein.</li><li>Die ISO-Norm (ISO/IEC/IEEE 29119-1) beinhaltet weitere Informationen über Konzepte des Softwaretestens.</li></ol>",
      "d": "FALSCH<br><br>Durch dynamische Tests können die Ursachen von Fehlerwirkungen (d. h. Fehlerzustände) nicht verhindert werden, sondern nur das Vorhandensein von Fehlerzuständen, die Fehlerwirkungen hervorrufen, nachgewiesen werden. (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.1.2 und Abschnitt 1.3; 1. Grundsatz).<br><br>1.1.2 Testen und Debugging<br><br>Testen und Debugging sind unterschiedliche Dinge. Die Durchführung von Tests kann Fehlerwirkungen aufzeigen, die durch Fehlerzustände in der Software hervorgerufen werden. Debugging ist im Gegensatz dazu die Entwicklungsaktivität, die solche Fehlerzustände findet, analysiert und behebt. Die nachfolgenden Fehlernachtests prüfen, ob die Debugging-Maßnahmen die ursprünglichen Fehlerzustände behoben haben. In manchen Fällen sind Tester für die ursprünglichen Tests und die abschließenden Fehlernachtests verantwortlich, während Entwickler das Debugging, die zugehörigen Komponenten- und Komponentenintegrationstests (kontinuierliche Integration) durchführen. Dennoch können in der agilen Softwareentwicklung und in einigen anderen Softwareentwicklungslebenszyklusmodellen Tester auch am Debugging und im Komponententest involviert sein. Die ISO-Norm (ISO/IEC/IEEE 29119-1) beinhaltet weitere Informationen über Konzepte des Softwaretestens.<br><br>1.3 Sieben Grundsätze des Testens<ol style=\"list-style-type: decimal;\"><li>Testen zeigt die Anwesenheit von Fehlerzuständen, nicht deren Abwesenheit: Testen kann zeigen, dass Fehlerzustände vorliegen, aber es kann nicht beweisen, dass es keine Fehlerzustände gibt. Testen reduziert die Wahrscheinlichkeit, dass noch unentdeckte Fehlerzustände in der Software vorhanden sind, aber auch wenn keine Fehlerzustände gefunden werden, ist Testen kein Beweis für Korrektheit.</li><li>Vollständiges Testen ist nicht möglich: Ein vollständiger Test, bei dem alle möglichen Eingabewerte und deren Kombinationen unter Berücksichtigung aller unterschiedlichen Vorbedingungen ausgeführt werden, ist nicht durchführbar, mit Ausnahme von sehr trivialen Testobjekten. Anstatt zu versuchen, vollständig zu testen, sollten Risikoanalyse, Testverfahren und Prioritäten genutzt werden, um den Testaufwand zu konzentrieren.</li><li>Frühes Testen spart Zeit und Geld: Um Fehlerzustände früh zu finden, sollten sowohl statische als auch dynamische Testaktivitäten so früh wie möglich im Softwareentwicklungslebenszyklus gestartet werden. Frühes Testen wird oft als Shift left bezeichnet. Frühes Testen im Softwareentwicklungslebenszyklus hilft dabei, kostenintensive Änderungen zu reduzieren oder vollständig zu vermeiden.</li><li>Häufung von Fehlerzuständen: Eine kleine Anzahl von Modulen enthält in der Regel die meisten Fehlerzustände, die während des Testens in der Phase vor Inbetriebnahme entdeckt werden, oder ist verantwortlich für die meisten der betrieblichen Fehlerwirkungen. Vorausgesagte Anhäufungen von Fehlerzuständen und die tatsächlich beobachteten Anhäufungen von Fehlerzuständen im Test oder im Betrieb sind ein wichtiger Beitrag zur Risikoanalyse, die genutzt wird, um den Testaufwand zu konzentrieren.</li><li>Vorsicht vor dem Pestizid-Paradoxon: Wenn die gleichen Tests immer wieder wiederholt werden, finden diese Tests irgendwann keine neuen Fehlerzustände mehr. Um neue Fehlerzustände zu finden, müssen bestehende Tests und Testdaten möglicherweise verändert werden und neue Tests geschrieben werden.</li><li>Testen ist kontextabhängig: Je nach Einsatzgebiet und Kontext ist das Testen anzupassen. Zum Beispiel wird sicherheitskritische industrielle Steuerungssoftware anders getestet als eine mobile E-Commerce-Applikation.</li><li>Trugschluss: „Keine Fehler“ bedeutet ein brauchbares System: Einige Unternehmen erwarten, dass Tester alle denkbaren Tests durchführen und alle denkbaren Fehlerzustände finden können, aber die Grundsätze 2 und 1 lehren uns, dass dies unmöglich ist.</li></ol>Siehe Myers 2011, Kaner 2002, Weinberg 2008 und Beizer 1990 für Beispiele dieser und anderer Grundsätze des Testens."
    }
  },



  

  {
    "frage": "Nachfolgend finden Sie eine Liste von Problemen, die während des Testens oder im Betrieb beobachtet werden können.<br><br>Welches Problem ist eine Fehlerwirkung?<br><br>Wählen Sie genau eine korrekte Option.",
    "inhalte": [],
    "antworten": {
      "a": "Das Produkt stürzte ab, als der Benutzer eine Option in einer Dialogbox auswählte.",
      "b": "Eine kompilierte Quellcodedatei wurde in der falschen Version zum Build hinzugefügt.",
      "c": "Der Berechnungsalgorithmus verwendet die falschen Eingangsvariablen.",
      "d": "Der Entwickler hat die Anforderungen an den Algorithmus falsch interpretiert."
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Eine Fehlerwirkung ist das Sichtbarwerden eines Fehlerzustands während der Ausführung. Ein Absturz ist vom Anwender deutlich spürbar (siehe CTFL Lehrplan CORE 2018; Abschnitt 1.2.3)",
      "b": "FALSCH<br><br>Diese Art von Fehlern (Fehlhandlungen) wird nicht unbedingt zu einer sichtbaren oder spürbaren Fehlerwirkung führen; zum Beispiel, wenn die Änderungen in der neuen Version der Quelldatei nur in den Kommentaren vorgenommen wurden. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)",
      "c": "FALSCH<br><br>Es handelt sich um einen Fehlerzustand, nicht um eine Fehlerwirkung. Verwendung von falschen Eingabevariablen wird nicht unbedingt zu einer sichtbaren oder spürbaren Fehlerwirkung führen; zum Beispiel, wenn niemand diesen speziellen Algorithmus verwendet; oder wenn die falsche Eingabevariable einen ähnlichen Wert wie die richtige Eingabevariable hat; oder wenn das FALSCHE Resultat des Algorithmus nicht verwendet wird. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)",
      "d": "FALSCH<br><br>Es handelt sich um eine Fehlhandlung, nicht um eine Fehlerwirkung. Diese Art von Fehlern wird nicht notwendigerweise zu einer Fehlerwirkung führen; zum Beispiel, wenn niemand diesen speziellen Algorithmus verwendet. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)"
    }
  },
  {
    "frage": "Ein Tester hat über einen Zeitraum von 5 Jahren Software-Applikationen auf mobilen Geräten einem Test unterzogen. Er hat sich einen großen Erfahrungsschatz im Testen von mobilen Applikationen angeeignet und erzielt in kürzer Zeit bessere Ergebnisse als andere. Über einen längeren Zeitraum hat der Tester die existierenden automatisierten Testfälle nicht modifiziert und auch keine neuen Testfälle mehr erstellt. Dies führt dazu, dass durch Ausführung der Tests immer weniger Fehler gefunden werden. Welchen Grundsatz des Softwaretestens hat der Tester nicht beachtet?",
    "inhalte": [],
    "antworten": {
      "a": "Testen ist abhängig vom Umfeld",
      "b": "Vollständiges Testen ist nicht möglich",
      "c": "Wiederholungen haben keine Wirksamkeit",
      "d": "Häufung von Fehlerzuständen"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Test ist abhängig vom Umfeld, egal, ob manuell oder automatisiert (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 6. Grundsatz), führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden.",
      "b": "FALSCH<br><br>Erschöpfendes vollständiges Testen ist unmöglich, egal wie viel Aufwand wir in den Test investieren (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 2. Grundsatz), führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden.",
      "c": "KORREKT<br><br>Ein Grundsatz (gem. CTFL CORE Lehrplan 2018) besagt: “Vorsicht vor dem Pestizid-Paradoxon“ bzw. Wiederholungen haben keine Wirksamkeit (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 5. Grundsatz), dass eine Ausführung immer der gleichen Testfälle keine neuen Erkenntnisse mehr bringt. Um neue Fehlerzustände zu finden, müssen bestehende Tests möglicherweise verändert werden und neue Tests erstellt werden.",
      "d": "FALSCH<br><br>Oftmals ist eine “Häufung von Fehlerzuständen“ (CTFL CORE Lehrplan 2018; Abschnitt 1.3; 4. Grundsatz) in einer kleinen Anzahl von Modulen zu beobachten; das führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden."
    }
  },
  {
    "frage": "Inwiefern leistet das Testen einen Beitrag zur Verbesserung von Qualität?",
    "inhalte": [],
    "antworten": {
      "a": "Testen stellt sicher, dass Anforderungen detailliert genug sind.",
      "b": "Testen verringert das Risiko von unzureichender Softwarequalität.",
      "c": "Testen stellt sicher, dass in der Organisation Standards befolgt werden.",
      "d": "Testen misst die Softwarequalität im Hinblick auf die Anzahl ausgeführter Testfälle."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Durch statisches Testen (Reviews) kann dazu beigetragen werden, aber es kann nicht sichergestellt werden, dass die Anforderungen detailliert genug sind. (vgl. CTFL Lehrplan 2018; Abschnitt 1.2.2).",
      "b": "KORREKT<br><br>Testen deckt Fehlerwirkungen und Fehlerzustände auf und verringert damit das Risiko von unzureichender Softwarequalität (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.1.1).",
      "c": "FALSCH<br><br>Dies ist Qualitätssicherung, aber nicht Testen (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.2).",
      "d": "FALSCH<br><br>Die Qualität kann nicht anhand der Anzahl ausgeführter Testfälle gemessen werden, ohne dass man das Ergebnis kennt (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.2)."
    }
  },
  {
    "frage": "Welche der folgenden Aktivitäten ist Teil der Hauptaktivität „Testanalyse“ im Testprozess?",
    "inhalte": [],
    "antworten": {
      "a": "Identifikation der erforderlichen Infrastruktur und Werkzeuge",
      "b": "Erstellen von Testsuiten basierend auf den Testskripten",
      "c": "Analyse der „Lessons learned“ zur Prozessverbesserung",
      "d": "Bewerten der Testbasis hinsichtlich Testbarkeit"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>diese Aktivität wird im “Testentwurf” durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testentwurf).",
      "b": "FALSCH<br><br>diese Aktivität wird in der “Testrealisierung” durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testrealisierung).",
      "c": "FALSCH<br><br>diese Aktivität wird im “Testabschluss“ durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testabschluss).",
      "d": "KORREKT<br><br>diese Aktivität wird in der „Testanalyse“ durchgeführt (CTFL CORE Lehrplan 2018; Abschnitt 1.4.2: „Während der Testanalyse wird die Testbasis analysiert, um testbare Features zu identifizieren …“)."
    }
  },
  {
    "frage": "Wie kann der White-Box-Test während des Abnahmetests angewendet werden?",
    "inhalte": [],
    "antworten": {
      "a": "Um zu prüfen, ob große Datenmengen zwischen integrierten Systemen übertragen werden können.",
      "b": "Um zu prüfen, ob alle Code-Anweisungen und Code-Entscheidungspfade ausgeführt wurden.",
      "c": "Um zu prüfen, ob alle Abläufe der Arbeitsprozesse abgedeckt sind.",
      "d": "Um alle Webseiten-Navigationen abzudecken."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Relevant für Integrationstests. (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.2)",
      "b": "FALSCH<br><br>Relevant für Komponententests (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.1 und 2.3.5, Beispiele für White-Box-Tests)",
      "c": "KORREKT<br><br>CTFL CORE Lehrplan 2018, Abschnitt 2.3.5: Für Abnahmetests sind die Tests so konzipiert, dass sie z. B. alle Dateistrukturen und Wertebereiche der Finanzdaten für Bank-zu-Bank-Überweisungen unterstützen.",
      "d": "FALSCH<br><br>Relevant für Systemtests (vgl. CTFL CORE Lehrplan 2018; Abschnitt 2.2.3, Beispiele für White-Box-Tests)"
    }
  },
  {
    "frage": "Welche der folgenden Aussagen zum Vergleich zwischen Komponententest und Systemtest ist WAHR?",
    "inhalte": [],
    "antworten": {
      "a": "Komponententests überprüfen die Funktion von Komponenten, Programmobjekten und Klassen, die separat prüfbar sind, während Systemtests die Schnittstellen zwischen den Komponenten und Wechselwirkungen mit anderen Teilen des Systems überprüfen.",
      "b": "Testfälle für den Komponententest werden in der Regel von Komponentenspezifikationen, Designspezifikationen oder Datenmodellen abgeleitet, während Testfälle für den Systemtest in der Regel von Anforderungsspezifikationen oder Anwendungsfällen abgeleitet werden.",
      "c": "Komponententests konzentrieren sich nur auf die funktionalen Eigenschaften, während Systemtests sich auf die funktionalen und nicht-funktionalen Eigenschaften konzentrieren.",
      "d": "Komponententests sind in der Verantwortung der Tester, während die Systemtests in der Regel in der Verantwortung der Benutzer des Systems liegen."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Systemtests testen nicht die Schnittstellen und Wechselwirkungen zwischen den Komponenten und anderen Teilen des Systems; das ist Ziel von Integrationstests (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.2.2).",
      "b": "KORREKT<br><br>(siehe CTFL CORE Lehrplan 2018, Abschnitt 2.2.1 (Komponententest): Beispiele für Arbeitsprodukte, die als Testbasis für Komponententests verwendet werden können, umfassen: detailliertes Design, Code, Datenmodell, Komponentenspezifikationen. CTFL CORE Lehrplan 2018; Abschnitt. 2.2.3: Beispiele für Arbeitsprodukte für Systemtests umfassen: System- und Softwareanforderungsspezifikationen (funktional und nicht funktionale), Anwendungsfälle.",
      "c": "FALSCH<br><br>Komponententests konzentrieren sich nicht nur auf funktionale, sondern auch auf nicht-funktionale Aspekte (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.1, Komponententest).",
      "d": "FALSCH<br><br>Komponententests werden auch von Entwicklern durchgeführt, wohin gegen sich (unabhängige) Tester mit Systemtests befassen (vgl. CTFL CORE Lehrplan 2018, Unterkapitel 2.2.1 und 2.2.3, jeweils Abschnitt „Spezifische Ansätze und Verantwortlichkeiten“)."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen ist zutreffend?",
    "inhalte": [],
    "antworten": {
      "a": "Der Zweck des Regressionstests ist es, zu überprüfen, ob die Korrektur erfolgreich implementiert wurde, während der Zweck der Fehlernachtests darin besteht, zu bestätigen, dass die Korrektur keine Seiteneffekte hat.",
      "b": "Der Zweck des Regressionstests ist es, unbeabsichtigte Seiteneffekte zu erkennen, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob das System in einer neuen Umgebung noch funktioniert.",
      "c": "Der Zweck des Regressionstests ist es, unbeabsichtigte Seiteneffekte zu erkennen, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob der ursprüngliche Fehlerzustand behoben wurde.",
      "d": "Der Zweck des Regressionstests ist es zu prüfen, ob die neue Funktionalität funktioniert, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob der ursprüngliche Fehlerzustand behoben wurde."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Regressionstests überprüfen nicht die erfolgreiche Implementierung einer Korrektur und Fehlernachtest prüfen nicht auf Seiteneffekte. (siehe CTFL CORE Lehrplan, Abschnitt 2.3.4).",
      "b": "FALSCH<br><br>Die Aussage über Fehlernachtests sollte sich auf Regressionstests beziehen (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.4).",
      "c": "KORREKT<br><br>CTFL CORE Lehrplan 2018, Abschnitt 2.3.4.",
      "d": "FALSCH<br><br>Test neuer Funktionalität ist nicht Bestandteil eines Regressionstests (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.4 im Vergleich zu Abschnitt. 2.3.4 für Regressionstests)."
    }
  },
  {
    "frage": "Welches ist die BESTE Definition eines inkrementellen Entwicklungsmodells?",
    "inhalte": [],
    "antworten": {
      "a": "Die Definition der Anforderungen, das Design der Software und das Testen erfolgen in einer Serie durch Hinzufügen von Teilen.",
      "b": "Eine Phase des Entwicklungsprozesses sollte beginnen, wenn die vorhergehende Phase abgeschlossen ist.",
      "c": "Das Testen wird als separate Phase betrachtet. Sie startet, wenn die Entwicklung abgeschlossen ist.",
      "d": "Das Testen wird der Entwicklung als Inkrement hinzugefügt."
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1 (9. Absatz): Bei der inkrementellen Entwicklung geht es um die Festlegung von Anforderungen, Entwurf, Entwicklung und Test eines Systems in Teilen.",
      "b": "FALSCH<br><br>Dieses ist ein sequenzielles Modell (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).",
      "c": "FALSCH<br><br>Dies beschreibt das Wasserfall-Modell (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).",
      "d": "FALSCH<br><br>Das Testen für sich ist kein Inkrement/zusätzliche Stufe in der Entwicklung, sondern während der Entwicklung gibt es Inkremente (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1)."
    }
  },
  {
    "frage": "Welcher der folgenden Entscheidungen sollte KEIN Auslöser für Wartungstests sein?",
    "inhalte": [],
    "antworten": {
      "a": "Die Entscheidung, die Wartbarkeit der Software zu testen",
      "b": "Die Entscheidung, das System nach der Migration auf einer neuen Betriebsplattform zu testen",
      "c": "Die Entscheidung zu testen, ob archivierte Daten abgerufen werden können",
      "d": "Die Entscheidung zum Testen nach 'Hot Fixes'"
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>Dies ist ein Wartbarkeitstest und nicht ein Wartungstest. „... die meisten Wartbarkeitsfehler (können) nur durch statische Tests gefunden werden.“ (CTFL CORE Lehrplan 2018, Kap. 3.1.3, letzter Absatz)",
      "b": "FALSCH<br><br>Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4.1: Betriebstests der neuen Umgebung, sowie der geänderten Software.",
      "c": "FALSCH<br><br>Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4.1, 3. Absatz: Testen von Wiederherstellungsprozeduren und Rückholprozeduren nach der Archivierung mit langen Aufbewahrungszeiten.",
      "d": "FALSCH<br><br>Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4, 2. Absatz, und Kap. 2.4.1: Reaktive Modifikation eines ausgelieferten Softwareproduktes zur Behebung von dringenden Fehlerzuständen, die zu tatsächlichen Fehlerwirkungen geführt haben."
    }
  },
  {
    "frage": "Welche der folgenden Optionen sind Rollen in einem formalen Review?",
    "inhalte": [],
    "antworten": {
      "a": "Entwickler, (Review-)Moderator, Reviewleiter, Gutachter, Tester",
      "b": "Autor, (Review-)Moderator, Manager, Gutachter, Entwickler",
      "c": "Autor, Manager, Reviewleiter, Gutachter, Designer",
      "d": "Autor, (Review-)Moderator, Reviewleiter, Gutachter, Protokollant"
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Tester und Entwickler sind KEINE Rollen im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.",
      "b": "FALSCH<br><br>Entwickler ist KEINE Rolle im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.",
      "c": "FALSCH<br><br>Designer ist KEINE Rolle im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.",
      "d": "KORREKT<br><br>siehe CTFL CORE Lehrplan 2018, Kapitel 3.2.2."
    }
  },
  {
    "frage": "Welche Aktivitäten werden im Rahmen der Planung eines formalen Reviews durchgeführt?",
    "inhalte": [],
    "antworten": {
      "a": "Sammeln von Metriken für die Bewertung der Effektivität des Reviews.",
      "b": "Beantwortung von Fragen, die die Teilnehmer haben könnten.",
      "c": "Definition und Prüfung der Erfüllung von Eingangskriterien für das Review.",
      "d": "Bewertung der Reviewbefunde gegenüber den Endekriterien."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Das Sammeln von Metriken ist der Hauptaktivität „Fehlerbehebung und Bericht“ zugeordnet. (vgl. CTFL CORE Lehrplan 2018, Abschnitt. 3.2.1);",
      "b": "FALSCH<br><br>Die Beantwortung von Fragen ist der Hauptaktivität „Reviewbeginn“ (Initiierung eines Reviews, KICKOFF) zugeordnet (vgl. CTFL CORE Lehrplan 2018, Abschnitt. 3.2.1);",
      "c": "KORREKT<br><br>Sowohl die Definition als auch die Prüfung von Eingangskriterien erfolgt in der „Planung“ eines formalen Reviews (vgl. CTFL CORE Lehrplan 2018, Abschnitt. 3.2.1);",
      "d": "FALSCH<br><br>Die Bewertung der Reviewbefunde gegenüber den Endekriterien ist der Hauptaktivität „Befundkommunikation und -analyse“ zugeordnet (vgl. CTFL CORE Lehrplan 2018, Abschnitt. 3.2.1);"
    }
  },
  {
    "frage": "Welche der unten aufgeführten Reviewarten ist AM BESTEN geeignet, wenn das Review gemäß einem formalen bzw. definierten Prozess mit Regeln und unter Verwendung von Checklisten durchgeführt werden soll?",
    "inhalte": [],
    "antworten": {
      "a": "Informelles Review",
      "b": "Technisches Review",
      "c": "Inspektion",
      "d": "Walkthrough"
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>ein informelles Review verwendet keinen formalen Prozess (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 3. Absatz)",
      "b": "FALSCH<br><br>die Verwendung von Checklisten ist optional (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 5. Absatz)",
      "c": "KORREKT<br><br>Inspektion ist ein definierter Prozess mit Regeln und Checklisten (siehe CTFL CORE Lehrplan 2018; Abschnitt 3.2.3, 6. Absatz)",
      "d": "FALSCH<br><br>erfordert nicht immer einen formalen Prozess und die Verwendung von Checklisten ist optional (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 4. Absatz)"
    }
  },
  {
    "frage": "Welche der folgenden Aussagen zum statischen Test ist am EHESTEN zutreffend?",
    "inhalte": [],
    "antworten": {
      "a": "Statischer Test ist eine kostengünstige Möglichkeit, Fehlerzustände zu erkennen und zu beheben.",
      "b": "Statischer Test macht den dynamischen Test theoretisch überflüssig.",
      "c": "Statischer Test ermöglicht, Laufzeitprobleme frühzeitig im Lebenszyklus zu erkennen.",
      "d": "Bei der Prüfung sicherheitskritischer Systeme hat der statische Test einen geringen Stellenwert, da der dynamische Test den Fehlerzustand besser findet."
    },
    "korrekteAntwort": "a",
    "feedback": {
      "a": "KORREKT<br><br>CTFL CORE Lehrplan 2018; Abschnitt 3.1.2, 3. Satz: Früh entdeckte Fehlerzustände sind oft viel kostengünstiger zu beheben als Fehlerzustände, die später im Lebenszyklus erkannt werden.",
      "b": "FALSCH<br><br>Dynamische Tests haben ihre Berechtigung, da sie andere Fehlerarten finden als statische Tests (vgl. CTFL CORE Lehrplan 2018; Abschnitt 3.1.3, 1. Absatz).",
      "c": "FALSCH<br><br>Dies geschieht beim dynamischen Testen (siehe Glossar V.3.2).",
      "d": "FALSCH<br><br>Statischer Test ist wichtig für sicherheitskritische Computersysteme (vgl. CTFL CORE Lehrplan 2018; Abschnitt 3.1, 2. Absatz)."
    }
  },
  {
    "frage": "Sie werden zum Review eingeladen. Das zu prüfende Arbeitsergebnis ist eine Beschreibung des firmeninternen Dokumentenerstellungsprozesses. Ziel der Beschreibung ist die für alle zweifelsfrei nachvollziehbare Darstellung der Arbeitsteilung zwischen den verschiedenen am Prozess beteiligten Rollen. Sie werden zum checklistenbasierten Review eingeladen. Die Checkliste wird Ihnen ebenfalls zugeschickt. Sie umfasst die folgenden Punkte: i. Wird für jede Tätigkeit der Ausführende klar benannt? ii. Ist für jede Tätigkeit das Eingangskriterium klar definiert? iii. Ist für jede Tätigkeit das Endekriterium klar definiert? iv. Sind für jede Tätigkeit die zuarbeitenden Rollen und ihr Arbeitsumfang klar definiert? Im Folgenden zeigen wir einen Ausschnitt des zu prüfenden Arbeitsergebnisses, zu dessen Review Sie die obige Checkliste anwenden sollen: „Nach Prüfung der Kundendokumentation auf Vollständigkeit und Korrektheit erstellt der Softwarearchitekt die Systemspezifikation. Nachdem der Softwarearchitekt die Systemspezifikation fertiggestellt hat, lädt er Tester zum Review ein. Eine bereitgestellte Checkliste beschreibt den Umfang des Reviews. Jeder eingeladene Gutachter erstellt – sofern notwendig – Reviewkommentare und schließt das Review mit einem offiziellen Review-done-Kommentar ab.“ Welcher der folgenden Aussagen zu Ihrem Review ist korrekt?",
    "inhalte": [],
    "antworten": {
      "a": "Punkt ii) der Checkliste wurde verletzt, da nicht klar ist, welche Bedingung erfüllt sein muss, damit zum Review eingeladen werden kann.",
      "b": "Ihnen fällt auf, dass neben dem Tester auch ein Experte für Validierung eingeladen werden muss. Da dieser Punkt aber nicht Bestandteil Ihrer Checkliste ist, erstellen Sie keinen entsprechenden Kommentar.",
      "c": "Punkt iii) der Checkliste wurde verletzt, da nicht klar ist, wodurch das Review als abgeschlossen gekennzeichnet ist.",
      "d": "Punkt i) der Checkliste wurde verletzt, da nicht klar ist, wer die Checkliste für die Einladung zum Review bereitstellt."
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>es ist beschrieben, dass der Architekt die Systemspezifikation fertiggestellt haben muss.",
      "b": "FALSCH<br><br>siehe CTFL CORE Lehrplan, Abschnitt 3.2.4, „Checklistenbasiert“: im letzten Satz des Absatzes steht, dass auch auf Punkte außerhalb der Checkliste geachtet werden muss.",
      "c": "FALSCH<br><br>es ist beschrieben: jeder Gutachter hat seinen Review-done-Kommentar erstellt.",
      "d": "KORREKT<br><br>es ist beschrieben: „Eine bereitgestellte Checkliste“ … aber wer stellt sie bereit?"
    }
  },
  {
    "frage": "Was ist checklistenbasiertes Testen?",
    "inhalte": [],
    "antworten": {
      "a": "Ein Testverfahren, bei dem Testfälle auf Basis des Wissens der Tester über frühere Fehler oder aus allgemeinem Wissen über Fehlerwirkungen abgeleitet werden.",
      "b": "Ein Testverfahren, das auf einer Analyse der Spezifikation einer Komponente oder eines Systems basiert.",
      "c": "Ein erfahrungsbasiertes Testverfahren, bei dem der erfahrene Tester z. B. eine Liste von Kontrollpunkten nutzt, welche beachtet, überprüft oder in Erinnerung gerufen werden müssen.",
      "d": "Ein Testansatz, bei dem die Tester dynamisch Tests entwerfen und durchführen, basierend auf ihrem Wissen, der Erkundung des Testelements und dem Ergebnis früherer Tests."
    },
    "korrekteAntwort": "c",
    "feedback": {
      "a": "FALSCH<br><br>Das ist die Definition für intuitive Testfallermittlung, siehe Glossar V.3.3.",
      "b": "FALSCH<br><br>Das ist die Definition für Black-Box-Testverfahren, siehe Glossar V.3.3.",
      "c": "KORREKT<br><br>siehe Glossar 3.3.",
      "d": "FALSCH<br><br>Das ist (bis auf die Erwähnung des Testers) die Definition für exploratives Testen, siehe Glossar V.3.3."
    }
  },
  {
    "frage": "Welches der folgenden Verfahren kann der Kategorie Black-Box-Testverfahren zugeordnet werden?",
    "inhalte": [],
    "antworten": {
      "a": "Verfahren, das auf der Analyse der Architektur basiert.",
      "b": "Verfahren, das prüft, ob das Testobjekt entsprechend dem Feinentwurf umgesetzt ist.",
      "c": "Verfahren, das auf dem Wissen über frühere Fehler oder dem allgemeinen Wissen über Fehler basiert.",
      "d": "Verfahren, das z. B. auf formalen Anforderungsdokumenten basiert."
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br>Dies bezieht sich auf White-Box-Testverfahren. (vgl. CTFL CORE Lehrplan 2018, 4.1.2, 3. Absatz)",
      "b": "FALSCH<br><br>Dies bezieht sich auf White-Box-Testverfahren. (vgl. CTFL CORE Lehrplan 2018; Abschnitte 4.1.2, 3. Absatz)",
      "c": "FALSCH<br><br>Dies bezieht sich auf erfahrungsbasierte Testverfahren. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.4)",
      "d": "KORREKT<br><br>CTFL CORE Lehrplan 2018; Abschnitt 4.1.2, 2. Absatz: Black-Box-Testverfahren basieren auf einer Analyse der zugehörigen Testbasis (z. B. formale Anforderungsdokumente, Spezifikationen, Anwendungsfälle, User-Stories)."
    }
  },
  {
    "frage": "Die folgende Aussage bezieht sich auf Entscheidungsüberdeckung: \"Wenn der Code nur aus einer einzigen IF-Anweisung (also keinen Schleifen oder CASE-Anweisungen) besteht und auch sonst durch den Test nicht geschachtelt aufgerufen wird, dann wird bei einem einzelnen Testfall, der ausgeführt wird, eine Entscheidungsüberdeckung von 50% erreicht.\" Welcher der folgenden Aussagen ist zutreffend?",
    "inhalte": [],
    "antworten": {
      "a": "Die Aussage ist wahr. Ein einzelner Testfall erzielt eine 100% Anweisungsüberdeckung und daher 50% Entscheidungsüberdeckung.",
      "b": "Die Aussage ist wahr. Bei einem einzelnen Testfall ist der Entscheidungsausgang der IF-Anweisung entweder wahr oder falsch.",
      "c": "Die Aussage ist falsch. Ein einzelner Testfall kann in diesem Fall nur eine Entscheidungsüberdeckung von 25% garantieren.",
      "d": "Die Aussage ist falsch. Die Aussage ist zu weit gefasst. Sie kann abhängig von der getesteten Software richtig sein oder nicht."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br>Während die gemachte Aussage wahr ist, ist die Erklärung falsch; weil die Beziehung zwischen Anweisungsüberdeckung und Entscheidungsüberdeckung falsch dargestellt ist. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.3.3)",
      "b": "KORREKT<br><br>Da jeder Testfall dazu führt, dass das Ergebnis der IF-Anweisung entweder WAHR oder FALSCH ist, haben wir definitiv 50% Entscheidungsüberdeckung erreicht. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.3.2, 2. Absatz)",
      "c": "FALSCH<br><br>Ein einzelner Testfall kann mehr als 25% Entscheidungsüberdeckung erreichen; bei der obigen Aussage sind es 50% Entscheidungsüberdeckung (vgl. Begründung zu Antwort b)",
      "d": "FALSCH<br><br>Die obige Aussage ist konkret und immer wahr; weil durch jeden einzelnen Testfall immer eine Entscheidungsüberdeckung von 50% erreicht wird. (vgl. Begründung zu Antwort b)"
    }
  },
  {
    "frage": "Was beschreibt am besten die Rolle eines Testers im Testprozess?",
    "inhalte": [],
    "antworten": {
      "a": "Die Überprüfung der Testumgebung und die Gewährleistung der Testbarkeit der Anwendung.",
      "b": "Die Planung, Durchführung und Dokumentation der Tests basierend auf vordefinierten Anforderungen.",
      "c": "Die Programmierung neuer Funktionen und die Korrektur von gefundenen Fehlern.",
      "d": "Die ausschließliche Fokussierung auf die Automatisierung bestehender Testfälle."
    },
    "korrekteAntwort": "b",
    "feedback": {
      "a": "FALSCH<br><br> Während die Überprüfung der Testumgebung wichtig ist, beschreibt dies nicht vollständig die Rolle eines Testers.",
      "b": "KORREKT<br><br> Tester sind für die Planung, Durchführung und Dokumentation der Tests verantwortlich.",
      "c": "FALSCH<br><br> Die Programmierung neuer Funktionen gehört in der Regel nicht zu den Aufgaben eines Testers.",
      "d": "FALSCH<br><br> Testautomatisierung ist nur ein Teil des Testprozesses, nicht die gesamte Rolle eines Testers."
    }
  },
  {
    "frage": "Welche der folgenden Aussagen zum Regressionstest ist WAHR?",
    "inhalte": [],
    "antworten": {
      "a": "Regressionstests werden durchgeführt, um sicherzustellen, dass neue Fehler in bereits getesteten Softwareteilen eingeführt wurden.",
      "b": "Regressionstests sind nur notwendig, wenn die Software in einer agilen Umgebung entwickelt wird.",
      "c": "Regressionstests umfassen das erneute Testen von fixierten Fehlern, um sicherzustellen, dass die Korrekturen funktionieren.",
      "d": "Regressionstests werden durchgeführt, um sicherzustellen, dass Änderungen nicht zu Fehlern in unveränderten Bereichen der Software führen."
    },
    "korrekteAntwort": "d",
    "feedback": {
      "a": "FALSCH<br><br> Das Ziel des Regressionstests ist es nicht, neue Fehler einzuführen, sondern sicherzustellen, dass durch Änderungen keine neuen Fehler in bereits getesteten Teilen verursacht werden.",
      "b": "FALSCH<br><br> Regressionstests sind unabhängig von der Entwicklungsart oder -methode wichtig und notwendig.",
      "c": "FALSCH<br><br> Während das Testen von fixierten Fehlern wichtig ist, ist es nicht die primäre Definition von Regressionstests.",
      "d": "KORREKT<br><br> Regressionstests zielen darauf ab, die Stabilität und Zuverlässigkeit der Software nach Änderungen zu gewährleisten, indem sichergestellt wird, dass keine neuen Fehler in unveränderte Bereiche eingeführt wurden."
    }
  }
]